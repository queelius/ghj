[
    {
        "id": 496744293,
        "node_id": "R_kgDOHZu3ZQ",
        "name": "algebraic.dist",
        "full_name": "queelius/algebraic.dist",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/algebraic.dist",
        "description": "Algebraic distributions",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/algebraic.dist",
        "forks_url": "https://api.github.com/repos/queelius/algebraic.dist/forks",
        "keys_url": "https://api.github.com/repos/queelius/algebraic.dist/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/algebraic.dist/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/algebraic.dist/teams",
        "hooks_url": "https://api.github.com/repos/queelius/algebraic.dist/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/algebraic.dist/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/algebraic.dist/events",
        "assignees_url": "https://api.github.com/repos/queelius/algebraic.dist/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/algebraic.dist/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/algebraic.dist/tags",
        "blobs_url": "https://api.github.com/repos/queelius/algebraic.dist/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/algebraic.dist/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/algebraic.dist/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/algebraic.dist/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/algebraic.dist/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/algebraic.dist/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/algebraic.dist/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/algebraic.dist/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/algebraic.dist/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/algebraic.dist/subscription",
        "commits_url": "https://api.github.com/repos/queelius/algebraic.dist/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/algebraic.dist/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/algebraic.dist/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/algebraic.dist/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/algebraic.dist/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/algebraic.dist/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/algebraic.dist/merges",
        "archive_url": "https://api.github.com/repos/queelius/algebraic.dist/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/algebraic.dist/downloads",
        "issues_url": "https://api.github.com/repos/queelius/algebraic.dist/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/algebraic.dist/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/algebraic.dist/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/algebraic.dist/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/algebraic.dist/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/algebraic.dist/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/algebraic.dist/deployments",
        "created_at": "2022-05-26T19:17:07Z",
        "updated_at": "2024-11-28T05:00:10Z",
        "pushed_at": "2024-11-28T05:00:06Z",
        "git_url": "git://github.com/queelius/algebraic.dist.git",
        "ssh_url": "git@github.com:queelius/algebraic.dist.git",
        "clone_url": "https://github.com/queelius/algebraic.dist.git",
        "svn_url": "https://github.com/queelius/algebraic.dist",
        "homepage": "https://queelius.github.io/algebraic.dist/",
        "size": 2682,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": "R",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "gpl-3.0",
            "name": "GNU General Public License v3.0",
            "spdx_id": "GPL-3.0",
            "url": "https://api.github.com/licenses/gpl-3.0",
            "node_id": "MDc6TGljZW5zZTk="
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "main",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 38
            }
        ],
        "readme_content": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# R package: `algebraic.dist`\n\n<!-- badges: start -->\n\n[![GPL-3\nLicense](https://img.shields.io/badge/license-GPL--3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\n<!-- badges: end -->\n\n<!-- summary-start -->\nAn algebra over distributions (random elements).\n<!-- summary-end -->\n\n<!-- tags-start -->\n**Tags**: multivariate distributions, multivariate normal distribution, multivariate empirical distribution, data generating process, R, data-science, statistics, inference, likelihood-models, probability-theory\n<!-- tags-end -->\n\n**Table Of Contents**\n\n- [R package: `algebraic.dist`](#r-package-algebraicdist)\n   - [Installation](#installation)\n   - [About](#about)\n\n## GitHub Pages Documentation\n\nThe GitHub documentation can be viewed [here](https://queelius.github.io/algebraic.dist/).\n\nSee the vignette [algebraic.dist: Example](https://queelius.github.io/algebraic.dist/articles/example.html)\nfor a quick introduction to the package.\n\n## Installation\n\nYou can install the development version of `algebraic.dist` from\n[GitHub](https://github.com/) with:\n\n``` r\n# install.packages(\"devtools\")\ndevtools::install_github(\"queelius/algebraic.dist\")\n```\n\n## About\n\nThe R package `algebraic.dist` provides an algebra over distributions.\nIt's not fully-formed yet, but I plan on using it for a lot of my future work.\nFor instance, I'll move a lot of the code in `algebraic.mle` and \n`likelihood.model` to this package.\n\nAfter that, I want to experiment with using the `algebraic.dist` to do the\nfollowing:\n\n- Compose distributions such that operations over distributions generate\nother known distributions.\n\n  There are a lot of well-known compositions, such as\nthe exponential distribution being the minimum of independent exponential distributions, or the sum of independent normal\ndistributions being a normal distribution, but there is a very large space of\npossible compositions that are not as well-known or well-studied that I want to\nexplore.\n\n- Let people use an R expression to lazily compose functions of distributions.\nSimplifying a distribution expression will generate a most simple R expression\nthat represents the same distribution.\n\nSometimes, this may result in a simple close-form distribution, like a \nmultivariate normal distribution, but in other cases it may result in a\n(hopefully simpler) expression that composes multiple distributions and\noperations over them.\n\n- With these R expressions that represent distributions, we can define more\noperations, like taking the limiting distribution of a sequence of\ndistributions, say $\\lim_{n \\to \\infty} \\frac{1}{n} \\sum_{i=1}^n X_i$, which is\nof normal by the central limit theorem.\n\n- Deduce various properties of these distributions, such as their moments,\nvariances, etc. Sometimes, this may require numerical integration or Monte\nCarlo methods, but if the expression simplifies to a known distribution, then\nwe can use the known properties of that distribution.\n\nI have a lot of this code in place in C++, but I want to\nre-implement it in R so that it's more accessible to others. I may also\nimplement some of the more interesting compositions in C++ and expose them to R\nvia Rcpp, but I'm not sure yet. I use a lot of templates and metaprogramming in\nC++, and I'm not sure how well that will translate to Rcpp.\n\n",
        "github_pages": "https://queelius.github.io/algebraic.dist/"
    },
    {
        "id": 900609508,
        "node_id": "R_kgDONa415A",
        "name": "AutoPoiesi",
        "full_name": "queelius/AutoPoiesi",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/AutoPoiesi",
        "description": "A policy-based agent capable of self-improvement.",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/AutoPoiesi",
        "forks_url": "https://api.github.com/repos/queelius/AutoPoiesi/forks",
        "keys_url": "https://api.github.com/repos/queelius/AutoPoiesi/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/AutoPoiesi/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/AutoPoiesi/teams",
        "hooks_url": "https://api.github.com/repos/queelius/AutoPoiesi/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/AutoPoiesi/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/AutoPoiesi/events",
        "assignees_url": "https://api.github.com/repos/queelius/AutoPoiesi/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/AutoPoiesi/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/AutoPoiesi/tags",
        "blobs_url": "https://api.github.com/repos/queelius/AutoPoiesi/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/AutoPoiesi/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/AutoPoiesi/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/AutoPoiesi/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/AutoPoiesi/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/AutoPoiesi/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/AutoPoiesi/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/AutoPoiesi/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/AutoPoiesi/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/AutoPoiesi/subscription",
        "commits_url": "https://api.github.com/repos/queelius/AutoPoiesi/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/AutoPoiesi/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/AutoPoiesi/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/AutoPoiesi/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/AutoPoiesi/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/AutoPoiesi/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/AutoPoiesi/merges",
        "archive_url": "https://api.github.com/repos/queelius/AutoPoiesi/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/AutoPoiesi/downloads",
        "issues_url": "https://api.github.com/repos/queelius/AutoPoiesi/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/AutoPoiesi/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/AutoPoiesi/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/AutoPoiesi/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/AutoPoiesi/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/AutoPoiesi/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/AutoPoiesi/deployments",
        "created_at": "2024-12-09T06:16:45Z",
        "updated_at": "2024-12-09T06:16:54Z",
        "pushed_at": "2024-12-09T06:16:50Z",
        "git_url": "git://github.com/queelius/AutoPoiesi.git",
        "ssh_url": "git@github.com:queelius/AutoPoiesi.git",
        "clone_url": "https://github.com/queelius/AutoPoiesi.git",
        "svn_url": "https://github.com/queelius/AutoPoiesi",
        "homepage": null,
        "size": 3,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": null,
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 1
            }
        ],
        "readme_content": "# README\n\n## Overview\n\nThis repository explores the construction of a continuously running, agentic AI system that leverages a Large Language Model (LLM) as one of its tools. The system treats the environment as an open-ended world where user inputs, newly discovered resources, and self-improvement tasks serve as observations and opportunities for policy refinement.\n\nOur agent operates within a reinforcement learning (RL) paradigm:\n\n- **States**: Represent the current state of the agent\u2019s environment, which includes:\n  - The most recent user input (if any).\n  - The current internal workspace containing code repositories, data structures, graders, and other tools.\n  - The conversation history with the LLM and other logs of its past actions.\n\n- **Actions**: Extend beyond simply responding to a prompt. The agent can:\n  - Interact with the LLM to reason about a problem.\n  - Modify, create, or decompose code functions in its repository.\n  - Retrieve, store, and transform documents from a Retrieval Augmented Generation (RAG) store.\n  - Construct new graders or evaluation metrics.\n  - Refine its internal toolset, reorganizing and simplifying existing primitives.\n  - Potentially do nothing (no-op) if that\u2019s advantageous at a given time step.\n\n- **Rewards**: Derived from multiple sources:\n  - External graders that evaluate answers, code correctness, or solution quality.\n  - User feedback (positive or negative) in response to the agent\u2019s outputs.\n  - Internal evaluation metrics that the agent sets to guide long-term self-improvement and alignment with certain principles.\n\nUnlike a traditional single-episode setup, the agent is persistent and \u201calways on.\u201d Inputs and requests may arrive intermittently from users, but even in their absence, the agent can explore, reorganize, learn, and improve itself.\n\n## Key Concepts\n\n### Continuous Interaction Loop\n\nThe system never fully \u201cresets.\u201d It continuously perceives (user requests, new data, sensor inputs), updates its internal structures, and takes actions to refine its capabilities and knowledge.\n\n- **Time Steps**: At each time step:\n  1. The environment provides observations (user queries, updated tool states, etc.).\n  2. The agent chooses an action from its large space of possibilities.\n  3. The outcome of that action updates the state (e.g., modifies internal code, retrieves new documents, or updates the LLM\u2019s context).\n  4. Rewards are computed and fed back to the agent.\n\n### LLM as a Fixed Tool\n\nWe treat the LLM as a stable component\u2014akin to a powerful API. The agent\u2019s neural policy network, however, evolves over time as it learns how best to use this LLM, along with other tools. The LLM is:\n- Not retrained frequently (though this could be explored later).\n- Accessed by actions that issue prompts, refine queries, or request reasoning.\n\nThis separation ensures a stable \u201ccore intelligence\u201d (the LLM) combined with a meta-layer (the policy and associated toolset) that learns to orchestrate and exploit that intelligence effectively.\n\n### Workspace & Tooling\n\nThe agent has access to a global workspace containing:\n- **Code Repositories**: Sets of Python functions, scripts, or other programs that can be called upon. The agent can refactor, create new functions, or break down large functions into smaller, more composable primitives.\n- **RAG Systems**: Retrieval-based tools for accessing external knowledge. The agent can add to or reorganize these knowledge stores, improving future retrievals.\n- **Grader Definitions**: The agent can create or improve graders\u2014evaluation functions that test code or solutions against criteria. Over time, it may learn to generate domain-specific graders to better measure progress in new tasks.\n\n### Expanded Action Space\n\nActions are now significantly richer. Examples include:\n\n- **LLM Actions**:\n  - \u201cAsk the LLM to explain concept X.\u201d\n  - \u201cRequest reasoning steps from the LLM about a difficult user query.\u201d\n\n- **Code-Manipulation Actions**:\n  - \u201cCreate a new Python function to handle data parsing.\u201d\n  - \u201cRefactor existing code into smaller, more general-purpose functions.\u201d\n  - \u201cIntroduce unit tests for a newly created function.\u201d\n\n- **Grader & Evaluation Actions**:\n  - \u201cGenerate a new grader for code correctness based on unit tests.\u201d\n  - \u201cImprove an existing grader to provide more nuanced feedback.\u201d\n\n- **RAG Actions**:\n  - \u201cRetrieve documents relevant to current user query.\u201d\n  - \u201cOrganize the knowledge base for faster lookups.\u201d\n  - \u201cAdd metadata tags to documents to improve retrieval quality.\u201d\n\n- **Meta-Actions (Self-Improvement)**:\n  - \u201cIdentify redundancies in the function library and remove them.\u201d\n  - \u201cDecompose a complex function into simpler building blocks.\u201d\n  - \u201cAdd documentation or comments to code functions to improve maintainability.\u201d\n\n- **No-Op Actions**:\n  - \u201cWait and do nothing this step,\u201d which can sometimes be strategic.\n\n### Multi-Source Reward Signals\n\nRewards come from:\n- **User Feedback**: Positive feedback if the user finds the output helpful, negative if it\u2019s off-target or harmful.\n- **Grader Outputs**: Functions or tests that validate a solution\u2019s correctness. Negative rewards for failing tests, positive rewards for passing.\n- **Internal Goals**: The agent might set internal objectives (like improving code test coverage or minimizing code duplication), measured by automated graders, yielding rewards as these goals are met.\n\nThis flexibility in reward sources encourages the agent to engage in open-ended, unsupervised improvement activities, not just user-driven tasks.\n\n### Embracing \u201cThe Bitter Lesson\u201d\n\nFollowing Richard Sutton\u2019s \u201cThe Bitter Lesson,\u201d we focus on scaling experience and letting the agent learn general strategies rather than hard-coding heuristics. Over time, as the policy network, code repository, and retrieval systems grow and adapt, the agent learns more general-purpose methods for:\n\n- Problem-solving across diverse tasks.\n- Self-improvement without constant human engineering.\n- Aligning with user interests and quality metrics provided by graders.\n\nWe avoid relying too heavily on carefully designed shortcuts and instead allow massive amounts of experience, trial, and error to shape a broadly competent agent.\n\n### Meta-Learning Aspects\n\nThe agent effectively engages in meta-learning:\n\n- It learns how to learn better, by improving its toolset and graders.\n- It may discover abstractions that make solving future problems easier.\n- The policy can learn to respond adaptively to new tasks, user queries, or internal goals as they arise, evolving its strategies over time.\n\n## Implementation Roadmap\n\n1. **Initial MVP**:\n   - Set up a loop with a stable LLM \u201cAPI\u201d and a small set of code functions.\n   - Implement a simple grader (e.g., unit tests for a particular code function).\n   - Train a basic RL policy to solve simple tasks, using MCTS or a policy gradient method to choose actions.\n\n2. **Expanding Toolsets**:\n   - Add functionalities to create, refactor, or remove functions.\n   - Incorporate a RAG system and actions to query and update it.\n   - Introduce multiple graders and more complex reward structures.\n\n3. **Self-Improvement & Meta-Learning**:\n   - Add actions for reorganizing code into more fundamental primitives.\n   - Introduce internal metrics for code quality or retrieval efficiency.\n   - Encourage the agent to improve its own graders, making it better at evaluating progress on new tasks.\n\n4. **User Interaction**:\n   - Incorporate real or simulated user queries that arrive intermittently.\n   - Reward or penalize the agent based on user satisfaction.\n\n5. **Scaling & Generalization**:\n   - Scale up the environment complexity.\n   - Evaluate how well the policy generalizes to entirely new tasks and domains.\n   - Study emergent behaviors and the evolution of the agent\u2019s internal toolkit over time.\n\n## Conclusion\n\nThis research direction aims to create a persistent, general-purpose AI agent that continually learns and improves. By blending RL, tool integration, and LLM capabilities, and by embracing the open-endedness of real-world environments, we hope to push toward more adaptive, general intelligence guided by experience, feedback, and the \u201cbitter lesson\u201d that scalable methods and massive training signals often surpass fine-tuned heuristics."
    },
    {
        "id": 652139154,
        "node_id": "R_kgDOJt7akg",
        "name": "chatgpt-pysearch",
        "full_name": "queelius/chatgpt-pysearch",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/chatgpt-pysearch",
        "description": null,
        "fork": false,
        "url": "https://api.github.com/repos/queelius/chatgpt-pysearch",
        "forks_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/forks",
        "keys_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/teams",
        "hooks_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/events",
        "assignees_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/tags",
        "blobs_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/subscription",
        "commits_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/merges",
        "archive_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/downloads",
        "issues_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/chatgpt-pysearch/deployments",
        "created_at": "2023-06-11T08:03:50Z",
        "updated_at": "2023-06-11T09:07:46Z",
        "pushed_at": "2023-06-11T08:38:04Z",
        "git_url": "git://github.com/queelius/chatgpt-pysearch.git",
        "ssh_url": "git@github.com:queelius/chatgpt-pysearch.git",
        "clone_url": "https://github.com/queelius/chatgpt-pysearch.git",
        "svn_url": "https://github.com/queelius/chatgpt-pysearch",
        "homepage": "https://queelius.github.io/chatgpt-pysearch/",
        "size": 13937,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": "HTML",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [
            "chat-log",
            "dev-log",
            "gpt-4",
            "python",
            "search"
        ],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 16
            }
        ],
        "readme_content": "# ChatGPT chat search\n\nThis was the first python app I developed in quite some time. I wanted to host ChatGPT logs, experiment with heroku, and see how easy it would be to develop the search app using nothing but ChatGPT. I've hosted the entire chat log that directly generated this app in this repo. It's nothing special, but it's interesting to see my early efforts at using ChatGPT.\n\nYou can see the chat log here: https://queelius.github.io/chatgpt-pysearch/index.html\n\nThe herok app is hosted here: https://chatgpt.metafunctor.com/\n",
        "github_pages": "https://queelius.github.io/chatgpt-pysearch/"
    },
    {
        "id": 165695449,
        "node_id": "MDEwOlJlcG9zaXRvcnkxNjU2OTU0NDk=",
        "name": "cipher_maps",
        "full_name": "queelius/cipher_maps",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/cipher_maps",
        "description": null,
        "fork": false,
        "url": "https://api.github.com/repos/queelius/cipher_maps",
        "forks_url": "https://api.github.com/repos/queelius/cipher_maps/forks",
        "keys_url": "https://api.github.com/repos/queelius/cipher_maps/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/cipher_maps/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/cipher_maps/teams",
        "hooks_url": "https://api.github.com/repos/queelius/cipher_maps/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/cipher_maps/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/cipher_maps/events",
        "assignees_url": "https://api.github.com/repos/queelius/cipher_maps/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/cipher_maps/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/cipher_maps/tags",
        "blobs_url": "https://api.github.com/repos/queelius/cipher_maps/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/cipher_maps/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/cipher_maps/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/cipher_maps/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/cipher_maps/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/cipher_maps/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/cipher_maps/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/cipher_maps/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/cipher_maps/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/cipher_maps/subscription",
        "commits_url": "https://api.github.com/repos/queelius/cipher_maps/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/cipher_maps/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/cipher_maps/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/cipher_maps/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/cipher_maps/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/cipher_maps/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/cipher_maps/merges",
        "archive_url": "https://api.github.com/repos/queelius/cipher_maps/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/cipher_maps/downloads",
        "issues_url": "https://api.github.com/repos/queelius/cipher_maps/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/cipher_maps/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/cipher_maps/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/cipher_maps/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/cipher_maps/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/cipher_maps/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/cipher_maps/deployments",
        "created_at": "2019-01-14T16:34:53Z",
        "updated_at": "2023-11-07T05:16:17Z",
        "pushed_at": "2023-10-06T05:49:19Z",
        "git_url": "git://github.com/queelius/cipher_maps.git",
        "ssh_url": "git@github.com:queelius/cipher_maps.git",
        "clone_url": "https://github.com/queelius/cipher_maps.git",
        "svn_url": "https://github.com/queelius/cipher_maps",
        "homepage": null,
        "size": 258,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": "TeX",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 7
            }
        ],
        "readme_content": "Universal function Bernoulli approximators\n================\n\n# Oblivious maps\n\nA set is an unordered collection of distinct elements, typically from\nsome implicitly understood universe. A countable set is a *finite set*\nor a *countably infinite set*. A *finite set* has a finite number of\nelements, such as\n![\\\\{ 1, 3, 5 \\\\}](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;%5C%7B%201%2C%203%2C%205%20%5C%7D \"\\{ 1, 3, 5 \\}\"),\nand a *countably infinite set* can be put in one-to-one correspondence\nwith the set of natural numbers,\n![\\\\{1,2,3,4,5,\\ldots\\\\}](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;%5C%7B1%2C2%2C3%2C4%2C5%2C%5Cldots%5C%7D \"\\{1,2,3,4,5,\\ldots\\}\").\nThe cardinality of a set\n![\\mathbb{A}](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;%5Cmathbb%7BA%7D \"\\mathbb{A}\"),\ndenoted by\n![\\|\\mathbb{A}\\|](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;%7C%5Cmathbb%7BA%7D%7C \"|\\mathbb{A}|\"),\nis a measure on the number of elements in the set, e.g.,\n![\\|\\\\{a,b\\\\}\\|=2](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;%7C%5C%7Ba%2Cb%5C%7D%7C%3D2 \"|\\{a,b\\}|=2\").\n\nA map represents a *many*-to-*one* relationship. A map that associates\nelements in\n![\\mathbb{X}](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;%5Cmathbb%7BX%7D \"\\mathbb{X}\")\nto elements in\n![\\mathbb{Y}](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;%5Cmathbb%7BY%7D \"\\mathbb{Y}\")\nhas a type denoted by\n![\\mathbb{X}\\mapsto\\mathbb{Y}](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;%5Cmathbb%7BX%7D%5Cmapsto%5Cmathbb%7BY%7D \"\\mathbb{X}\\mapsto\\mathbb{Y}\").\nFor a map of type\n![X \\mapsto Y](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;X%20%5Cmapsto%20Y \"X \\mapsto Y\"),\nwe denote\n![X](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;X \"X\")\nthe *input* and\n![Y](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;Y \"Y\")\nthe output. Typically, it is relatively easy to find which output is\nassociated with a given input, but the inverse operation, determining\nwhich inputs are associated with a given output is computationally\nharder. Of course, this is not necessarily the case, and mathematically\nthe map is just a one-to-many relation over\n![X \\times Y](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;X%20%5Ctimes%20Y \"X \\times Y\").\n\nFor instance, Table depicts a function over a finite domain of\n![n](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;n \"n\")\nelements, where each input\n![x \\in X](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;x%20%5Cin%20X \"x \\in X\")\nis associated with a single output\n![y \\in Y](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;y%20%5Cin%20Y \"y \\in Y\"),\ni.e.,\n![y = f(x)](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;y%20%3D%20f%28x%29 \"y = f(x)\").\n\nThe input does not need to be a simple set like natural numbers, but\nrather can be any type of set, such as a set of pairs as given in .\n\nSince we are interested in constructing maps in computer memory, we must\nhave some way to represent them. One technique may be given by the\nfollowing table.\n\nThe oblivious map is given by the following definition.\n\\begin{definition} The *oblivious Bernoulli map* is a specialization of\nthe Bernoulli map. We denote an oblivious map of\n![f](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;f \"f\")\nby\n![f^\\* = (f,\\mathcal{C})](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;f%5E%2A%20%3D%20%28f%2C%5Cmathcal%7BC%7D%29 \"f^* = (f,\\mathcal{C})\")\nwhere\n![\\mathcal{C}](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;%5Cmathcal%7BC%7D \"\\mathcal{C}\")\nis the subset of the computational basis of\n![f](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;f \"f\")\nwhich\n![f^\\*](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;f%5E%2A \"f^*\")\nprovides. An oblivious Bernoulli map satisifes the following conditions:\n\n-   The function\n    ![f^\\* : X \\mapsto Y](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;f%5E%2A%20%3A%20X%20%5Cmapsto%20Y \"f^* : X \\mapsto Y\")\n    is a Bernoulli map of\n    ![f](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;f \"f\").\n\n-   If an element of\n    ![x \\in X](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;x%20%5Cin%20X \"x \\in X\")\n    is not in the domain of definition,\n    ![f(x)](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;f%28x%29 \"f(x)\")\n    is a random oracle over\n    ![Y](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;Y \"Y\")\n\n-   A particular mapping\n    ![y = f^\\*(x)](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;y%20%3D%20f%5E%2A%28x%29 \"y = f^*(x)\")\n    may only be learned by applying\n    ![f^\\*](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;f%5E%2A \"f^*\")\n    to\n    ![x](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;x \"x\").\n\nIn an *oblivious map*, a mapping (row in the table) is only learned upon\nrequest.\n\nObserve that\n![f^\\*](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;f%5E%2A \"f^*\")\nis an oblivious value. Typically, we are also interested in functions in\nwhich the domain and codomain also represent oblivious values, i.e.,\n\n![f^\\* : X^\\* \\mapsto Y^\\*](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;f%5E%2A%20%3A%20X%5E%2A%20%5Cmapsto%20Y%5E%2A \"f^* : X^* \\mapsto Y^*\")\n\nwhere\n![X^\\* = (X,\\mathcal{C}\\_1)](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;X%5E%2A%20%3D%20%28X%2C%5Cmathcal%7BC%7D_1%29 \"X^* = (X,\\mathcal{C}_1)\"),\n![Y^\\* = (Y,\\mathcal{C}\\_2)](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;Y%5E%2A%20%3D%20%28Y%2C%5Cmathcal%7BC%7D_2%29 \"Y^* = (Y,\\mathcal{C}_2)\"),\nand\n![f^\\* = (f,\\mathcal{C}\\_3)](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;f%5E%2A%20%3D%20%28f%2C%5Cmathcal%7BC%7D_3%29 \"f^* = (f,\\mathcal{C}_3)\").\n\nIt may be the case that\n![X^\\*](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;X%5E%2A \"X^*\")\nis a set of oblivious integers that, say, only supports testing equality\nand addition. Of course, once we have addition, we may also implement\nmultiplication, powers, and many other operations.\n\nBy , the space complexity of the Bernoulli map with an error rate\n![\\operatorname{error\\\\\\_rate}(\\hat{f}, x)](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;%5Coperatorname%7Berror%5C_rate%7D%28%5Chat%7Bf%7D%2C%20x%29 \"\\operatorname{error\\_rate}(\\hat{f}, x)\")\nis given by the following theorem.\n## Abstract data type\n\nA *type* is a set and the elements of the set are called the *values* of\nthe type. An *abstract data type* is a type and a set of operations on\nvalues of the type. For example, the *integer* abstract data type is the\nset of all integers and a set of standard operations (computational\nbasis) such as addition, subtraction, and multiplication.\n\nA *data structure* is a particular way of organizing data and may\nimplement one or more abstract data types. An *immutable* data structure\nhas static state; once constructed, its state does not change until it\nis destroyed. Let\n![\\hat{f} : X \\mapsto Y](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;%5Chat%7Bf%7D%20%3A%20X%20%5Cmapsto%20Y \"\\hat{f} : X \\mapsto Y\")\nmodel the concept of a Bernoulli approximation of\n![f : X \\mapsto Y](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;f%20%3A%20X%20%5Cmapsto%20Y \"f : X \\mapsto Y\").\nThen,\n\n-   ![\\hat{f}(x)](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;%5Chat%7Bf%7D%28x%29 \"\\hat{f}(x)\")\n\n    Returns a value in\n    ![Y](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;Y \"Y\").\n\n-   ![\\operatorname{error\\\\\\_rate(\\hat{f},x)](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;%5Coperatorname%7Berror%5C_rate%28%5Chat%7Bf%7D%2Cx%29 \"\\operatorname{error\\_rate(\\hat{f},x)\").\n\n    Returns the *error rate* of\n    ![\\hat{f}](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;%5Chat%7Bf%7D \"\\hat{f}\")\n    applied to\n    ![x](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;x \"x\"),\n    i.e.,\n\n    ![\\Pr\\\\{\\hat{f}(x) = f(x)} = \\operatorname{error\\\\\\_rate(\\hat{f},x)](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;%5CPr%5C%7B%5Chat%7Bf%7D%28x%29%20%3D%20f%28x%29%7D%20%3D%20%5Coperatorname%7Berror%5C_rate%28%5Chat%7Bf%7D%2Cx%29 \"\\Pr\\{\\hat{f}(x) = f(x)} = \\operatorname{error\\_rate(\\hat{f},x)\")\n\n    for every\n    ![x \\in \\operatorname{dom}(f)](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;x%20%5Cin%20%5Coperatorname%7Bdom%7D%28f%29 \"x \\in \\operatorname{dom}(f)\").\n"
    },
    {
        "id": 654518689,
        "node_id": "R_kgDOJwMpoQ",
        "name": "dfr_dist",
        "full_name": "queelius/dfr_dist",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/dfr_dist",
        "description": "Dynamic failure rate distributions (DFR)",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/dfr_dist",
        "forks_url": "https://api.github.com/repos/queelius/dfr_dist/forks",
        "keys_url": "https://api.github.com/repos/queelius/dfr_dist/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/dfr_dist/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/dfr_dist/teams",
        "hooks_url": "https://api.github.com/repos/queelius/dfr_dist/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/dfr_dist/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/dfr_dist/events",
        "assignees_url": "https://api.github.com/repos/queelius/dfr_dist/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/dfr_dist/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/dfr_dist/tags",
        "blobs_url": "https://api.github.com/repos/queelius/dfr_dist/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/dfr_dist/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/dfr_dist/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/dfr_dist/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/dfr_dist/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/dfr_dist/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/dfr_dist/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/dfr_dist/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/dfr_dist/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/dfr_dist/subscription",
        "commits_url": "https://api.github.com/repos/queelius/dfr_dist/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/dfr_dist/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/dfr_dist/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/dfr_dist/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/dfr_dist/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/dfr_dist/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/dfr_dist/merges",
        "archive_url": "https://api.github.com/repos/queelius/dfr_dist/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/dfr_dist/downloads",
        "issues_url": "https://api.github.com/repos/queelius/dfr_dist/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/dfr_dist/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/dfr_dist/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/dfr_dist/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/dfr_dist/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/dfr_dist/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/dfr_dist/deployments",
        "created_at": "2023-06-16T09:56:38Z",
        "updated_at": "2023-06-16T19:10:15Z",
        "pushed_at": "2023-12-27T23:02:19Z",
        "git_url": "git://github.com/queelius/dfr_dist.git",
        "ssh_url": "git@github.com:queelius/dfr_dist.git",
        "clone_url": "https://github.com/queelius/dfr_dist.git",
        "svn_url": "https://github.com/queelius/dfr_dist",
        "homepage": "https://queelius.github.io/dfr_dist/",
        "size": 428,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": "R",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": false,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "gpl-3.0",
            "name": "GNU General Public License v3.0",
            "spdx_id": "GPL-3.0",
            "url": "https://api.github.com/licenses/gpl-3.0",
            "node_id": "MDc6TGljZW5zZTk="
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [
            "autoregressive",
            "failure-rate",
            "likelihood-functions",
            "maximum-likelihood-estimation",
            "reliability",
            "statistical-inference",
            "survival-analysis"
        ],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "main",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 13
            }
        ],
        "readme_content": "\n  - [R package `dfr.dist`: dynamic failure rate (DFR)\n    distributions](#r-package-dfrdist-dynamic-failure-rate-dfr-distributions)\n      - [Installation](#installation)\n      - [Usage](#usage)\n\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n## R package `dfr.dist`: dynamic failure rate (DFR) distributions\n\n<!-- badges: start -->\n\n<!-- badges: end -->\n\nAn R package for working with models in survival analysis in which the\ndistribution is parameterized by a very flexible failure rate function\n(any function that satisfies properties like being non-negative,\nintegrating to infinity over the domain, and having a support of `(0,\nInf)`.\n\n### Installation\n\nYou can install the development version of `dfr.dist` from GitHub repo\nwith:\n\n``` r\n# install.packages(\"devtools\")\ndevtools::install_github(\"queelius/dfr_dist\")\n```\n\n### Usage\n\nThe R packge `dfr_dist` provides an API for specifying and estimating\ndynamic failure rate distributions. They can depend on the data in any\nway, as the failure rate is any function of time and any set of\npredictors, as long as the failure rate satsifies two key properties:\n\n1.  It\u2019s non-negative. It is not meaningful to have a negative failure\n    rate; the failure rate can decrease some times, and even go to\n    ![0](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;0\n    \"0\"), though.\n\n2.  At the limit as\n    ![t](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;t\n    \"t\") goes to infinity, the cumulative hazard\n    ![H](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;H\n    \"H\") also goes to infinity:   \n    ![&#10; \\\\lim\\_{t \\\\to \\\\infty} H(t, x\\_1, \\\\ldots, x\\_p) =\n    \\\\infty,&#10;\n    ](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;%0A%20%5Clim_%7Bt%20%5Cto%20%5Cinfty%7D%20H%28t%2C%20x_1%2C%20%5Cldots%2C%20x_p%29%20%3D%20%5Cinfty%2C%0A%20%20\n    \"\n \\\\lim_{t \\\\to \\\\infty} H(t, x_1, \\\\ldots, x_p) = \\\\infty,\n  \")  \n        where ![H(t, x\\_1, \\\\ldots, x\\_p) = \\\\int\\_{0}^t h(u, x\\_1, \\\\ldots,\n    x\\_p)\n    du](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;H%28t%2C%20x_1%2C%20%5Cldots%2C%20x_p%29%20%3D%20%5Cint_%7B0%7D%5Et%20h%28u%2C%20x_1%2C%20%5Cldots%2C%20x_p%29%20du\n    \"H(t, x_1, \\\\ldots, x_p) = \\\\int_{0}^t h(u, x_1, \\\\ldots, x_p) du\").\n    If this constraint isn\u2019t satisfied, then the survival function is\n    not well-defined, since it is defined as ![S(t) =\n    \\\\exp\\\\bigl\\\\{-H(t)\\\\bigr\\\\}](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;S%28t%29%20%3D%20%5Cexp%5Cbigl%5C%7B-H%28t%29%5Cbigr%5C%7D\n    \"S(t) = \\\\exp\\\\bigl\\\\{-H(t)\\\\bigr\\\\}\").\n\nThe `dfr_dist` object satisfies all of the requirements of an algebraic\ndistribution (see `algebraic.dist`) and a likelihoood model (see\n`likelihood.model`).\n\nThe package is designed to be used with the `algebraic.mle` package,\nwhich provides a framework for performing maximum likelihood estimation\n(MLE).\n\nA vignette showing how to use it is\n[here](https://queelius.github.io/dfr_dist/articles/failure_rate.html).\n",
        "github_pages": "https://queelius.github.io/dfr_dist/"
    },
    {
        "id": 701211737,
        "node_id": "R_kgDOKcukWQ",
        "name": "disjoint_interval_set",
        "full_name": "queelius/disjoint_interval_set",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/disjoint_interval_set",
        "description": "Disjoint Interval Set (DIS)",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/disjoint_interval_set",
        "forks_url": "https://api.github.com/repos/queelius/disjoint_interval_set/forks",
        "keys_url": "https://api.github.com/repos/queelius/disjoint_interval_set/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/disjoint_interval_set/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/disjoint_interval_set/teams",
        "hooks_url": "https://api.github.com/repos/queelius/disjoint_interval_set/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/disjoint_interval_set/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/disjoint_interval_set/events",
        "assignees_url": "https://api.github.com/repos/queelius/disjoint_interval_set/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/disjoint_interval_set/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/disjoint_interval_set/tags",
        "blobs_url": "https://api.github.com/repos/queelius/disjoint_interval_set/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/disjoint_interval_set/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/disjoint_interval_set/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/disjoint_interval_set/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/disjoint_interval_set/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/disjoint_interval_set/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/disjoint_interval_set/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/disjoint_interval_set/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/disjoint_interval_set/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/disjoint_interval_set/subscription",
        "commits_url": "https://api.github.com/repos/queelius/disjoint_interval_set/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/disjoint_interval_set/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/disjoint_interval_set/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/disjoint_interval_set/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/disjoint_interval_set/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/disjoint_interval_set/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/disjoint_interval_set/merges",
        "archive_url": "https://api.github.com/repos/queelius/disjoint_interval_set/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/disjoint_interval_set/downloads",
        "issues_url": "https://api.github.com/repos/queelius/disjoint_interval_set/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/disjoint_interval_set/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/disjoint_interval_set/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/disjoint_interval_set/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/disjoint_interval_set/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/disjoint_interval_set/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/disjoint_interval_set/deployments",
        "created_at": "2023-10-06T06:58:55Z",
        "updated_at": "2024-06-11T01:48:34Z",
        "pushed_at": "2024-06-11T01:48:31Z",
        "git_url": "git://github.com/queelius/disjoint_interval_set.git",
        "ssh_url": "git@github.com:queelius/disjoint_interval_set.git",
        "clone_url": "https://github.com/queelius/disjoint_interval_set.git",
        "svn_url": "https://github.com/queelius/disjoint_interval_set",
        "homepage": null,
        "size": 11,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": "C++",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 2
            }
        ],
        "readme_content": "# Disjoint Interval Set\n\nThe Disjoint Interval Set (DIS) equipped with a few operations\nsatisfies the concept of a Boolean algebra over sets of disjoint\nintervals equipped with all the standard set-theoretic operations,\nlike intersection (*), union (+), and complement (~).\n\n## Concept: Boolean Algebra\n\nA Boolean algebra provides a powerful conceptual and mathematical framework.\nIt is a set of elements equipped with a few operations that satisfy\na few axioms. The operations are usually called union (+), intersection (*),\nand complement (~). The axioms are usually called the Boolean laws.\n\n## Constructors\n\nThe DIS supports the following constructors:\n\n- **Empty Constructor**: `disjoint_interval_set()`\n\n  Create an empty DIS.\n\n- **Constructor From Iterable**: `disjoint_interval_set(intervals)`\n\n  Create a DIS from an iterable of intervals.\n\n- **Copy Constructor**: `disjoint_interval_set(disjoint_interval_set)`\n\n  Create a copy of a DIS.\n\n## Set-Theoretic Operations\n\nThe DIS supports the following set-theoretic operations:\n\n- **Union**: `operator+(disjoint_interval_set, disjoint_interval_set)`\n\n  Create a DIS that is the union of two DIS.\n\n- **Intersection**: `operator*(disjoint_interval_set, disjoint_interval_set)`\n\n  Create a DIS that is the intersection of two DIS.\n\n- **Complement**: `operator~(disjoint_interval_set)`\n\n  Create a DIS that is the complement of a DIS.\n\n- **Set-Difference**: `operator-(disjoint_interval_set, disjoint_interval_set)`\n\n  Create a DIS that is the set difference of two DIS.\n\n- **Symmetric Difference**: `operator^(disjoint_interval_set, disjoint_interval_set)`\n\n  Create a DIS that is the symmetric difference of two DIS.\n\n## Predicates\n\nThe DIS supports the following predicates:\n\n- **Empty**: `is_empty(disjoint_interval_set)`: Check if a DIS is empty.\n\n- **Relational Predicates**: `==`, `!=`, `<`, `<=`, `>`, `>=`:\n\n  Compare two DIS for equality, inequality, subset, proper subset, superset,\n  and proper superset.\n\n  These also work with intervals and values. For example, `DIS == interval`,\n  since an interval can be considered a DIS with a single interval and a\n  value can be considered an interval with a single value, `[value, value]`.\n\n- **Set Membership**: `contains(disjoint_interval_set, value)`\n\n  Check if a DIS contains a value.\n\n## Interval Type\n\nThe DIS is parameterized by the interval type. The interval type must\nsatisfy the concept of an interval.\n\n### Interval Concept\n\nAn interval is a pair of values that satisfy the following axioms:\n\n- `infimum(interval)`: Return the infimum of the interval.\n- `supremum(interval)`: Return the supremum of the interval.\n- `contains(interval, value)`: Check if the interval contains a value."
    },
    {
        "id": 883056352,
        "node_id": "R_kgDONKJe4A",
        "name": "fuzzy-logic-search",
        "full_name": "queelius/fuzzy-logic-search",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/fuzzy-logic-search",
        "description": "Fuzzy logic search on plain documents and JSON documents.",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/fuzzy-logic-search",
        "forks_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/forks",
        "keys_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/teams",
        "hooks_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/events",
        "assignees_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/tags",
        "blobs_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/subscription",
        "commits_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/merges",
        "archive_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/downloads",
        "issues_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/fuzzy-logic-search/deployments",
        "created_at": "2024-11-04T09:55:31Z",
        "updated_at": "2024-12-10T09:10:00Z",
        "pushed_at": "2024-12-10T09:09:56Z",
        "git_url": "git://github.com/queelius/fuzzy-logic-search.git",
        "ssh_url": "git@github.com:queelius/fuzzy-logic-search.git",
        "clone_url": "https://github.com/queelius/fuzzy-logic-search.git",
        "svn_url": "https://github.com/queelius/fuzzy-logic-search",
        "homepage": "https://queelius.github.io/fuzzy-logic-search",
        "size": 11036,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": "Python",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": false,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "mit",
            "name": "MIT License",
            "spdx_id": "MIT",
            "url": "https://api.github.com/licenses/mit",
            "node_id": "MDc6TGljZW5zZTEz"
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [
            "boolean-algebra",
            "defuzzification",
            "fuzzification",
            "fuzzy-json-queries",
            "fuzzy-logic",
            "fuzzy-result-sets",
            "fuzzy-search",
            "homomorphisms"
        ],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 17
            }
        ],
        "readme_content": "# fuzzy-logic-search\n\n**fuzzy-logic-search** is an academic and practical framework for querying structured and unstructured documents using fuzzy logic principles. Unlike traditional Boolean search techniques that yield a binary match or non-match, **fuzzy-logic-search** produces a continuous score in the range [0, 1], indicating the *degree-of-membership (DoM)*\u2014or relevance\u2014of each document to the given query.\n\nThis system supports queries on both structured JSON documents and flat text files, offering a uniform fuzzy logic interface to a variety of data sources. Users can compose queries using logical operators, quantifiers, modifiers, and custom predicates that return continuous or crisp DoM values, enabling rich, human-centric querying.\n\n---\n\n## Table of Contents\n\n1. [Introduction](#introduction)  \n2. [Core Concepts](#core-concepts)  \n3. [Why Fuzzy Logic?](#why-fuzzy-logic)  \n4. [Document Models and Identity](#document-models-and-identity)  \n5. [Query Syntax and Semantics](#query-syntax-and-semantics)  \n6. [Custom Predicates and Extensibility](#custom-predicates-and-extensibility)  \n7. [Flat Document Support](#flat-document-support)  \n8. [Homomorphism: Theory and Examples](#homomorphism-theory-and-examples)  \n9. [Evaluation and Post-Processing](#evaluation-and-post-processing)  \n10. [Examples](#examples)  \n11. [Applications and Use Cases](#applications-and-use-cases)  \n12. [Future Directions](#future-directions)  \n13. [References](#references)\n\n---\n\n## Introduction\n\nConventional search often treats queries and documents as sharply delineated: a document either matches the query or it does not. Real-world reasoning, however, is often more nuanced. **fuzzy-logic-search** introduces gradation, allowing documents to match queries to varying extents. This can be crucial when dealing with heterogeneous datasets, ambiguous search terms, or user queries that are not strictly binary.\n\n---\n\n## Core Concepts\n\n1. **Fuzzy Sets**:  \n   A fuzzy set assigns to each element a membership value in [0, 1]. In **fuzzy-logic-search**, each document is assigned a degree of relevance to the query, reflecting partial matches rather than absolute inclusion or exclusion.\n\n2. **Fuzzy Operations**:  \n   Logical operators from Boolean logic (`and`, `or`, `not`) are extended using fuzzy logic. For instance:\n   - `and` \u2192 *minimum* of the membership scores,\n   - `or` \u2192 *maximum* of the membership scores,\n   - `not` \u2192 *1 minus* the membership score.\n\n3. **Linguistic Hedges (Modifiers)**:  \n   Terms like `very` and `somewhat` transform membership values. For example:\n   - `very Q` might square the DoM, emphasizing already-strong matches.\n   - `somewhat Q` might take a square root, broadening tolerance to partial matches.\n\n---\n\n## Why Fuzzy Logic?\n\nFuzzy logic better models how humans interpret queries. Instead of forcing binary decisions, it allows for degrees of satisfaction. Benefits include:\n\n- **Graduated Transitions**: Smoothly vary between full match and no match, rather than abrupt cutoffs.\n- **Complex Queries**: Easily combine multiple conditions (e.g., `(and (field age (> 25)) (field name (contains \"Smith\")))`) and produce nuanced relevance scores.\n- **Interpretability and Flexibility**: Fuzzy sets can be interpreted directly as numeric scores or, if desired, mapped back to linguistic categories (like \"very relevant\") through optional defuzzification.\n\n---\n\n## Document Models and Identity\n\n**fuzzy-logic-search** supports two primary document types:\n\n1. **Structured JSON Documents**:  \n   Each JSON document may reside in its own file or be provided programmatically as a Python dictionary. Documents are identified by:\n   - **Filename**: If loading from a file, the filename serves as the document\u2019s ID.\n   - **Hash**: If provided as a dictionary, a hash of the document is used as its ID.\n   - **Index**: If documents are provided in a list with no other identifiers, their list index is used.\n\n2. **Flat Documents (e.g., `.txt`, `.md`)**:  \n   When fields are not applicable, documents are treated as raw text. Queries default to fuzzy logic operations on content-based similarity (e.g., normalized TF-IDF scores), providing a DoM that represents how well the document\u2019s text aligns with the query terms.\n\n---\n\n## Query Syntax and Semantics\n\nQueries are represented as abstract syntax trees (ASTs), enabling complex, composable logic. For example:\n\n```lisp\n(and \n  (field x (== 1)) \n  (not (field y (startswith z))))\n```\n\nThis may parse to:\n\n```json\n[\n  \"and\",\n  [\"field\", \"x\", [\"==\", 1]],\n  [\"not\", [\"field\", \"y\", [\"startswith\", \"z\"]]]\n]\n```\n\n**Key Components**:\n- **field path**: Specifies where in a JSON document to look.\n- **predicates**: Such as `==`, `>`, `<`, `startswith`, or `contains`, yield a membership value.  \n- **logical operators**: `and`, `or`, `not` apply fuzzy logic to combine or modify conditions.\n- **modifiers**: `very`, `somewhat` and others can transform membership values.\n\n---\n\n## Custom Predicates and Extensibility\n\n**fuzzy-logic-search** is fully extensible. Users can define their own predicates with custom membership logic. While default predicates often map to crisp Boolean tests (yielding 0.0 or 1.0), advanced users can integrate domain-specific scoring functions that return continuous values.\n\nFor example, you can define a custom predicate `_similar(ob, doc)` that returns a continuous similarity measure (e.g., cosine similarity, Jaccard index, or a learned embedding distance) normalized to [0,1].\n\nHere is a snippet from the default predicate set (simplified):\n\n```python\ndef _contains(ob, doc, quant=all) -> float:\n    if isinstance(ob, list):\n        return float(quant(str(o) in str(doc) for o in ob))\n    else:\n        return float(str(ob) in str(doc))\n```\n\nThis returns 1.0 if `doc` contains `ob`, and 0.0 otherwise. Users can replace this logic or add new predicates that compute partial matches, graded similarities, or probabilistic scores.\n\n---\n\n## Flat Document Support\n\nFor flat documents without structured fields, **fuzzy-logic-search** defaults to similarity-based measures. For instance, when you query `(contains \"Smith\")` over a `.txt` file, an internal TF-IDF-based scoring mechanism might produce a relevance score proportional to the frequency and distinctiveness of `\"Smith\"` in the document. Thus, even plain text searches benefit from fuzzy logic, capturing how \"strongly\" a document matches rather than requiring an exact condition.\n\n---\n\n## Homomorphism: Theory and Examples\n\nA notable mathematical property of this system is that the mapping from queries (`Q`) to result sets (`R`) is a **homomorphism**. This means:\n\n1. Operations on queries translate directly to operations on their corresponding fuzzy result sets.\n2. If you have queries `Q1` and `Q2`, and their corresponding result sets `R1` and `R2`, then:\n   \\[\n   \\Phi(Q1 \\,\\text{and}\\, Q2) = \\Phi(Q1) \\,\\text{and}\\, \\Phi(Q2) = R1 \\cap R2\n   \\]\n   where the `and` operation on results is applied element-wise to their membership values.\n\n**Example**:  \n- Suppose `Q1(d)` assigns a relevance of 0.8 to document `d`, and `Q2(d)` assigns 0.6.  \n- `Q1 and Q2` would assign `min(0.8, 0.6) = 0.6` to `d`.  \n- Likewise, the result sets `R1` and `R2` induced by `Q1` and `Q2` would yield a result `R = R1 and R2` that has the same minimal intersection membership.\n\nThis property ensures **consistency and predictability**: whether you combine fuzzy sets at the query level or at the result level, you arrive at the same final degrees of membership.\n\n**Non-Invertibility**:  \nWhile we can map `Q` to `R`, we cannot uniquely recover `Q` from `R`. Different queries may produce identical result sets, so the process is not invertible.\n\n---\n\n## Evaluation and Post-Processing\n\nEvaluating a query `Q` over a document set `D` yields a fuzzy set `R`:\n\\[\nR = \\{(d, Q(d)) \\mid d \\in D \\}\n\\]\n\nSince both queries and results are fuzzy sets, you can post-process `R` using the same operations:\n- Apply logical operators to combine multiple result sets (`R = R1 and (not R2)`).\n- Use modifiers on results directly (`very R`), sharpening or broadening the final membership values without re-running the original queries.\n\nThis flexible architecture encourages iterative refinement, experimentation, and dynamic adjustment of search results after the initial computation.\n\n---\n\n## Examples\n\n**Simple Structured Query**:\n```lisp\n(field age (> 25))\n```\nFor a document `{\"age\": 30}`, this might yield a high membership (close to 1.0), while `{\"age\": 20}` might yield a lower membership (0.0 if crisp, or a partial score if using a graded comparison).\n\n**Compound Query**:\n```lisp\n(and\n  (field address.city (== \"New York\"))\n  (not (field age (< 25))))\n```\nThis increases membership for documents whose `address.city` closely matches `\"New York\"` and whose `age` is not less than 25, combining these conditions fuzzily.\n\n**Post-Processing**:\nIf `R1` results from `Q1`, and `R2` from `Q2`, you can form a new result set:\n```lisp\nR = very (R1 or R2)\n```\nThis applies the `or` (max) operation at the result level and then the `very` modifier to emphasize top matches.\n\n---\n\n## Applications and Use Cases\n\n- **Search Engines**: Instead of returning a binary match, yield graded results that reflect partial matches and relevance strength.\n- **Recommendation Systems**: Combine multiple user preference queries fuzzily, weighting attributes like price, popularity, and genre to produce a nuanced recommendation score.\n- **Data Analysis**: Query large JSON datasets or plain text corpora with flexible, human-like reasoning, enabling exploratory data analysis and gradual refinement of search criteria.\n\n---\n\n## Future Directions\n\n1. **Adaptive Defuzzification**: Map membership scores back to linguistic categories (e.g., \"highly relevant\", \"mildly relevant\") for user-facing explanations.\n2. **Advanced Similarity Measures**: Integrate vector-based semantic similarity or machine learning\u2013derived embeddings to produce more meaningful fuzzy matches.\n3. **Performance and Indexing**: Scale to larger datasets with indexing and caching strategies, ensuring efficiency without compromising fuzzy logic principles.\n\n---\n\n## References\n\n- Zadeh, L. A. (1965). *Fuzzy sets.* Information and Control, 8(3), 338\u2013353.\n- Klir, G. J., & Yuan, B. (1995). *Fuzzy sets and fuzzy logic: theory and applications.* Prentice Hall.\n- Zimmermann, H.-J. (1996). *Fuzzy set theory\u2014and its applications.* Springer.\n\n---\n\n**fuzzy-logic-search** offers a unified, theory-driven approach to querying documents\u2014both structured and unstructured\u2014through the lens of fuzzy logic. It encourages a more nuanced view of relevance, supports extensibility through custom predicates, and maintains a homomorphism between queries and their result sets. Ultimately, it stands as both a pedagogical tool and a practical system for modern information retrieval scenarios.",
        "github_pages": "https://queelius.github.io/fuzzy-logic-search/"
    },
    {
        "id": 847716881,
        "node_id": "R_kgDOMociEQ",
        "name": "ga-llm",
        "full_name": "queelius/ga-llm",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/ga-llm",
        "description": null,
        "fork": false,
        "url": "https://api.github.com/repos/queelius/ga-llm",
        "forks_url": "https://api.github.com/repos/queelius/ga-llm/forks",
        "keys_url": "https://api.github.com/repos/queelius/ga-llm/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/ga-llm/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/ga-llm/teams",
        "hooks_url": "https://api.github.com/repos/queelius/ga-llm/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/ga-llm/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/ga-llm/events",
        "assignees_url": "https://api.github.com/repos/queelius/ga-llm/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/ga-llm/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/ga-llm/tags",
        "blobs_url": "https://api.github.com/repos/queelius/ga-llm/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/ga-llm/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/ga-llm/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/ga-llm/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/ga-llm/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/ga-llm/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/ga-llm/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/ga-llm/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/ga-llm/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/ga-llm/subscription",
        "commits_url": "https://api.github.com/repos/queelius/ga-llm/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/ga-llm/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/ga-llm/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/ga-llm/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/ga-llm/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/ga-llm/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/ga-llm/merges",
        "archive_url": "https://api.github.com/repos/queelius/ga-llm/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/ga-llm/downloads",
        "issues_url": "https://api.github.com/repos/queelius/ga-llm/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/ga-llm/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/ga-llm/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/ga-llm/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/ga-llm/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/ga-llm/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/ga-llm/deployments",
        "created_at": "2024-08-26T12:12:03Z",
        "updated_at": "2024-08-26T12:16:58Z",
        "pushed_at": "2024-08-26T12:15:07Z",
        "git_url": "git://github.com/queelius/ga-llm.git",
        "ssh_url": "git@github.com:queelius/ga-llm.git",
        "clone_url": "https://github.com/queelius/ga-llm.git",
        "svn_url": "https://github.com/queelius/ga-llm",
        "homepage": null,
        "size": 6,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": null,
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": false,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 2
            }
        ],
        "readme_content": "# Improving Generative Model Performance using Genetic Algorithms\n\n## Abstract\n\nIn this paper, we propose a novel approach to improving the performance of generative models, including large language models (LLMs), using Genetic Algorithms (GAs). Our method iteratively refines model outputs through the evolutionary process of selection, crossover, and mutation, guided by a problem-specific fitness function. We demonstrate the effectiveness of this approach across several tasks, including text generation and reasoning, and explore the trade-offs between quality, diversity, and computational efficiency.\n\n*Keywords*: Genetic Algorithms, Language Models, Generative Models, Evolutionary Optimization\n\n## 1. Introduction\n\nThe field of generative models, particularly large language models (LLMs), has seen significant advancements in recent years. These models are capable of producing high-quality text across various tasks, from creative writing to reasoning and problem-solving. However, despite their successes, generative models can still struggle with generating optimal outputs for specific tasks. In this paper, we introduce an approach to optimize generative model performance using Genetic Algorithms (GAs).\n\nGenetic Algorithms are a class of evolutionary algorithms inspired by natural selection, where candidate solutions evolve over generations based on their fitness to a given problem. We explore how GAs can be applied to improve the quality, diversity, and adaptability of LLM-generated outputs, and provide a framework that integrates GAs with generative models.\n\n## 2. Background\n\n### 2.1 Genetic Algorithms\n\nGenetic Algorithms (GAs) are optimization techniques that simulate the process of natural evolution. The basic components of GAs include:\n\n1. **Population**: A set of candidate solutions.\n2. **Selection**: The process of choosing individuals from the population based on their fitness.\n3. **Crossover**: The combination of two or more parent solutions to create offspring.\n4. **Mutation**: The introduction of random changes to offspring.\n5. **Fitness Function**: A measure of how well a solution solves the problem.\n6. **Termination**: The criteria for stopping the algorithm, typically based on convergence or a predefined number of generations.\n\nMathematically, the optimization problem solved by GAs can be expressed as:\n\n\\[\nS^* = \\arg\\max_{S \\in \\mathcal{S}} F(S)\n\\]\n\nwhere \\( S^* \\) is the optimal solution, \\( \\mathcal{S} \\) is the set of all possible solutions, and \\( F(S) \\) is the fitness function evaluating solution \\( S \\).\n\n### 2.2 Generative Models\n\nGenerative models, particularly LLMs, have become integral in various AI tasks. These models are trained to generate new data instances based on learned patterns. While LLMs are powerful, they may not always generate optimal outputs due to limitations in training data or model architecture. The application of GAs offers a promising approach to refining and optimizing these outputs through iterative improvement.\n\n## 3. Methodology\n\n### 3.1 GA-LLM-Optimize Framework\n\nWe propose the following high-level framework for optimizing LLM outputs using Genetic Algorithms:\n\n#### Algorithm: GA-LLM-Optimize(prompt \\( P \\), model \\( M \\), population_size \\( N \\), generations \\( G \\))\n\n1. **Initialization**: Generate an initial population \\( \\text{Pop} = \\{S_1, S_2, \\dots, S_N\\} \\) where \\( S_i = M(P) \\) for \\( i = 1 \\) to \\( N \\).\n2. **Evaluation**: Calculate the fitness \\( F_i = F(S_i) \\) for each \\( S_i \\) in \\( \\text{Pop} \\).\n3. **Selection**: Select parents based on fitness using a selection strategy (e.g., tournament selection).\n4. **Crossover**: Combine selected parents to create offspring solutions.\n5. **Mutation**: Apply random mutations to some offspring.\n6. **Replacement**: Form the new population by replacing old individuals with offspring.\n7. **Termination**: Repeat steps 2-6 until termination criteria are met.\n\n\\[\nS^* = \\arg\\max_{S \\in \\text{Pop}} F(S)\n\\]\n\n### 3.2 Fitness Function Design\n\nThe fitness function \\( F(S) \\) is task-dependent and can be customized to evaluate content quality, relevance, coherence, diversity, or other criteria. We discuss several variations of fitness functions, including single-objective and multi-objective formulations.\n\n### 3.3 Genetic Operators: Crossover and Mutation\n\nWe explore different methods for crossover and mutation tailored to text generation tasks. These include:\n\n1. **Semantic Crossover**: Combining semantic elements from two parent outputs.\n2. **Prompt Mutation**: Introducing slight variations in the prompt to influence generation.\n3. **Textual Mutation**: Directly modifying words, phrases, or structures in the output.\n\n## 4. Experiments\n\n### 4.1 Experimental Setup\n\nDescribe the experimental setup, including the specific generative models, prompts, tasks, and GA parameters (e.g., population size, number of generations).\n\n### 4.2 Baselines\n\nWe compare our GA-based optimization approach against baseline generative methods, including:\n\n- Beam search\n- Random sampling\n- Fine-tuning without GA\n\n### 4.3 Metrics\n\nEvaluation metrics include:\n\n- Content quality (e.g., BLEU, ROUGE)\n- Coherence and relevance\n- Diversity\n- Computational efficiency\n\n## 5. Results\n\n### 5.1 Main Results\n\nPresent the main experimental results, including tables and figures comparing the performance of our GA-based optimization approach against baselines.\n\n\\[\n\\text{Table 1: Comparison of Quality and Diversity Metrics}\n\\]\n\n\\[\n\\text{Figure 1: Fitness over Generations}\n\\]\n\n### 5.2 Ablation Study\n\nDiscuss the results of an ablation study where different components of the GA (e.g., crossover, mutation) are removed or modified to evaluate their impact on performance.\n\n## 6. Discussion\n\n### 6.1 Advantages and Limitations\n\nWe discuss the advantages of using GAs for optimizing generative models, such as improved output quality and diversity. We also address the limitations, including computational costs and potential convergence issues.\n\n### 6.2 Future Work\n\nPotential avenues for future research include:\n\n- Scaling GAs for larger populations and longer generations\n- Exploring hybrid approaches combining GAs with reinforcement learning or fine-tuning\n- Applying this method to other domains, such as image or music generation\n\n## 7. Conclusion\n\nIn this paper, we presented a novel approach to optimizing generative model outputs using Genetic Algorithms. Our results demonstrate the potential of evolutionary techniques to enhance the performance of large language models across various tasks. We believe that this approach opens up new possibilities for fine-tuning and adapting generative models in complex environments.\n\n## References\n\n(Add references here)\n"
    },
    {
        "id": 322443867,
        "node_id": "MDEwOlJlcG9zaXRvcnkzMjI0NDM4Njc=",
        "name": "homomorphic_computational_extensions",
        "full_name": "queelius/homomorphic_computational_extensions",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/homomorphic_computational_extensions",
        "description": "Homomorphic computational extensions",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions",
        "forks_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/forks",
        "keys_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/teams",
        "hooks_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/events",
        "assignees_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/tags",
        "blobs_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/subscription",
        "commits_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/merges",
        "archive_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/downloads",
        "issues_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/homomorphic_computational_extensions/deployments",
        "created_at": "2020-12-18T00:13:12Z",
        "updated_at": "2024-08-05T15:28:46Z",
        "pushed_at": "2024-04-17T01:50:16Z",
        "git_url": "git://github.com/queelius/homomorphic_computational_extensions.git",
        "ssh_url": "git@github.com:queelius/homomorphic_computational_extensions.git",
        "clone_url": "https://github.com/queelius/homomorphic_computational_extensions.git",
        "svn_url": "https://github.com/queelius/homomorphic_computational_extensions",
        "homepage": "http://queelius.github.io/homomorphic_computational_extensions/",
        "size": 80,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": "C++",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "gpl-3.0",
            "name": "GNU General Public License v3.0",
            "spdx_id": "GPL-3.0",
            "url": "https://api.github.com/licenses/gpl-3.0",
            "node_id": "MDc6TGljZW5zZTk="
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [
            "category-theory",
            "computer-science",
            "data-types",
            "homomormphism"
        ],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "main",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 27
            }
        ],
        "readme_content": "Homomorphic computational extensions\n================\nAlex Towell\n3/5/2022\n\nWe consider homomorphisms which are based on computational concerns which are used to\ntransform inefficient or lossy computations over some original domain `T` into a\nconceptually equivalent group `T*` over a restricted set of operations.\n\nIf the original problem can be solved using these restricted operations, then we may\ntransform `T` into `T*` and efficiently perform the computations.\nSometimes, the entire solution cannot be transformed back to `T`, but the restricted\nset of functions or operations may still be sufficient, e.g., evaluating\n`a + c < b + c` even though `a+c` or `b+c` may not be in the domain of `T`.\n\nSee the [documentation](http://queelius.github.io/homomorphic_computational_extensions/)\nfor more.\n\nGiven the depth and specificity of your project, the README.md for your GitHub repository should reflect the theoretical underpinnings and overarching conceptual framework guiding the development of mathematical objects like `lg<T>`. Here's a draft that captures the essence of your work, using appropriate mathematical notation and terminology to cater to an informed audience.\n\n---\n\n# Conceptual Framework for Computational Homomorphisms\n\n## Overview\n\nThis repository explores the development and implementation of mathematical objects designed to address computational inefficiencies, precision loss, and the potential for overflow and underflow in numerical computations. Central to our approach is the application of homomorphisms from algebraic structures like rings and groups into computationally efficient domains, facilitating operations that are inherently problematic in the original computational basis.\n\n## Theoretical Foundation\n\nOur work is rooted in the mathematical concepts of **rings**, **groups**, **homomorphisms**, and **approximate algorithms**. By leveraging these foundational principles, we aim to transform operations over some domain \\(D\\) into a conceptually equivalent group \\(G\\) over a restricted set of operations. This transformation, guided by computational homomorphisms, allows for the efficient execution of operations that are either inefficient or prone to loss in the original domain.\n\n### Computational Homomorphisms\n\nGiven a type \\(T\\) that models a ring or group with operations \\(\\oplus\\) and \\(\\otimes\\), we define a transformation into a domain \\(D'\\) where these operations can be efficiently computed through a restricted computational basis \\(B\\). This transformation not only aims to preserve the algebraic structure but also to mitigate computational issues such as overflow, underflow, and significant precision loss.\n\n## Implementation of Homomorphic Objects\n\nHaving laid the theoretical foundation, here we proceed to briefly cover a few\nchoice imlementations of the concept. These impleentations are not exhaustive, but\nwork well together to demonstrate the concept and its potential.\n\n### Log Domain Implementation: `lg<T>`\n\nThe `lg<T>` class maps multiplication operations into addition within the logarithmic domain, effectively addressing computational limitations in the original domain. We simply map a value to its logarithm, and then define\na restricted computational basis for this value type. In particular, we allow for\ncomparison predicates, multiplication (which is addition under the hood), division\n(which is subtraction under the hood), and exponentiation (which is multiplication\nunder the hood).\n\nThe `lg<T>` class is designed to facilitate efficient computations by leveraging the properties of logarithms to transform multiplication operations into addition. This transformation not only mitigates the risk of overflow and underflow but also enables the use of efficient addition-based operations within the log domain.\n\n```cpp\nauto a = lg<double>(3); // store: log(3)\nauto b = lg<double>(4); // store: log(4)\nauto c = a * b // c = lg<double>{12} // store: log(3) + log(4) = log(12)\nauto d = lg<double>(100) // store: log(100)\nauto e = d / c // store: log(100) - log(12) = log(100/12) = log(8.33)\nassert(a < b)\nassert(e < d)\n```\n\nIf we have a lot of values to multiply, we can map them all to their logarithms\nand then efficiently do the equivalent computation in the log-domain. This also\navoids underflows or overflows that may occur in the original domain.\n\nTo get at the stored logarthm, we provide a method `value()`:\n\n```cpp\nauto x = a.value() // returns log(3)\n```\nThis is not normally what you want, and it may even leak the abstraction, but\nwe provide it anyway.\n\n```cpp\nstd::cout << a.value(); // outputs \"exp(\" << a.value() << \")\\n\";\n```\n\nSo, `lg<T>(x)` maps `x` to the log-domain. We can then map the result back to the\noriginal domain `T` by simply exponentiating the stored value. We provide\na conversion operator to do this: `operator T()`.\n\n```cpp\nstd::cout << a; // outputs \"exp(\" << a.value() << \")\";\nstd::cout << (double)a; // outputs 3.0\n```\n\nWe may not be able to map the value back to the original domain, although\noften we can because only the intermedate results of the computation may have\ncaused an overflow or underflow in the origional domain, but the final result\nmay not. In this case, we can simply map the final result in `lg<T>` back to\nthe original domain `T` to retrieve the exact result.\n\nWe also efficiently support exponentiation and a few other operations:\n\n```cpp\nauto f = exp(a) // f = e^a, in `a` we stored log(3), in `f` we store: exp(log(3)) = 3\n```\n\nNotice that exponentiation may result in an overflow or underflow in the\ntransformed log-domain. For instance, if we have stored the result of a very\nlarge number that doesn't fit into the origional domain but it does fit in\nthe log domain, then exponentiating it may result undoes the transformation,\nresulting in an overflow or underflow again. This is fine -- `lg<T>` is\ndesigned to make multiplication and division efficient, and it does so\nwithout causing overflows or underflows, but it does not guarantee that\nexponentiation will not cause overflows or underflows.\n\nWe can also not efficiently support addition or subtraction in the log-domain:\n\n```cpp\nauto g = a + b\n```\n\nHowe do we implement this? Conceptually, we can do the following:\n\n1. Take the exponetial of the values stored in `a` andn `b`:\n\n    `exp(log(3)) * exp(log(4)) = 3 * 4 = 12`\n\n2. Store the result: `lg<double>(12)`\n\nHowever, both step 1 and step 2 can result in overflows or underflows. We can\ndetect whether it will result in an overflow or underflow prior to\ndoing the operation, so we see that addition and subtraction are partial functions\nin the log-domain. We can still define them, but they may not be defined for\nall inputs. More importantly, even if we can do the operation without an overflow\nor underflow, it is not a very efficient operation. Thus, we have chosen to\nrestrict the computational basis of `lg<T>` to only support multiplication,\ndivision, predicates, \n\n\nWe also support logarithms and exponentiation:\n\n```cpp\nauto h = log(a) // we already store log(3) in `a`, so we store:\n                // log(log(3)) or log((double)a)\n\nauto i = exp(a) // we already store log(3) in `a`, so we store:\n                  // exp(log(3)) = (double)a.\n```\n\n### Exponential Domain Implementation: `exp<T>`\n\n\nPreviously, in `lg<T>`, we mapped `x` to `log(x)` and then defined multiplication\nin terms of `lg<T>` as addition in the log-domain. We can also map `x` to `exp(x)`\nand then define addition in terms of `expo<T>` as multiplication in the exp-domain:\n\n```cpp\nauto a = expo<double>(3); // store: exp(3)\nauto b = expo<double>(4); // store: exp(4)\nauto c = a + b // c = expo<double>{12} // store: exp(3) * exp(4)\n```\n\n### Log-Exp-Sum\n\nIf we have `lg<T>` and `exp<T>`, then we can define `log_exp_sum<T>` which is a type that\n\n\n#### Approximate Algorithms\n\nHere, we also see an opportunity to explore the development of approximate algorithms\nthat can model computations outside of its restricted computational basis \\(B\\).\nIt can do so without converting back to the original domain \\(D\\), but often with\nsome loss of precision or efficiency.\n\nIn the log-exp-sum basis, we can do so-called softmax or softmin operations, which\napproximate the maximum or minimum of a set of numbers, respectively. These operations\nare useful in machine learning and optimization algorithms, and can be computed\nefficiently in the log-exp-sum basis.\n\nWe can wrap the output of such an approximate algorithm in a type that can support estimating\nthe error of the approximation, and can be converted back to the original domain \\(D\\).\nDifferent kinds of opoerations may thus be performed on the result of this approximate\nalgorithm, such as comparing it to another value, or adding it to another value,\nwhile propagating and updating the error estimates, e.g.,\n`a < b` where either `a` or `b` is the result of the softmax operation. In this case,\nsince softmax result provides an upper bound on the maximum of the set of numbers, we\nknow that if `a` is a softmax result (and the true value of the operation is latent)\nand `b` is exact, then if `a < b` is true, then we know that the latent value of the\nsoftmax result is less than `b`, and so it should return `true` with probability of\nbeing incorrect `0` and `false` with probability of being incorrect that is a\nfuntion of the error estimate of `a`. If both `a` and `b` are softmax results, then\nboth softmax values represent latent values and the error estimate becomes more\ncomplicated, but can still be estimated.\n\nWe formalize the value of the operation `a < b` with the error estimate as a type\n`bernoulli<bool>` which we formalize elsewhere in anohher C++ library,\n`bernoulli_data_types`. See the [documentation](http://queelius.github.io/bernoulli_data_types/)\nfor more.   \n\n## Future Directions\n\nOur ongoing work will focus on expanding the library of mathematical objects and exploring their applications across various computational domains. We are particularly interested in the potential for these objects to enhance computational efficiency, precision, and robustness in fields ranging from numerical analysis to artificial intelligence.\n\n### Contributions\n\nWe welcome contributions from researchers and practitioners interested in advancing the state of computational mathematics through the exploration of homomorphic transformations and their applications. Whether through theoretical insights, new mathematical objects, or practical implementations, your contributions can help shape the future of computational efficiency and precision.\n",
        "github_pages": "https://queelius.github.io/homomorphic_computational_extensions/"
    },
    {
        "id": 363018287,
        "node_id": "MDEwOlJlcG9zaXRvcnkzNjMwMTgyODc=",
        "name": "known_plaintext_attack_time_series_analysis",
        "full_name": "queelius/known_plaintext_attack_time_series_analysis",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/known_plaintext_attack_time_series_analysis",
        "description": null,
        "fork": false,
        "url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis",
        "forks_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/forks",
        "keys_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/teams",
        "hooks_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/events",
        "assignees_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/tags",
        "blobs_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/subscription",
        "commits_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/merges",
        "archive_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/downloads",
        "issues_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/known_plaintext_attack_time_series_analysis/deployments",
        "created_at": "2021-04-30T03:43:19Z",
        "updated_at": "2023-03-18T01:31:10Z",
        "pushed_at": "2021-05-03T10:46:34Z",
        "git_url": "git://github.com/queelius/known_plaintext_attack_time_series_analysis.git",
        "ssh_url": "git@github.com:queelius/known_plaintext_attack_time_series_analysis.git",
        "clone_url": "https://github.com/queelius/known_plaintext_attack_time_series_analysis.git",
        "svn_url": "https://github.com/queelius/known_plaintext_attack_time_series_analysis",
        "homepage": null,
        "size": 11108,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": "TeX",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 3
            }
        ],
        "readme_content": "# Time series analysis of a confidentiality measure for an Encrypted search system\n\nWe derive a confidentiality measure against an adversary deploying a known-plaintext attack on the search agents Encrypted searches.\nWe perform a time series analysis on a theoretical adversary in order to derive an estimator of the forecast distribution\non the confidentiality measure, which may be used to inform policies such as when and how frequently a password change may\nbe called for to maintain a minimum level of confidentiality.\n\nkeywords: time series analysis, known-plaintext attack, encrypted search, confidentiality measure, estimation\n"
    },
    {
        "id": 630066204,
        "node_id": "R_kgDOJY4MHA",
        "name": "locus",
        "full_name": "queelius/locus",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/locus",
        "description": "Seeing how easy it is to convert an old project on Google App Engine to a modern framework with the help of ChatGPT",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/locus",
        "forks_url": "https://api.github.com/repos/queelius/locus/forks",
        "keys_url": "https://api.github.com/repos/queelius/locus/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/locus/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/locus/teams",
        "hooks_url": "https://api.github.com/repos/queelius/locus/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/locus/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/locus/events",
        "assignees_url": "https://api.github.com/repos/queelius/locus/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/locus/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/locus/tags",
        "blobs_url": "https://api.github.com/repos/queelius/locus/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/locus/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/locus/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/locus/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/locus/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/locus/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/locus/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/locus/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/locus/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/locus/subscription",
        "commits_url": "https://api.github.com/repos/queelius/locus/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/locus/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/locus/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/locus/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/locus/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/locus/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/locus/merges",
        "archive_url": "https://api.github.com/repos/queelius/locus/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/locus/downloads",
        "issues_url": "https://api.github.com/repos/queelius/locus/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/locus/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/locus/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/locus/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/locus/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/locus/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/locus/deployments",
        "created_at": "2023-04-19T15:40:35Z",
        "updated_at": "2023-04-19T15:40:35Z",
        "pushed_at": "2023-04-19T15:40:35Z",
        "git_url": "git://github.com/queelius/locus.git",
        "ssh_url": "git@github.com:queelius/locus.git",
        "clone_url": "https://github.com/queelius/locus.git",
        "svn_url": "https://github.com/queelius/locus",
        "homepage": null,
        "size": 5,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": null,
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "apache-2.0",
            "name": "Apache License 2.0",
            "spdx_id": "Apache-2.0",
            "url": "https://api.github.com/licenses/apache-2.0",
            "node_id": "MDc6TGljZW5zZTI="
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "main",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 1
            }
        ],
        "readme_content": "# locus\nSeeing how easy it is to convert an old project on Google App Engine to a modern framework with the help of ChatGPT\n"
    },
    {
        "id": 453513565,
        "node_id": "R_kgDOGwgRXQ",
        "name": "md.tools",
        "full_name": "queelius/md.tools",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/md.tools",
        "description": "Masked data tools",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/md.tools",
        "forks_url": "https://api.github.com/repos/queelius/md.tools/forks",
        "keys_url": "https://api.github.com/repos/queelius/md.tools/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/md.tools/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/md.tools/teams",
        "hooks_url": "https://api.github.com/repos/queelius/md.tools/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/md.tools/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/md.tools/events",
        "assignees_url": "https://api.github.com/repos/queelius/md.tools/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/md.tools/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/md.tools/tags",
        "blobs_url": "https://api.github.com/repos/queelius/md.tools/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/md.tools/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/md.tools/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/md.tools/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/md.tools/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/md.tools/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/md.tools/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/md.tools/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/md.tools/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/md.tools/subscription",
        "commits_url": "https://api.github.com/repos/queelius/md.tools/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/md.tools/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/md.tools/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/md.tools/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/md.tools/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/md.tools/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/md.tools/merges",
        "archive_url": "https://api.github.com/repos/queelius/md.tools/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/md.tools/downloads",
        "issues_url": "https://api.github.com/repos/queelius/md.tools/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/md.tools/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/md.tools/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/md.tools/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/md.tools/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/md.tools/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/md.tools/deployments",
        "created_at": "2022-01-29T20:41:28Z",
        "updated_at": "2024-06-15T19:48:07Z",
        "pushed_at": "2023-07-22T09:31:06Z",
        "git_url": "git://github.com/queelius/md.tools.git",
        "ssh_url": "git@github.com:queelius/md.tools.git",
        "clone_url": "https://github.com/queelius/md.tools.git",
        "svn_url": "https://github.com/queelius/md.tools",
        "homepage": "https://queelius.github.io/md.tools/",
        "size": 790,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": "R",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "other",
            "name": "Other",
            "spdx_id": "NOASSERTION",
            "url": null,
            "node_id": "MDc6TGljZW5zZTA="
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 34
            }
        ],
        "readme_content": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# R package: `md.tools`\n\n<!-- badges: start -->\n<!-- badges: end -->\n\nA miscellaneous set of tools for working with *masked data* and common\nfeatures of masked data. The tool set takes inspiration from functional\nprogramming, with inputs and outputs defined over masked data frames of\ntype `tbl_md` (or just data frames), making it consistent with the\n*tidyverse* way of doing things.\n\nWe provide a set of simple functions on masked data frames, which may be\nused to compose more complicated functions, particularly when using the\npipe operator `%>%`.\n\n#### Installation\n\nYou can install the development version of `md.tools` from\n[GitHub](https://github.com/queelius/md.tools) with:\n\n``` r\n# install.packages(\"devtools\")\n#devtools::install_github(\"queelius/md.tools\")\n```\n\nWe load the libraries `md.tools` and `tidyverse` with:\n\n``` r\nlibrary(tidyverse)\nlibrary(md.tools)\n```\n\n## Matrices\n\nA lot of space in `md.tools` is devoted to working with matrices encoded\nin the columns of data frames. We could directly store matrices in a\ncolumn, but we prefer to work with columns defined over primitive types\nlike `boolean`.\n\nConsider the `boolean` matrix `C` of size `10`-by-`3`:\n\n``` r\nn <- 5\nm <- 3\nC <- matrix(sample(c(T,F), size=m*n, replace=TRUE), nrow=n)\n```\n\nWe may represent this in a data frame of 5 rows with the columns `c1`,\n`c2`, and `c3` with:\n\n``` r\nmd <- md_encode_matrix(C,\"c\")\nprint(md)\n#> # A tibble: 5 \u00d7 3\n#>   c1    c2    c3   \n#>   <lgl> <lgl> <lgl>\n#> 1 FALSE TRUE  TRUE \n#> 2 TRUE  TRUE  TRUE \n#> 3 TRUE  TRUE  TRUE \n#> 4 FALSE FALSE FALSE\n#> 5 FALSE FALSE FALSE\n```\n\nWe may also decode a matrix stored in a data frame with:\n\n``` r\nprint(all(C == md_decode_matrix(md,\"c\")))\n#> [1] TRUE\n```\n\nWe may want to work with a Boolean matrix as a list. The function\n`md_boolean_matrix_to_list` uses the following transformation:\n\nIf we have a $n$-by-$m$ Boolean matrix, then if the $(j,k)$-element is\n`TRUE`, the $j$-th vector in the list contains the integer $k$.\n\nWe can show the `md` with the candidate set as a set of integers with:\n\n``` r\nmd %>% md_boolean_matrix_to_charsets(\"c\", \"candidate set\")\n#> # A tibble: 5 \u00d7 4\n#>   c1    c2    c3    `candidate set`\n#>   <lgl> <lgl> <lgl> <chr>          \n#> 1 FALSE TRUE  TRUE  {2, 3}         \n#> 2 TRUE  TRUE  TRUE  {1, 2, 3}      \n#> 3 TRUE  TRUE  TRUE  {1, 2, 3}      \n#> 4 FALSE FALSE FALSE {}             \n#> 5 FALSE FALSE FALSE {}\n```\n\nWe allow converting between three representations: lists of integer\nvectors, Boolean vectors, and lists of charsets (sets represented with\nstrings, e.g., \u201c{ 1, 2 }\u201d. Thus, the inverse of\n`md_boolean_matrix_to_list` is just `md_list_to_boolean_matrix` and so\non.\n\n## Decorators\n\nWe now consider some data frame transformations that adds additional\ncolumns with information that may be inferred from what is already in\nthe data frame. For this reason, we have chosen to call them\n*decorators*.\n\nIn a masked data frame, we may have a column `k` that stores the failed\ncomponent. We simulate failed components and mark them as *latent* with:\n\n``` r\nmd <- md %>%\n  mutate(k=sample(1:m,n,replace=TRUE)) %>%\n  md_mark_latent(\"k\")\nprint(md)\n#> Latent variables:  k \n#> # A tibble: 5 \u00d7 4\n#>   c1    c2    c3        k\n#>   <lgl> <lgl> <lgl> <int>\n#> 1 FALSE TRUE  TRUE      1\n#> 2 TRUE  TRUE  TRUE      1\n#> 3 TRUE  TRUE  TRUE      2\n#> 4 FALSE FALSE FALSE     3\n#> 5 FALSE FALSE FALSE     3\n```\n\nWe may additionally have a candidate set encoded by the Boolean columns\n`c1`,\u2026,`cm`, in which case we may infer whether the candidate set\n*contains* the failed component `k` with:\n\n``` r\nmd <- md %>% md_set_contains(\"c\", \"k\", \"contains\")\nprint(md)\n#> Latent variables:  k \n#> # A tibble: 5 \u00d7 5\n#>   c1    c2    c3        k contains\n#>   <lgl> <lgl> <lgl> <int> <lgl>   \n#> 1 FALSE TRUE  TRUE      1 FALSE   \n#> 2 TRUE  TRUE  TRUE      1 TRUE    \n#> 3 TRUE  TRUE  TRUE      2 TRUE    \n#> 4 FALSE FALSE FALSE     3 FALSE   \n#> 5 FALSE FALSE FALSE     3 FALSE\n```\n\nWe see that there is a new column, `contains`, that tells us whether the\ncandidate set actually contains the failed component. No new information\nis given by this column, it only presents what information that is\nalready there in a potentially more conventient format.\n\nGiven the same data frame and candidate set, we may determine the\n*cardinality* of the candidate sets with:\n\n``` r\nmd <- md %>% md_set_size(\"c\")\nprint(md)\n#> Latent variables:  k \n#> # A tibble: 5 \u00d7 6\n#>   c1    c2    c3        k contains size_c\n#>   <lgl> <lgl> <lgl> <int> <lgl>     <int>\n#> 1 FALSE TRUE  TRUE      1 FALSE         2\n#> 2 TRUE  TRUE  TRUE      1 TRUE          3\n#> 3 TRUE  TRUE  TRUE      2 TRUE          3\n#> 4 FALSE FALSE FALSE     3 FALSE         0\n#> 5 FALSE FALSE FALSE     3 FALSE         0\n```\n\nWe may *unmark* a column variable as latent with:\n\n``` r\nmd <- md %>% md_unmark_latent(\"k\")\nprint(md)\n#> # A tibble: 5 \u00d7 6\n#>   c1    c2    c3        k contains size_c\n#>   <lgl> <lgl> <lgl> <int> <lgl>     <int>\n#> 1 FALSE TRUE  TRUE      1 FALSE         2\n#> 2 TRUE  TRUE  TRUE      1 TRUE          3\n#> 3 TRUE  TRUE  TRUE      2 TRUE          3\n#> 4 FALSE FALSE FALSE     3 FALSE         0\n#> 5 FALSE FALSE FALSE     3 FALSE         0\n```\n\nThe latent variable specification is metadata about the masked data\nframe, but it does not necessarily impose any requirements on algorithms\napplied to it.\n\nMore generally, a masked data frame may have a lot more metadata about\nit, and we provide some tools for working with them. However, for the\nmost part, you are expected to handle the metadata yourself. The\nmetadata is stored in the *attributes*, and so underneath the hood, a\nmasked data frame is just a data frame and may be treated as one.\n\n## Metadata\n\nTo read and write data frames for sharing with others, including\nyourself, we prefer to work with plaintext files like CSV files, where\neach row corresponds to some set of measurements of some experimental\nunit.\n\nHowever, we may also want to store *metadata* about the experiment that\ngenerated the data, or we may wish to store more information about the\nexperimental units that does not naturally fit into the data frame\nmodel.\n\nTo store metadata, we take the general approach of storing JSON\n(Javscript Object Notation) in the *comments* of the tabular data file\n(like CSV), where a comment by default is anything after the `#`\ncharacter on a line.\n\n``` r\ndata <- md_read_csv_with_meta(\"./data-raw/exp_series_md_1.csv\")\n#> Rows: 1000 Columns: 8\n#> \u2500\u2500 Column specification \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n#> Delimiter: \",\"\n#> dbl (5): t, k, t1, t2, t3\n#> lgl (3): x1, x2, x3\n#> \n#> \u2139 Use `spec()` to retrieve the full column specification for this data.\n#> \u2139 Specify the column types or set `show_col_types = FALSE` to quiet this message.\nprint(data)\n#> Latent variables:  k t1 t2 t3 \n#> # A tibble: 1,000 \u00d7 8\n#>          t     k      t1      t2     t3 x1    x2    x3   \n#>      <dbl> <dbl>   <dbl>   <dbl>  <dbl> <lgl> <lgl> <lgl>\n#>  1 0.144       2 0.281   0.144   0.266  TRUE  TRUE  FALSE\n#>  2 0.0105      1 0.0105  0.0141  0.0633 TRUE  FALSE TRUE \n#>  3 0.0363      2 0.105   0.0363  0.545  TRUE  TRUE  FALSE\n#>  4 0.00972     1 0.00972 0.251   0.0960 TRUE  FALSE TRUE \n#>  5 0.0377      3 0.0937  0.0943  0.0377 TRUE  FALSE TRUE \n#>  6 0.0958      3 0.283   0.391   0.0958 FALSE TRUE  TRUE \n#>  7 0.169       3 0.197   1.01    0.169  FALSE TRUE  TRUE \n#>  8 0.270       3 0.322   0.371   0.270  FALSE TRUE  TRUE \n#>  9 0.299       3 0.390   0.401   0.299  TRUE  FALSE TRUE \n#> 10 0.00794     2 0.524   0.00794 0.120  FALSE TRUE  TRUE \n#> # \u2139 990 more rows\n```\n\nWe may view all of the metadata stored in `data` with:\n\n``` r\nmeta <- attributes(data)\nmeta[\"row.names\"] <- NULL\nprint(meta)\n#> $class\n#> [1] \"tbl_md\"     \"tbl_df\"     \"tbl\"        \"data.frame\"\n#> \n#> $names\n#> [1] \"t\"  \"k\"  \"t1\" \"t2\" \"t3\" \"x1\" \"x2\" \"x3\"\n#> \n#> $comment\n#> [1] \"this is a simulation test.\"\n#> \n#> $param\n#> [1] 3 4 5\n#> \n#> $components\n#>        family param\n#> 1 exponential     3\n#> 2 exponential     4\n#> 3 exponential     5\n#> \n#> $candidate_conditions\n#> [1] \"C1\" \"C2\" \"C3\"\n#> \n#> $latent\n#> [1] \"k\"  \"t1\" \"t2\" \"t3\"\n#> \n#> $observable\n#> [1] \"t\"  \"x1\" \"x2\" \"x3\"\n#> \n#> $num_comp\n#> [1] 3\n#> \n#> $sample_size\n#> [1] 1000\n```\n\nNote that we removed the `row.names` attribute, since it\u2019s quite long\nand uninformative.\n\nA lot of the metadata for `data` has to do with how the data was\ngenerated. In particular, we see this data is the result of a simulation\nfor a series system with $3$ exponentially distributed component\nlifetimes parameterized by $\\lambda = (3,4,5)'$ and a candidate model\nconsistent with conditions $C_1$, $C_2$, and $C_3$ for series systems\nwith a masked component cause of failure in the form of candidate sets.\n",
        "github_pages": "https://queelius.github.io/md.tools/"
    },
    {
        "id": 732414436,
        "node_id": "R_kgDOK6fB5A",
        "name": "papers",
        "full_name": "queelius/papers",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/papers",
        "description": "latent-data",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/papers",
        "forks_url": "https://api.github.com/repos/queelius/papers/forks",
        "keys_url": "https://api.github.com/repos/queelius/papers/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/papers/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/papers/teams",
        "hooks_url": "https://api.github.com/repos/queelius/papers/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/papers/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/papers/events",
        "assignees_url": "https://api.github.com/repos/queelius/papers/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/papers/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/papers/tags",
        "blobs_url": "https://api.github.com/repos/queelius/papers/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/papers/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/papers/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/papers/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/papers/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/papers/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/papers/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/papers/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/papers/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/papers/subscription",
        "commits_url": "https://api.github.com/repos/queelius/papers/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/papers/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/papers/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/papers/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/papers/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/papers/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/papers/merges",
        "archive_url": "https://api.github.com/repos/queelius/papers/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/papers/downloads",
        "issues_url": "https://api.github.com/repos/queelius/papers/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/papers/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/papers/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/papers/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/papers/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/papers/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/papers/deployments",
        "created_at": "2023-12-16T15:45:27Z",
        "updated_at": "2024-09-22T19:13:10Z",
        "pushed_at": "2024-09-22T19:13:07Z",
        "git_url": "git://github.com/queelius/papers.git",
        "ssh_url": "git@github.com:queelius/papers.git",
        "clone_url": "https://github.com/queelius/papers.git",
        "svn_url": "https://github.com/queelius/papers",
        "homepage": null,
        "size": 1289,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": "TeX",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": false,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 30
            }
        ],
        "readme_content": "# Collection of Unfinished Papers\n\n"
    },
    {
        "id": 389302251,
        "node_id": "MDEwOlJlcG9zaXRvcnkzODkzMDIyNTE=",
        "name": "prob.4.2.comp.stats",
        "full_name": "queelius/prob.4.2.comp.stats",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/prob.4.2.comp.stats",
        "description": null,
        "fork": false,
        "url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats",
        "forks_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/forks",
        "keys_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/teams",
        "hooks_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/events",
        "assignees_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/tags",
        "blobs_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/subscription",
        "commits_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/merges",
        "archive_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/downloads",
        "issues_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/prob.4.2.comp.stats/deployments",
        "created_at": "2021-07-25T08:49:08Z",
        "updated_at": "2021-07-26T12:48:46Z",
        "pushed_at": "2021-07-26T12:48:43Z",
        "git_url": "git://github.com/queelius/prob.4.2.comp.stats.git",
        "ssh_url": "git@github.com:queelius/prob.4.2.comp.stats.git",
        "clone_url": "https://github.com/queelius/prob.4.2.comp.stats.git",
        "svn_url": "https://github.com/queelius/prob.4.2.comp.stats",
        "homepage": null,
        "size": 300,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": "R",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "gpl-3.0",
            "name": "GNU General Public License v3.0",
            "spdx_id": "GPL-3.0",
            "url": "https://api.github.com/licenses/gpl-3.0",
            "node_id": "MDc6TGljZW5zZTk="
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "main",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 12
            }
        ],
        "readme_content": "# Problem 4.2 - Computational Statistics\n"
    },
    {
        "id": 621201276,
        "node_id": "R_kgDOJQbHfA",
        "name": "problem_sets",
        "full_name": "queelius/problem_sets",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/problem_sets",
        "description": null,
        "fork": false,
        "url": "https://api.github.com/repos/queelius/problem_sets",
        "forks_url": "https://api.github.com/repos/queelius/problem_sets/forks",
        "keys_url": "https://api.github.com/repos/queelius/problem_sets/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/problem_sets/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/problem_sets/teams",
        "hooks_url": "https://api.github.com/repos/queelius/problem_sets/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/problem_sets/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/problem_sets/events",
        "assignees_url": "https://api.github.com/repos/queelius/problem_sets/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/problem_sets/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/problem_sets/tags",
        "blobs_url": "https://api.github.com/repos/queelius/problem_sets/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/problem_sets/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/problem_sets/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/problem_sets/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/problem_sets/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/problem_sets/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/problem_sets/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/problem_sets/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/problem_sets/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/problem_sets/subscription",
        "commits_url": "https://api.github.com/repos/queelius/problem_sets/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/problem_sets/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/problem_sets/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/problem_sets/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/problem_sets/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/problem_sets/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/problem_sets/merges",
        "archive_url": "https://api.github.com/repos/queelius/problem_sets/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/problem_sets/downloads",
        "issues_url": "https://api.github.com/repos/queelius/problem_sets/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/problem_sets/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/problem_sets/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/problem_sets/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/problem_sets/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/problem_sets/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/problem_sets/deployments",
        "created_at": "2023-03-30T07:33:06Z",
        "updated_at": "2023-03-30T07:58:45Z",
        "pushed_at": "2023-03-30T08:01:28Z",
        "git_url": "git://github.com/queelius/problem_sets.git",
        "ssh_url": "git@github.com:queelius/problem_sets.git",
        "clone_url": "https://github.com/queelius/problem_sets.git",
        "svn_url": "https://github.com/queelius/problem_sets",
        "homepage": null,
        "size": 472679,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": "Mathematica",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "gpl-3.0",
            "name": "GNU General Public License v3.0",
            "spdx_id": "GPL-3.0",
            "url": "https://api.github.com/licenses/gpl-3.0",
            "node_id": "MDc6TGljZW5zZTk="
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "main",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 3
            }
        ],
        "readme_content": "# problem_sets"
    },
    {
        "id": 338903937,
        "node_id": "MDEwOlJlcG9zaXRvcnkzMzg5MDM5Mzc=",
        "name": "queelius",
        "full_name": "queelius/queelius",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/queelius",
        "description": "Config files for my GitHub profile.",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/queelius",
        "forks_url": "https://api.github.com/repos/queelius/queelius/forks",
        "keys_url": "https://api.github.com/repos/queelius/queelius/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/queelius/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/queelius/teams",
        "hooks_url": "https://api.github.com/repos/queelius/queelius/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/queelius/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/queelius/events",
        "assignees_url": "https://api.github.com/repos/queelius/queelius/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/queelius/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/queelius/tags",
        "blobs_url": "https://api.github.com/repos/queelius/queelius/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/queelius/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/queelius/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/queelius/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/queelius/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/queelius/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/queelius/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/queelius/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/queelius/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/queelius/subscription",
        "commits_url": "https://api.github.com/repos/queelius/queelius/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/queelius/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/queelius/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/queelius/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/queelius/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/queelius/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/queelius/merges",
        "archive_url": "https://api.github.com/repos/queelius/queelius/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/queelius/downloads",
        "issues_url": "https://api.github.com/repos/queelius/queelius/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/queelius/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/queelius/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/queelius/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/queelius/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/queelius/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/queelius/deployments",
        "created_at": "2021-02-14T21:17:44Z",
        "updated_at": "2024-05-31T14:36:27Z",
        "pushed_at": "2024-05-20T04:10:57Z",
        "git_url": "git://github.com/queelius/queelius.git",
        "ssh_url": "git@github.com:queelius/queelius.git",
        "clone_url": "https://github.com/queelius/queelius.git",
        "svn_url": "https://github.com/queelius/queelius",
        "homepage": "https://github.com/queelius",
        "size": 10,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": null,
        "has_issues": false,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": false,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [
            "config",
            "github-config"
        ],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "main",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 5
            }
        ],
        "readme_content": "- I\u2019m Alex Towell and I can be reached at lex@metafunctor.com.\n- I have two masters degrees from SIUE: Computer Science and Mathematics/Statistics.\n- I\u2019m interested encrypted search and homomorphic encryption, oblivious and probabilitistic data structures and algorithms, machine learning and statistics, AI, and programming.\n- I\u2019m looking to collaborate on papers (some partially complete). Here are some ideas, but I'm open to other opportunities:\n  * Oblivious, privacy-preserving algebraic data types for confidential computation on untrusted systems, with analysis informed by information and probability theory. The data types are algebraic in nature because I have been researching ways to compose them to facilitate building larger oblivious programs from smaller oblivious components, the essence of programming.\n  * Probabilistic algorithms and probabilistic algebraic data types primarily concerned with specifying a type of approximation error (normally due to rate distortion) which I tentatively refer to as the Bernoulli Model.\n    * Probabilistic data structures that model set-indicator functions, like the Bloom filter, are a well-known special case, but I seek to significantly generalize the results and propagate information about the approximation error through a family of monadic constructions.\n    * I have been pursuing derivations of the expected lower-bounds on the space complexity of these approximate Bernoulli types in addition to practical near-optimal data structures that model them.\n    * Related to my Computer Science thesis, I have also applied the above results to an approximate Boolean algebra for encrypted search.\n  * Reliability engineering and applying statistical inference and learning to predict likely breakdowns (and its causes) of critical systems.\n    * It concerns reliability theory and my publication titled \"Estimating how confidential encrypted searches are using moving average bootstrap method\" concerns reliability engineering.\n    * My master's paper \"Reliability Estimation in Series Systems: Maximum Likelihood Techniques for Right-Censored and Masked Failure Data\" is also related.\n  * An information-theoretic model of an optimal adversary (provides a lower-bound on confidientiality in some cases) who, with some probability of success, compromises the confidentiality of an encrypted search system by observing a time series of inputs and outputs.\n  * Decentralized \"trust machines\" (technological solutions to securing trust that does not rely on central authorities), Research on oblivious, privacy-preserving computations is one of the tools in automating trust, but I'm also interested in technologies like Blockchain.\n\n<!---\nqueelius/queelius is a \u2728 special \u2728 repository because its `README.md` (this file) appears on your GitHub profile.\nYou can click the Preview link to take a look at your changes.\n--->\n"
    },
    {
        "id": 529838635,
        "node_id": "R_kgDOH5SyKw",
        "name": "queelius.github.io",
        "full_name": "queelius/queelius.github.io",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/queelius.github.io",
        "description": "queelius.github.io",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/queelius.github.io",
        "forks_url": "https://api.github.com/repos/queelius/queelius.github.io/forks",
        "keys_url": "https://api.github.com/repos/queelius/queelius.github.io/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/queelius.github.io/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/queelius.github.io/teams",
        "hooks_url": "https://api.github.com/repos/queelius/queelius.github.io/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/queelius.github.io/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/queelius.github.io/events",
        "assignees_url": "https://api.github.com/repos/queelius/queelius.github.io/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/queelius.github.io/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/queelius.github.io/tags",
        "blobs_url": "https://api.github.com/repos/queelius/queelius.github.io/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/queelius.github.io/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/queelius.github.io/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/queelius.github.io/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/queelius.github.io/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/queelius.github.io/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/queelius.github.io/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/queelius.github.io/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/queelius.github.io/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/queelius.github.io/subscription",
        "commits_url": "https://api.github.com/repos/queelius/queelius.github.io/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/queelius.github.io/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/queelius.github.io/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/queelius.github.io/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/queelius.github.io/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/queelius.github.io/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/queelius.github.io/merges",
        "archive_url": "https://api.github.com/repos/queelius/queelius.github.io/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/queelius.github.io/downloads",
        "issues_url": "https://api.github.com/repos/queelius/queelius.github.io/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/queelius.github.io/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/queelius.github.io/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/queelius.github.io/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/queelius.github.io/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/queelius.github.io/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/queelius.github.io/deployments",
        "created_at": "2022-08-28T11:12:14Z",
        "updated_at": "2023-06-28T02:34:23Z",
        "pushed_at": "2023-06-21T22:48:20Z",
        "git_url": "git://github.com/queelius/queelius.github.io.git",
        "ssh_url": "git@github.com:queelius/queelius.github.io.git",
        "clone_url": "https://github.com/queelius/queelius.github.io.git",
        "svn_url": "https://github.com/queelius/queelius.github.io",
        "homepage": "https://queelius.github.io/",
        "size": 5,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": null,
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "main",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 7
            }
        ],
        "readme_content": "# Queelius's GitHub Page \ud83d\udc4b\n\nHello! I'm Alex Towell, a Computer Science Master from SIUE, currently deepening my knowledge in Statistics. With a keen interest in everything from AI/ML/LLM and Encryption to Programming Language Design, I am consistently exploring new frontiers in technology.\n\n## My Interests\n- AI/ML/LLM\n- Encrypted Search & Homomorphic Encryption\n- Encryption and Cryptographic Hashing\n- Oblivious and Probabilistic Data Structures & Algorithms\n- Statistical Modeling and Probabilistic Programming\n- Reliability Engineering\n- Programming Language Design\n\n## Projects\nI'm always working on projects to explore new ideas and technologies.\nYou can find a comprehensive list and detailed information about my projects over at [metafunctor.com](https://metafunctor.com/#projects) or by looking at\nmy GitHub [repo](https://github.com/queelius).\n\n## Contact\nInterested in discussing a project, collaboration, or just want to chat? Feel free to reach me at lex@metafunctor.com or visit my website [metafunctor.com](https://www.metafunctor.com) to know more about me and my work.\n",
        "github_pages": "https://queelius.github.io/queelius.github.io/"
    },
    {
        "id": 801229804,
        "node_id": "R_kgDOL8HL7A",
        "name": "random_oracles",
        "full_name": "queelius/random_oracles",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/random_oracles",
        "description": "Cryptographic Hash Functions,, Random Oracles, and Lazy Computation",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/random_oracles",
        "forks_url": "https://api.github.com/repos/queelius/random_oracles/forks",
        "keys_url": "https://api.github.com/repos/queelius/random_oracles/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/random_oracles/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/random_oracles/teams",
        "hooks_url": "https://api.github.com/repos/queelius/random_oracles/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/random_oracles/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/random_oracles/events",
        "assignees_url": "https://api.github.com/repos/queelius/random_oracles/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/random_oracles/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/random_oracles/tags",
        "blobs_url": "https://api.github.com/repos/queelius/random_oracles/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/random_oracles/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/random_oracles/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/random_oracles/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/random_oracles/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/random_oracles/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/random_oracles/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/random_oracles/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/random_oracles/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/random_oracles/subscription",
        "commits_url": "https://api.github.com/repos/queelius/random_oracles/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/random_oracles/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/random_oracles/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/random_oracles/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/random_oracles/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/random_oracles/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/random_oracles/merges",
        "archive_url": "https://api.github.com/repos/queelius/random_oracles/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/random_oracles/downloads",
        "issues_url": "https://api.github.com/repos/queelius/random_oracles/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/random_oracles/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/random_oracles/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/random_oracles/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/random_oracles/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/random_oracles/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/random_oracles/deployments",
        "created_at": "2024-05-15T20:40:25Z",
        "updated_at": "2024-11-01T20:46:45Z",
        "pushed_at": "2024-11-01T20:46:42Z",
        "git_url": "git://github.com/queelius/random_oracles.git",
        "ssh_url": "git@github.com:queelius/random_oracles.git",
        "clone_url": "https://github.com/queelius/random_oracles.git",
        "svn_url": "https://github.com/queelius/random_oracles",
        "homepage": "",
        "size": 22,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": "Python",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": false,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 5
            }
        ],
        "readme_content": "# Introduction to Cryptographic Hash Functions and Random Oracles\n\nIn this module, we explore the fundamental concepts of hash functions, random oracles, and lazy computation. These concepts are pivotal in the fields of cryptography and theoretical computer science, offering a robust foundation for understanding secure communications and data integrity. Through a series of Python classes, we simulate behaviors and properties that, while often theoretical, provide deep insights into the practical applications of these abstract concepts.\n\n## Cryptographic Hash Functions\n\nA **cryptographic hash function** is a mathematical algorithm that converts an arbitrary block of data into a fixed-size bit string, known as a *digest*. The ideal hash function has several important properties:\n\n- **Deterministic:** The same input always produces the same output.\n- **Quick computation:** The function generates the output quickly.\n- **Pre-image resistance:** Given a hash output, it should be computationally infeasible to reverse it to find the original input.\n- **Avalanche effect:** Small changes in the input drastically change the output.\n- **Collision-resistant:** It should be difficult to find two different inputs that produce the same output.\n\nMathematically, a hash function can be represented as:\n\n$$\n\\text{hash} : \\\\{0,1\\\\}^* \\rightarrow \\\\{0,1\\\\}^n\n$$\n\n### Collision Resistance\n\nA well-designed cryptographic hash function with an output length of \\( n \\) bits has a collision probability of approximately \\( \\frac{1}{2^n} \\). For a random oracle, given its infinite output space, the probability of collision is zero. When truncated to \\( n \\) bits, the random oracle behaves similarly to a cryptographic hash function in terms of collision resistance.\n\nThe following Python class represents the general structure of a digest object, encapsulating these properties:\n\n```python\nclass Digest:\n    def __init__(self, digest):\n        self._digest = bytes.fromhex(digest) if isinstance(digest, str) else digest\n\n    def digest(self):\n        return self._digest\n\n    def hexdigest(self):\n        return self.digest().hex()\n```\n\n## Random Oracles\n\nThe **random oracle model** is an abstract machine used to study the security of cryptographic protocols. It assumes the existence of a random oracle that provides truly random responses to every unique query. In practice, random oracles are simulated using hash functions, albeit imperfectly.\n\nMathematically, a random oracle can be represented as:\n\n$$\n\\text{oracle} : \\\\{0,1\\\\}^* \\rightarrow \\\\{0,1\\\\}^\\infty\n$$\n\nA `RandomOracleDigest` is conceptualized in our Python framework to mimic this behavior:\n\n```python\nclass OracleDigest(Digest):\n    def __init__(self, input, entropy=None):\n        super().__init__(input)\n        if entropy is None:\n            entropy = lambda : hashlib.sha256(os.urandom(32)).digest()\n        self.entropy = entropy\n        self.cache = {}\n\n    def __getitem__(self, index):\n        if index not in self.cache:\n            self.cache[index] = self.entropy()[0]\n        return self.cache[index]\n```\n\n## Lazy Computation and Infinite Digests\n\n**Lazy computation** refers to the programming strategy of delaying the calculation of a value until it is needed. This concept is particularly useful in dealing with theoretically infinite outputs on finite machines. One can even define an algebra over the data structure, such as `truncate` and, `apply`, and so on. However, note that operations like `concat` are restricted to left-hand-side being finite and right-hand-side being potentially infinite. Essentially, any operation that does not require acccess or modification with respect to the right-hand-side is allowed.\n\nIn our framework, `LazyDigest` generates infinite outputs based on a seed value and a hash function, allowing the digest to be computed on demand:\n\n```python\nclass LazyDigest(Digest):\n    def __init__(self, seed, hash_fn=hashlib.sha256):\n        super().__init__(seed)\n        self.hash_fn = hash_fn\n\n    def __getitem__(self, index):\n        h = self.hash_fn()\n        h.update(self.digest())\n        h.update(str(index).encode('utf-8'))\n        return h.digest()[0]\n```\n\nThrough this exploration, we aim to demystify these complex ideas and illustrate their practical implications using Python, providing an interactive and engaging learning experience.\n\n## Detailed Class Explanations\n\n### Digest Class\n\nThe `Digest` class serves as the foundational component in our framework, abstracting the functionality of a cryptographic hash function's output. This class encapsulates the digest operations, providing a unified interface regardless of the hash function used.\n\n```python\nclass Digest:\n    def __init__(self, digest):\n        \"\"\"\n        Initialize with the given digest.\n        \"\"\"\n        self._digest = bytes.fromhex(digest) if isinstance(digest, str) else digest\n\n    def digest(self):\n        \"\"\"\n        Get the digest as a bytes object.\n        \"\"\"\n        return self._digest\n\n    def hexdigest(self):\n        \"\"\"\n        Get the digest as a hex string.\n        \"\"\"\n        return self.digest().hex()\n```\n\n- **Initialization:** The constructor accepts a digest, which can be either a hexadecimal string or a bytes object.\n- **Digest Retrieval:** The `digest` method returns the raw bytes of the digest.\n- **Hexadecimal Representation:** The `hexdigest` method provides a hexadecimal string representation of the digest.\n\n### OracleDigest Class\n\nThe `OracleDigest` class extends `Digest` to simulate a random oracle, a theoretical construct in cryptography that provides a random response for each unique query but remains consistent for repeated queries.\n\n```python\nclass OracleDigest(Digest):\n    def __init__(self, input, entropy=None):\n        super().__init__(input)\n        if entropy is None:\n            entropy = lambda: hashlib.sha256(os.urandom(32)).digest()\n        self.entropy = entropy\n        self.cache = {}\n\n    def __getitem__(self, index):\n        if index not in self.cache:\n            self.cache[index] = self.entropy()[0]\n        return self.cache[index]\n```\n\n- **Initialization:** Accepts an `input` as the seed for the random oracle. The `entropy` parameter specifies a randomness source, defaulting to a SHA-256 hash of random data from `os.urandom`.\n- **Lazy Loading:** The `__getitem__` method implements lazy loading, generating random bytes when first requested and caching them for consistent future access.\n\n### LazyDigest Class\n\nThe `LazyDigest` class embodies the principle of lazy computation to simulate an infinite digest based on a given seed and hash function.\n\n```python\nclass LazyDigest(Digest):\n    def __init__(self, seed, hash_fn=hashlib.sha256):\n        super().__init__(seed)\n        self.hash_fn = hash_fn\n\n    def __getitem__(self, index):\n        h = self.hash_fn()\n        h.update(self.digest())\n        h.update(str(index).encode('utf-8'))\n        return h.digest()[0]\n```\n\n- **Seed and Hash Function:** Initializes with a `seed` and a `hash_fn`.\n- **Lazy Byte Generation:** The `__getitem__` method generates each byte only when accessed, using the seed and index.\n\n### LazyHexDigest Class\n\nThe `LazyHexDigest` class extends `LazyDigest` by providing hexadecimal representations of the lazily computed bytes.\n\n```python\nclass LazyHexDigest(LazyDigest):\n    def __getitem__(self, index):\n        return super().__getitem__(index).hex()\n\n    def hexdigest(self):\n        return self\n```\n\n- **Hexadecimal Output:** Converts each byte into its hexadecimal representation for easier visualization and analysis.\n\n### Oracle Class\n\nThe `Oracle` class simulates a random oracle by caching the outputs for given inputs, ensuring consistent results for repeated queries.\n\n```python\nclass Oracle:\n    def __init__(self):\n        self.cache = {}\n\n    def __call__(self, x):\n        if x not in self.cache:\n            self.cache[x] = OracleDigest(x)\n        return self.cache[x]\n```\n\n- **Caching Mechanism:** Uses a dictionary to cache results, mimicking the random oracle's property of consistent outputs for identical inputs.\n- **Integration with `OracleDigest`:** Uses the `OracleDigest` class to generate new digests.\n\n### CryptoHash Class\n\nThe `CryptoHash` class serves as a wrapper for any cryptographic hash function, facilitating the easy generation of digests from arbitrary data inputs.\n\n```python\nclass CryptoHash:\n    def __init__(self, hash_fn=hashlib.sha256):\n        self.hash_fn = hash_fn\n\n    def __call__(self, x):\n        return Digest(self.hash_fn(x).digest())\n```\n\n- **Flexibility in Hash Function Selection:** Allows the use of any hash function supported by Python's `hashlib`.\n- **Simple Interface:** Abstracts complex cryptographic functions for easier usage.\n\n### OracleHash Class\n\nThe `OracleHash` class approximates a random oracle by generating lazy, infinite digests using a cryptographic hash function seeded by the input.\n\n```python\nclass OracleHash(CryptoHash):\n    def __call__(self, x):\n        return LazyDigest(self.hash_fn(x).digest(), self.hash_fn)\n```\n\n- **Extension of `CryptoHash`:** Inherits the simplicity and flexibility of `CryptoHash`.\n- **Integration with `LazyDigest`:** Uses `LazyDigest` to create digests that can theoretically extend indefinitely.\n\n## Discussion on Approximation and Finite Machines\n\nIt's important to note that while these implementations provide valuable insights, they are approximations constrained by the limitations of finite machines:\n\n1. **Random Oracle Approximation:** The `OracleDigest` and `Oracle` classes use finite caching mechanisms, which means they cannot perfectly emulate a random oracle due to memory constraints. Additionally, each instantiation of a random oracle can diverge due to different entropy sources, illustrating the inherent randomness and\n\n the practical challenges of achieving idealized behavior.\n\n2. **Lazy Computation:** The `LazyDigest` class demonstrates how infinite sequences can be generated on demand. However, it does not possess the true properties of a random oracle, as it relies on deterministic cryptographic hash functions and finite computation.\n\n## Usage\n\nTo use these classes, you can create instances and call them with your desired inputs. Here is an example:\n\n```python\nfrom digest import Digest, OracleDigest, LazyDigest\nfrom oracle import Oracle, CryptoHash, OracleHash\n\n# Example usage of Digest\ndigest = Digest(hashlib.sha256(b\"example input\").digest())\nprint(digest.hexdigest())\n\n# Example usage of OracleDigest\noracle_digest = OracleDigest(b\"example input\")\nprint(oracle_digest[0])\n\n# Example usage of LazyDigest\nlazy_digest = LazyDigest(b\"example seed\")\nprint(lazy_digest[0])\n\n# Example usage of Oracle\noracle = Oracle()\nprint(oracle(b\"example input\")[0])\n\n# Example usage of CryptoHash\ncrypto_hash = CryptoHash()\nprint(crypto_hash(b\"example input\").hexdigest())\n\n# Example usage of OracleHash\noracle_hash = OracleHash()\nprint(oracle_hash(b\"example input\")[0])\n```\n\n## Conclusion\n\nThis project provides a clear and concise introduction to the concepts of hash functions, random oracles, and lazy computation. The provided Python classes and functions illustrate these concepts and can be used for further experimentation and learning.\n"
    },
    {
        "id": 716881508,
        "node_id": "R_kgDOKrq-ZA",
        "name": "reliability-estimation-in-series-systems-model-selection",
        "full_name": "queelius/reliability-estimation-in-series-systems-model-selection",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/reliability-estimation-in-series-systems-model-selection",
        "description": null,
        "fork": false,
        "url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection",
        "forks_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/forks",
        "keys_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/teams",
        "hooks_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/events",
        "assignees_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/tags",
        "blobs_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/subscription",
        "commits_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/merges",
        "archive_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/downloads",
        "issues_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems-model-selection/deployments",
        "created_at": "2023-11-10T04:16:05Z",
        "updated_at": "2024-02-20T00:44:52Z",
        "pushed_at": "2024-02-20T00:38:42Z",
        "git_url": "git://github.com/queelius/reliability-estimation-in-series-systems-model-selection.git",
        "ssh_url": "git@github.com:queelius/reliability-estimation-in-series-systems-model-selection.git",
        "clone_url": "https://github.com/queelius/reliability-estimation-in-series-systems-model-selection.git",
        "svn_url": "https://github.com/queelius/reliability-estimation-in-series-systems-model-selection",
        "homepage": null,
        "size": 26596,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": "HTML",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": false,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 2
            }
        ],
        "readme_content": "## Model Selection in Series Systems with Weibull Components\n"
    },
    {
        "id": 890035490,
        "node_id": "R_kgDONQzdIg",
        "name": "resume",
        "full_name": "queelius/resume",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/resume",
        "description": null,
        "fork": false,
        "url": "https://api.github.com/repos/queelius/resume",
        "forks_url": "https://api.github.com/repos/queelius/resume/forks",
        "keys_url": "https://api.github.com/repos/queelius/resume/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/resume/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/resume/teams",
        "hooks_url": "https://api.github.com/repos/queelius/resume/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/resume/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/resume/events",
        "assignees_url": "https://api.github.com/repos/queelius/resume/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/resume/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/resume/tags",
        "blobs_url": "https://api.github.com/repos/queelius/resume/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/resume/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/resume/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/resume/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/resume/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/resume/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/resume/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/resume/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/resume/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/resume/subscription",
        "commits_url": "https://api.github.com/repos/queelius/resume/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/resume/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/resume/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/resume/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/resume/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/resume/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/resume/merges",
        "archive_url": "https://api.github.com/repos/queelius/resume/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/resume/downloads",
        "issues_url": "https://api.github.com/repos/queelius/resume/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/resume/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/resume/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/resume/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/resume/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/resume/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/resume/deployments",
        "created_at": "2024-11-17T21:04:21Z",
        "updated_at": "2024-11-18T12:58:19Z",
        "pushed_at": "2024-11-18T12:58:16Z",
        "git_url": "git://github.com/queelius/resume.git",
        "ssh_url": "git@github.com:queelius/resume.git",
        "clone_url": "https://github.com/queelius/resume.git",
        "svn_url": "https://github.com/queelius/resume",
        "homepage": null,
        "size": 456,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": "TeX",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": false,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 2
            }
        ],
        "readme_content": "My resume / cv\n",
        "images": [
            "lex.png"
        ]
    },
    {
        "id": 401513045,
        "node_id": "MDEwOlJlcG9zaXRvcnk0MDE1MTMwNDU=",
        "name": "rstatlab",
        "full_name": "queelius/rstatlab",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/rstatlab",
        "description": null,
        "fork": false,
        "url": "https://api.github.com/repos/queelius/rstatlab",
        "forks_url": "https://api.github.com/repos/queelius/rstatlab/forks",
        "keys_url": "https://api.github.com/repos/queelius/rstatlab/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/rstatlab/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/rstatlab/teams",
        "hooks_url": "https://api.github.com/repos/queelius/rstatlab/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/rstatlab/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/rstatlab/events",
        "assignees_url": "https://api.github.com/repos/queelius/rstatlab/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/rstatlab/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/rstatlab/tags",
        "blobs_url": "https://api.github.com/repos/queelius/rstatlab/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/rstatlab/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/rstatlab/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/rstatlab/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/rstatlab/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/rstatlab/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/rstatlab/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/rstatlab/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/rstatlab/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/rstatlab/subscription",
        "commits_url": "https://api.github.com/repos/queelius/rstatlab/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/rstatlab/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/rstatlab/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/rstatlab/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/rstatlab/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/rstatlab/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/rstatlab/merges",
        "archive_url": "https://api.github.com/repos/queelius/rstatlab/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/rstatlab/downloads",
        "issues_url": "https://api.github.com/repos/queelius/rstatlab/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/rstatlab/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/rstatlab/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/rstatlab/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/rstatlab/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/rstatlab/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/rstatlab/deployments",
        "created_at": "2021-08-30T23:25:35Z",
        "updated_at": "2021-09-02T00:17:12Z",
        "pushed_at": "2021-09-02T00:17:09Z",
        "git_url": "git://github.com/queelius/rstatlab.git",
        "ssh_url": "git@github.com:queelius/rstatlab.git",
        "clone_url": "https://github.com/queelius/rstatlab.git",
        "svn_url": "https://github.com/queelius/rstatlab",
        "homepage": null,
        "size": 2288,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": null,
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "jpailden",
                "commits": 165
            },
            {
                "name": "queelius",
                "commits": 5
            }
        ],
        "readme_content": "This repository contains weekly statistical lab materials for Stat 244 and Stat 380 at SIUE.\n"
    },
    {
        "id": 758180435,
        "node_id": "R_kgDOLTDqUw",
        "name": "solomonoff_induction",
        "full_name": "queelius/solomonoff_induction",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/solomonoff_induction",
        "description": null,
        "fork": false,
        "url": "https://api.github.com/repos/queelius/solomonoff_induction",
        "forks_url": "https://api.github.com/repos/queelius/solomonoff_induction/forks",
        "keys_url": "https://api.github.com/repos/queelius/solomonoff_induction/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/solomonoff_induction/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/solomonoff_induction/teams",
        "hooks_url": "https://api.github.com/repos/queelius/solomonoff_induction/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/solomonoff_induction/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/solomonoff_induction/events",
        "assignees_url": "https://api.github.com/repos/queelius/solomonoff_induction/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/solomonoff_induction/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/solomonoff_induction/tags",
        "blobs_url": "https://api.github.com/repos/queelius/solomonoff_induction/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/solomonoff_induction/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/solomonoff_induction/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/solomonoff_induction/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/solomonoff_induction/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/solomonoff_induction/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/solomonoff_induction/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/solomonoff_induction/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/solomonoff_induction/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/solomonoff_induction/subscription",
        "commits_url": "https://api.github.com/repos/queelius/solomonoff_induction/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/solomonoff_induction/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/solomonoff_induction/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/solomonoff_induction/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/solomonoff_induction/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/solomonoff_induction/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/solomonoff_induction/merges",
        "archive_url": "https://api.github.com/repos/queelius/solomonoff_induction/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/solomonoff_induction/downloads",
        "issues_url": "https://api.github.com/repos/queelius/solomonoff_induction/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/solomonoff_induction/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/solomonoff_induction/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/solomonoff_induction/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/solomonoff_induction/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/solomonoff_induction/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/solomonoff_induction/deployments",
        "created_at": "2024-02-15T19:28:46Z",
        "updated_at": "2024-04-25T12:12:22Z",
        "pushed_at": "2024-04-25T12:12:19Z",
        "git_url": "git://github.com/queelius/solomonoff_induction.git",
        "ssh_url": "git@github.com:queelius/solomonoff_induction.git",
        "clone_url": "https://github.com/queelius/solomonoff_induction.git",
        "svn_url": "https://github.com/queelius/solomonoff_induction",
        "homepage": null,
        "size": 52,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": "Python",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": false,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "mit",
            "name": "MIT License",
            "spdx_id": "MIT",
            "url": "https://api.github.com/licenses/mit",
            "node_id": "MDc6TGljZW5zZTEz"
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 10
            }
        ],
        "readme_content": "# Markov chains\n\nA first-order Markov chain is a conditional probability distribution of the form\n$$\n    P(X_k = x_k | X_{k-1} = x_{k-1}),\n$$\nwhere $x_j \\in X$, $X$ is the support of $X_1,X_2,\\ldots$.\nIn this context, we refer to $X$ as the set of *tokens* that may be observed.\n\nAn $n$-th order Markov chain models\n$$\n    P(X_k = x_k | x_{k-1}, x_{k-2}, \\ldots, x_{k-n + 1}).\n$$\n\nWe can model this with a first-order Markov chain with $|X|^n$ states, where\neach state has up to $|X|$ non-zero transition probabilities,\n$$\n    P(S_k = s_k | S_{k-1} = s_{k-1})\n$$\nwhere $s_1,s_2,\\ldots \\in X^n$ but we still do state transitions on $x_1,x_2,\\ldots$.\nSome observations:\n\n1. As the token set $X$ increases in size (cardinality), the number of states grows\n   by $|X|^n$, e.g., if $n=2$ then it grows quadradically.\n2. As the order $n$ increases, the number of states grows exponentially.\n3. As the order $n$ increases, the number of state transitions stays *constant*, $O(|X|)$.\n4. As the order $n$ increases, the Markov chain's transition matrix becomes increasingly sparse,\n   with a maximum density of $|X|^{1-n}$ non-zero entries (as $n \\to \\infty$, the density\n   goes to $0$).\n"
    },
    {
        "id": 871518157,
        "node_id": "R_kgDOM_JPzQ",
        "name": "space-sandbox-sim",
        "full_name": "queelius/space-sandbox-sim",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/space-sandbox-sim",
        "description": null,
        "fork": false,
        "url": "https://api.github.com/repos/queelius/space-sandbox-sim",
        "forks_url": "https://api.github.com/repos/queelius/space-sandbox-sim/forks",
        "keys_url": "https://api.github.com/repos/queelius/space-sandbox-sim/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/space-sandbox-sim/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/space-sandbox-sim/teams",
        "hooks_url": "https://api.github.com/repos/queelius/space-sandbox-sim/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/space-sandbox-sim/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/space-sandbox-sim/events",
        "assignees_url": "https://api.github.com/repos/queelius/space-sandbox-sim/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/space-sandbox-sim/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/space-sandbox-sim/tags",
        "blobs_url": "https://api.github.com/repos/queelius/space-sandbox-sim/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/space-sandbox-sim/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/space-sandbox-sim/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/space-sandbox-sim/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/space-sandbox-sim/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/space-sandbox-sim/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/space-sandbox-sim/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/space-sandbox-sim/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/space-sandbox-sim/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/space-sandbox-sim/subscription",
        "commits_url": "https://api.github.com/repos/queelius/space-sandbox-sim/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/space-sandbox-sim/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/space-sandbox-sim/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/space-sandbox-sim/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/space-sandbox-sim/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/space-sandbox-sim/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/space-sandbox-sim/merges",
        "archive_url": "https://api.github.com/repos/queelius/space-sandbox-sim/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/space-sandbox-sim/downloads",
        "issues_url": "https://api.github.com/repos/queelius/space-sandbox-sim/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/space-sandbox-sim/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/space-sandbox-sim/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/space-sandbox-sim/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/space-sandbox-sim/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/space-sandbox-sim/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/space-sandbox-sim/deployments",
        "created_at": "2024-10-12T07:23:23Z",
        "updated_at": "2024-11-18T08:25:08Z",
        "pushed_at": "2024-11-18T07:50:53Z",
        "git_url": "git://github.com/queelius/space-sandbox-sim.git",
        "ssh_url": "git@github.com:queelius/space-sandbox-sim.git",
        "clone_url": "https://github.com/queelius/space-sandbox-sim.git",
        "svn_url": "https://github.com/queelius/space-sandbox-sim",
        "homepage": null,
        "size": 12080,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": "Python",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": false,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 6
            }
        ]
    },
    {
        "id": 728854123,
        "node_id": "R_kgDOK3Fuaw",
        "name": "tournamentpetersonlock",
        "full_name": "queelius/tournamentpetersonlock",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/tournamentpetersonlock",
        "description": "Scalable lock based on 2-thread Peterson lock.",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/tournamentpetersonlock",
        "forks_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/forks",
        "keys_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/teams",
        "hooks_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/events",
        "assignees_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/tags",
        "blobs_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/subscription",
        "commits_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/merges",
        "archive_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/downloads",
        "issues_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/tournamentpetersonlock/deployments",
        "created_at": "2023-12-07T20:57:14Z",
        "updated_at": "2023-12-07T20:58:53Z",
        "pushed_at": "2023-12-07T22:41:56Z",
        "git_url": "git://github.com/queelius/tournamentpetersonlock.git",
        "ssh_url": "git@github.com:queelius/tournamentpetersonlock.git",
        "clone_url": "https://github.com/queelius/tournamentpetersonlock.git",
        "svn_url": "https://github.com/queelius/tournamentpetersonlock",
        "homepage": null,
        "size": 8,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": "Java",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "mit",
            "name": "MIT License",
            "spdx_id": "MIT",
            "url": "https://api.github.com/licenses/mit",
            "node_id": "MDc6TGljZW5zZTEz"
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 2
            }
        ],
        "readme_content": "# Java Package: `tournamentpetersonlock`\n\n## Overview\n\n`tournamentpetersonlock` is an elegant Java implementation of a scalable locking mechanism based on the classic Peterson lock algorithm. This project addresses the challenge of generalizing the two-thread Peterson lock to accommodate `n` threads, with `n` being a power of two, using a binary tree of Peterson locks.\n\nDeveloped as a response to Exercise 13 in \"The Art of Multiprocessor Programming\" by Maurice Herlihy and Nir Shavit (2008), it was part of the coursework for CS-590 Multiprocessor Synchronization at SIUE under Dr. Greg Stephen.\n\n## Features\n- **Binary Tree Structure**: Utilizes a binary tree of 2-thread Peterson locks.\n- **Scalable Synchronization**: Designed to handle a power of two number of threads for efficient multi-thread synchronization.\n- **Thread Safety**: Ensures mutual exclusion, deadlock freedom, and starvation freedom in concurrent environments.\n\n## Getting Started\n\nTo use `tournamentpetersonlock` in your project, clone this repository and include the Java files in your project's classpath.\n\n### Installation\n```bash\ngit clone https://github.com/queelius/tournamentpetersonlock.git\n```\n\n## Building and Testing with Maven\n\n### Prerequisites\n- Java Development Kit (JDK) - Version 1.8 or above.\n- Maven - If not already installed, you can download it from [Maven's official website](https://maven.apache.org/download.cgi).\n\n### Building the Project\nNavigate to the project's root directory and run the following command to compile the project:\n```bash\nmvn compile\n```\n\n### Running Tests\nTo run the tests, execute:\n\n```bash\nmvn test\n```\n\nThis command will automatically handle downloading the necessary dependencies, compiling the source code, and running the tests.\n\n\n## Usage\n\nAfter building the project with Maven, you can use `tournamentpetersonlock` in your Java applications. Here's a minimal working example demonstrating how to use `tournamentpetersonlock`:\n\n```java\nimport tournamentpetersonlock.TournamentLock;\n\npublic class TournamentExample {\n    public static void main(String[] args) {\n        // Number of threads (must be a power of two)\n        int numThreads = 4;\n\n        // Create an instance of the lock\n        TournamentLock lock = new TournamentLock(numThreads);\n\n        // Example usage of the lock in a thread\n        Runnable task = () -> {\n            lock.lock();\n            try {\n                // Critical section\n                System.out.println(\"Thread \" + Thread.currentThread().getId() + \" is in the critical section\");\n            } finally {\n                lock.unlock();\n            }\n        };\n\n        // Starting threads\n        for (int i = 0; i < numThreads; i++) {\n            new Thread(task).start();\n        }\n    }\n}\n```\n\nThis example creates an `TournamentLock` lock for a specified number of threads and demonstrates its usage in a multi-threaded context. Each thread acquires the lock before entering the critical section and releases it afterward.\n\nNote: Ensure that the number of threads is a power of two, as required by the `TournamentLock` implementation.\n\n### Running the Example With Maven\n- Place the above code in a file named `TournamentExample.java` in the `src/main/java` directory of your project.\n\n- Compile and run the example using Maven:\n\n```bash\n  mvn compile\n  mvn exec:java -Dexec.mainClass=\"tournamentpetersonlock.PetersonLockExample\"\n```\n\n### Running the Example Without Maven\n\n- Place example code into `TournamentExample.java` somewhere.\n\n- This step requires Maven: Make sure you packaged `tournamentpetersonlock` into a JAR:\n\n```bash\nmvn package\n```\n\n- Place the JAR package into same directory as `TournamentExample.java` and rename it to `tournamentpetersonlock-1.0.jar`.\n\n- Compile and run the example:\n\n```bash\njavac -cp .:tournamentpetersonlock-1.0.jar TournamentExample.java\njava -cp .:tournamentpetersonlock-1.0.jar TournamentExample\n```\n\n## Theoretical Background\n\nThe `tournamentpetersonlock` is underpinned by key theoretical principles ensuring robust and reliable synchronization in multi-threaded environments:\n\n- **Mutual Exclusion**: Each node in the binary tree represents a 2-thread Peterson lock. Threads are only promoted to the next layer if they acquire the lock at their current layer, ensuring that at any level, only half of the threads can progress. This process leads to mutual exclusion at the root, extending to the entire tree.\n\n- **Freedom from Deadlock**: Upon release, a thread sets its flag variable to false for each node along its path. This action allows other threads, which were previously unable to progress due to the lock, to move forward, thus preventing deadlock in the system.\n\n- **Freedom from Starvation**: Since each Peterson lock is starvation-free and the earlier arriving thread (which is not the victim) at a node gets promoted, this property is recursively maintained at each tree layer. Consequently, the entire tree structure is free from starvation.\n\n## Contributing\nContributions to `tournamentpetersonlock` are welcome. Please review any contribution guidelines in this repository and ensure to follow standard practices for contributing to open source projects.\n\n## License\nThis project is licensed under the [MIT License](LICENSE).\n"
    },
    {
        "id": 750342233,
        "node_id": "R_kgDOLLlQWQ",
        "name": "video-playlist-manager",
        "full_name": "queelius/video-playlist-manager",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/video-playlist-manager",
        "description": "video-playlist-manager",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/video-playlist-manager",
        "forks_url": "https://api.github.com/repos/queelius/video-playlist-manager/forks",
        "keys_url": "https://api.github.com/repos/queelius/video-playlist-manager/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/video-playlist-manager/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/video-playlist-manager/teams",
        "hooks_url": "https://api.github.com/repos/queelius/video-playlist-manager/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/video-playlist-manager/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/video-playlist-manager/events",
        "assignees_url": "https://api.github.com/repos/queelius/video-playlist-manager/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/video-playlist-manager/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/video-playlist-manager/tags",
        "blobs_url": "https://api.github.com/repos/queelius/video-playlist-manager/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/video-playlist-manager/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/video-playlist-manager/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/video-playlist-manager/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/video-playlist-manager/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/video-playlist-manager/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/video-playlist-manager/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/video-playlist-manager/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/video-playlist-manager/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/video-playlist-manager/subscription",
        "commits_url": "https://api.github.com/repos/queelius/video-playlist-manager/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/video-playlist-manager/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/video-playlist-manager/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/video-playlist-manager/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/video-playlist-manager/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/video-playlist-manager/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/video-playlist-manager/merges",
        "archive_url": "https://api.github.com/repos/queelius/video-playlist-manager/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/video-playlist-manager/downloads",
        "issues_url": "https://api.github.com/repos/queelius/video-playlist-manager/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/video-playlist-manager/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/video-playlist-manager/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/video-playlist-manager/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/video-playlist-manager/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/video-playlist-manager/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/video-playlist-manager/deployments",
        "created_at": "2024-01-30T13:16:07Z",
        "updated_at": "2024-11-18T08:00:42Z",
        "pushed_at": "2024-11-18T08:00:39Z",
        "git_url": "git://github.com/queelius/video-playlist-manager.git",
        "ssh_url": "git@github.com:queelius/video-playlist-manager.git",
        "clone_url": "https://github.com/queelius/video-playlist-manager.git",
        "svn_url": "https://github.com/queelius/video-playlist-manager",
        "homepage": null,
        "size": 20,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": "Python",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": false,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "mit",
            "name": "MIT License",
            "spdx_id": "MIT",
            "url": "https://api.github.com/licenses/mit",
            "node_id": "MDc6TGljZW5zZTEz"
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 5
            }
        ],
        "readme_content": "# Video Playlist Daemon\n\n## Overview\nVideo Playlist Daemon is a tool designed to serve as a backend for managing video playlists. It is designed to be used as a standalone application or as a tool for lage language models (LLM). It is built using Python and FastAPI, and uses MongoDB as the database.\n\n## Motivation and Use Cases\n1. **Language Model Integration**: Facilitates the integration of YouTube playlist data into language models for enhanced content retrieval and processing.\n2. **Playlist Management Outside YouTube**: Simplifies tracking and managing educational or curated content, useful for bloggers and educators.\n3. **Educational Tool**: Showcases the application development process using conversational AI, potentially including a feature to view the development chat.\n\n## Features\n- Import playlists from YouTube channels or JSON files.\n- Manage playlists: add, delete, and update content.\n- Manage videos: add, delete, and update content.\n- Search for videos. Since it is based on Elasticsearch, it supports full-text search and ranking. We document the expressive query language in this document as well.\n- API endpoints to fetch playlist and video details.\n\n## Requirements\n\n- Docker\n- Docker Compose\n\n## Setup\n\n1. Clone this repository.\n2. Build and run the Docker containers: `docker-compose up --build`\n\nThe application will be available at `http://localhost:8000`.\n\n## API Endpoints\n\nWe use the following endpoints to manage playlists, videos, and import data from external sources. It is a RESTful API that uses JSON for data exchange. It is based on FastAPI and so `/docs` and `/redoc` are available for interactive documentation.\n\n### Search\n\n#### GET /search \nSearches for videos based on query parameters.\n- **Query Parameters**:\n  - `query`: The search term(s) to look for in videos. If empty, a default set of videos is returned (e.g., top 10 by views).\n  - `limit` (optional, default=10): Limits the number of returned results. Useful for implementing pagination or limiting result sets.\n- **Notes**: The search functionality supports full-text search on video descriptions. It employs a ranking algorithm (like BM25) to order the results by relevance. If no query is provided, it returns a default set of videos, which can be sorted by popularity, recency, or other criteria.\n\n### Managing Playlists\n\n#### POST /playlist\nCreates a new playlist.\n- **Body Parameters**:\n  - `playlist_name`: Name of the new playlist.\n  - `description` (optional): A brief description of the playlist.\n- **Notes**: This endpoint is used to create custom playlists within the application.\n\n#### GET /playlist/{playlist_id}\nRetrieves a specific playlist. If `playlist_id` is omitted, returns a list of all playlists.\n- **Path Parameters**:\n  - `playlist_id` (optional): The unique identifier of the playlist to retrieve.\n- **Notes**: Fetches details of a single playlist. If no `playlist_id` is provided, the endpoint lists all playlists, which can be used for browsing or administrative purposes.\n\n#### PUT /playlist/{playlist_id}\nUpdates a specific playlist.\n- **Path Parameters**:\n  - `playlist_id`: The unique identifier of the playlist to update.\n- **Body Parameters**:\n  - `playlist_name` (optional): New name for the playlist.\n  - `description` (optional): Updated description.\n  - `video_ids` (optional): List of video IDs to add to the playlist.\n- **Notes**: Allows modifications to playlist details like name and description. Can also be used to add or remove videos from the playlist.\n\n#### DELETE /playlist/{playlist_id}\nDeletes a specific playlist.\n- **Path Parameters**:\n  - `playlist_id`: The unique identifier of the playlist to delete.\n- **Notes**: Removes a playlist from the application. This action should be irreversible and may require additional confirmation in the UI.\n\n### Managing Videos\n\n#### POST /videos\nAdds a new video.\n- **Body Parameters**:\n  - `video_url`: URL of the video.\n  - `description` (optional): Description of the video.\n- **Notes**: This endpoint allows users to add standalone videos or videos not imported from external sources.\n\n#### GET /videos/{video_id}\nRetrieves a specific video. If `video_id` is omitted, returns a list of all videos.\n- **Path Parameters**:\n  - `video_id` (optional): The unique identifier of the video to retrieve.\n- **Notes**: Fetches details of a single video. Similar to playlists, omitting `video_id` lists all videos in the application.\n\n#### PUT /videos/{video_id}\nUpdates a specific video.\n- **Path Parameters**:\n  - `video_id`: The unique identifier of the video to update.\n- **Body Parameters**:\n  - `video_url` (optional): New URL for the video.\n  - `description` (optional): Updated description of the video.\n- **Notes**: Enables updating\n\n#### DELETE /videos/{video_id}\nDelete a specific video.\n- **Path Parameters**:\n  - `video_id`: The unique identifier of the video to delete.\n- **Notes**: Removes a video from the application. This action should be irreversible and may require additional confirmation in the UI. If the video is part of a playlist, it should be removed from the playlist as well.\n\n### Importing Data\n\n#### POST /import/youtube-playlist\nImport a playlist from YouTube.\n- **Body Parameters**:\n  - `youtube_playlist_id`: ID of the YouTube playlist to import.\n- **Notes**: This endpoint allows users to import playlists from YouTube. The system fetches playlist data, including all associated videos, and adds them to the application's database.\n\n#### POST /import/youtube-channel\nImport a channel from YouTube.\n- **Body Parameters**:\n  - `youtube_channel_id`: ID of the YouTube channel to import.\n- **Notes**: Similar to playlist import, this endpoint enables importing all of the visible playlists on the YouTube channel. Metadata such as channel description, original source, and any associated playlists are stored.\n\n##### Example\nTo import the playlists from my YouTube channel [queelius](https://www.youtube.com/channel/UCYNVzb35O7e2GBICAYfOXDg), which has a channel ID of `UC8butISFwT-Wl7EV0hUK0BQ`, we can use the following command:\n\n```bash\ncurl -X POST \"http://localhost:8000/import-youtube-channel/\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{\\\"youtube_channel_id\\\":\\\"UC8butISFwT-Wl7EV0hUK0BQ\\\"}\"\n```\n\n#### POST /import/youtube-video\nImport a video from YouTube.\n- **Body Parameters**:\n  - `youtube_video_id`: ID of the YouTube video to import.\n- **Notes**: Similar to playlist import, this endpoint enables importing individual videos. Metadata such as video description, original source, and any associated playlist information are stored.\n\n#### POST /import/video-link\nImport a video from a URL.\n- **Body Parameters**:\n  - `video_url`: URL of the video to import.\n  - `description` (optional): Description of the video.\n- **Notes**: This endpoint allows users to add standalone videos or videos not imported from external sources.\n\n#### GET /export/data\nDownload all the data (playlists and videos) as a JSON file.\n- **Notes**: This endpoint allows users to download all the data in the application as a JSON file. This can be used to backup the data or to import it into another application.\n\n## Data Model\n\n### Playlist Document\n\nRepresents a playlist in the application.\n\n- **id** (string): Unique identifier for the playlist.\n- **title** (string): Title of the playlist.\n- **original_playlist_url** (string, optional): URL of the original playlist (e.g., YouTube playlist).\n- **original_owner_url** (string, optional): URL of the original owner (e.g., YouTube channel).\n- **description** (string, optional): Description of the playlist.\n- **video_ids** (array of strings, optional): List of video IDs that are part of this playlist.\n- **comments** (array of strings, optional): Comments added by users.\n- **likes** (integer): Number of likes the playlist has received.\n- **views** (integer): Number of views for the playlist.\n\nTo create the Elasticsearch mapping for the playlist index, use the following CURL command:\n```bash\ncurl -X PUT \"localhost:9200/playlist_index\" -H 'Content-Type: application/json' -d'\n{\n  \"mappings\": {\n    \"properties\": {\n      \"id\": { \"type\": \"keyword\" },\n      \"title\": { \"type\": \"text\" },\n      \"original_playlist_url\": { \"type\": \"text\", \"index\": false },\n      \"original_owner_url\": { \"type\": \"text\", \"index\": false },\n      \"description\": { \"type\": \"text\" },\n      \"video_ids\": { \"type\": \"keyword\" },  // Array of video IDs\n      \"comments\": { \"type\": \"text\" },      // Array of comments\n      \"likes\": { \"type\": \"integer\" },\n      \"views\": { \"type\": \"integer\" }\n    }\n  }\n}'\n```\n\n### Video Document\n\nRepresents a video, which can be standalone or part of playlists.\n\n- **id** (string): Unique identifier for the video.\n- **original_playlist_url** (string, optional): URL of the original playlist (e.g., YouTube playlist).\n- **original_owner_url** (string, optional): Original owner URL (e.g., YouTube channel).\n- **comments** (array of strings, optional): Comments added by users.\n- **likes** (integer): Number of likes the video has received.\n- **views** (integer): Number of views for the video.\n- **url** (string): URL where the video can be accessed.\n- **title** (string, optional): Title of the video.\n- **description** (string, optional): Description of the video.\n\nTo create the Elasticsearch mapping for the video index, use the following CURL command:\n```bash\ncurl -X PUT \"localhost:9200/video_index\" -H 'Content-Type: application/json' -d'\n{\n  \"mappings\": {\n    \"properties\": {\n      \"id\": { \"type\": \"keyword\" },\n      \"original_playlist_url\": { \"type\": \"text\", \"index\": false },\n      \"original_owner_url\": { \"type\": \"text\", \"index\": false },\n      \"comments\": { \"type\": \"text\" },      // Array of comments\n      \"likes\": { \"type\": \"integer\" },\n      \"views\": { \"type\": \"integer\" },\n      \"url\": { \"type\": \"text\", \"index\": false },\n      \"title\": { \"type\": \"text\" },\n      \"description\": { \"type\": \"text\" }\n    }\n  }\n}'\n```\n\n\n## Query Language\n\nThe search functionality supports full-text search on fields, like video descriptions. It employs a ranking algorithm (like BM25) to order the results by relevance. If no query is provided, it returns a default set of videos, which can be sorted by popularity, recency, or other criteria.\n\nWe support arbitrary Elasticsearch queries, which can be used to implement more complex search functionality. By default, the `/search` endpoint matches on video descriptions and video titles (if available)\nand uses BM25 to rank the results.\n\nHowever, *any* field, say playlist description or title, may also be used, and it can be combined with other fields using boolean operators. See the Data Model section for a list of available fields and see\nthe documentation for the Elasticsearch query language for more information on how to construct queries.\n\n## Google API Setup\n\nFor the application to import channel playlists from YouTube, you need to set up Google API credentials and authenticate the application (YouTube Data API v3). This section describes the process.\n\n\n### Obtaining Google API Credentials\n\n1. Go to the [Google Cloud Console](https://console.cloud.google.com/).\n2. Create a new project.\n3. Enable the YouTube Data API v3 for your project.\n4. Create credentials for a desktop application. This will give you a client ID and client secret.\n5. Download the credentials and save them in a file named `client_secrets.json` in the root directory of this project.\n\n### Authenticating the Application\n\nThe first time you run the application, it will attempt to authenticate with Google's API using the credentials in the `client_secrets.json` file. You will be prompted to >\n\nIf the access token expires, the application will automatically use the refresh token to obtain a new one. If the `token.pickle` file is deleted, you will need to re-authe>\n\n## Future Work\n\n- **Vector Database Integration**: To assist with RAG (Retrieval-Augmented Generation), integrate a vector database.\n- **Function Calling**: Implement standard interfaces for LMs (language models) to use this as a tool.\n\n## Contribution\nI am open to contributions and suggestions. Please open an issue or pull request if you have any ideas.\n\n## License\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details."
    },
    {
        "id": 895185892,
        "node_id": "R_kgDONVtz5A",
        "name": "xtoolkit",
        "full_name": "queelius/xtoolkit",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/xtoolkit",
        "description": null,
        "fork": false,
        "url": "https://api.github.com/repos/queelius/xtoolkit",
        "forks_url": "https://api.github.com/repos/queelius/xtoolkit/forks",
        "keys_url": "https://api.github.com/repos/queelius/xtoolkit/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/xtoolkit/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/xtoolkit/teams",
        "hooks_url": "https://api.github.com/repos/queelius/xtoolkit/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/xtoolkit/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/xtoolkit/events",
        "assignees_url": "https://api.github.com/repos/queelius/xtoolkit/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/xtoolkit/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/xtoolkit/tags",
        "blobs_url": "https://api.github.com/repos/queelius/xtoolkit/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/xtoolkit/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/xtoolkit/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/xtoolkit/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/xtoolkit/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/xtoolkit/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/xtoolkit/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/xtoolkit/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/xtoolkit/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/xtoolkit/subscription",
        "commits_url": "https://api.github.com/repos/queelius/xtoolkit/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/xtoolkit/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/xtoolkit/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/xtoolkit/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/xtoolkit/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/xtoolkit/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/xtoolkit/merges",
        "archive_url": "https://api.github.com/repos/queelius/xtoolkit/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/xtoolkit/downloads",
        "issues_url": "https://api.github.com/repos/queelius/xtoolkit/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/xtoolkit/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/xtoolkit/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/xtoolkit/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/xtoolkit/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/xtoolkit/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/xtoolkit/deployments",
        "created_at": "2024-11-27T18:01:55Z",
        "updated_at": "2024-11-30T09:35:18Z",
        "pushed_at": "2024-12-02T14:56:29Z",
        "git_url": "git://github.com/queelius/xtoolkit.git",
        "ssh_url": "git@github.com:queelius/xtoolkit.git",
        "clone_url": "https://github.com/queelius/xtoolkit.git",
        "svn_url": "https://github.com/queelius/xtoolkit",
        "homepage": null,
        "size": 47,
        "stargazers_count": 0,
        "watchers_count": 0,
        "language": "Python",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "other",
            "name": "Other",
            "spdx_id": "NOASSERTION",
            "url": null,
            "node_id": "MDc6TGljZW5zZTA="
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 0,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 5
            }
        ],
        "readme_content": "# Expression Toolkit: `xtoolkit`\n\nA rules-based expression rewriting toolkit for symbolic computation.\n\n## Introduction\n\n`xtoolkit` is a Python package that provides tools for symbolic computation through expression rewriting. It offers capabilities such as pattern matching, rule-based transformations, expression evaluation, theorem proving via tree search, and data generation for AI and machine learning applications.\n\n## Quick Start\n\nTo quickly get started with `xtoolkit`, follow these steps:\n\n1. **Installation**:\n\n   Install `xtoolkit` from PyPI:\n\n   ```sh\n   pip install xtoolkit\n   ```\n\n2. **Basic Usage**:\n\n   Here's a simple example of how to use `xtoolkit` to simplify an expression:\n\n   ```python\n   from xtoolkit import simplifier\n\n   # Define a simplification rule: x + 0 => x\n   rules = [\n       [['+', ['?', 'x'], 0], [':', 'x']]\n   ]\n\n   # Create a simplifier function using the rule\n   simplify = simplifier(rules)\n\n   # Simplify an expression\n   expr = ['+', 'a', 0]\n   result = simplify(expr)\n   print(f\"Simplified expression: {result}\")  # Output: Simplified expression: a\n   ```\n\n3. **Exploring More Features**:\n\n   To explore more advanced features like symbolic differentiation, tree search algorithms for theorem proving, and working with predefined mathematical rules, refer to the detailed sections below.\n\n## Table of Contents\n\n- [Expression Toolkit: `xtoolkit`](#expression-toolkit-xtoolkit)\n  - [Introduction](#introduction)\n  - [Quick Start](#quick-start)\n  - [Table of Contents](#table-of-contents)\n  - [Installation](#installation)\n  - [Overview](#overview)\n  - [Representation of Rules and Expressions](#representation-of-rules-and-expressions)\n    - [Rewrite Rules: Pattern Matching and Skeleton Instantiation](#rewrite-rules-pattern-matching-and-skeleton-instantiation)\n      - [Abstract Syntax Tree (AST) Representation](#abstract-syntax-tree-ast-representation)\n        - [Examples](#examples)\n      - [Simplified Domain-Specific Language (DSL)](#simplified-domain-specific-language-dsl)\n      - [Alternative JSON Representation](#alternative-json-representation)\n    - [Expressions](#expressions)\n  - [Pattern Matching](#pattern-matching)\n  - [Skeleton Instantiation](#skeleton-instantiation)\n  - [Evaluation](#evaluation)\n    - [Example: Evaluating Expressions](#example-evaluating-expressions)\n  - [Simplification Process](#simplification-process)\n    - [The Simplification Process](#the-simplification-process)\n    - [Example: Simplifying Expressions](#example-simplifying-expressions)\n      - [Steps:](#steps)\n      - [Example with Evaluation](#example-with-evaluation)\n  - [Tree Search and Theorem Proving](#tree-search-and-theorem-proving)\n    - [Search Algorithms](#search-algorithms)\n  - [Modules](#modules)\n    - [Core Modules](#core-modules)\n    - [Search Modules](#search-modules)\n  - [Using Tree Search Algorithms: DFS and Best-First Search](#using-tree-search-algorithms-dfs-and-best-first-search)\n    - [Depth-First Search (DFS)](#depth-first-search-dfs)\n      - [Example: Proving a Trigonometric Identity](#example-proving-a-trigonometric-identity)\n        - [Steps:](#steps-1)\n      - [Explanation](#explanation)\n    - [Best-First Search](#best-first-search)\n      - [Example: Simplifying an Algebraic Expression](#example-simplifying-an-algebraic-expression)\n        - [Proofs Steps](#proofs-steps)\n      - [Explanation of Best-First Search](#explanation-of-best-first-search)\n    - [Notes on Usage](#notes-on-usage)\n    - [Additional Tips](#additional-tips)\n    - [Practical Applications](#practical-applications)\n  - [Predefined Rewrite Rules](#predefined-rewrite-rules)\n  - [Notebooks and Examples](#notebooks-and-examples)\n  - [The Power of Language Design](#the-power-of-language-design)\n\n## Installation\n\nTo install the package locally from the source code:\n\n```sh\ngit clone https://github.com/queelius/xtoolkit\ncd xtoolkit\npip install -e .\n```\n\nTo install it from PyPI:\n\n```sh\npip install xtoolkit\n```\n\n## Overview\n\n`xtoolkit` provides a comprehensive set of tools for symbolic computation:\n\n- **Expression Rewriting Engine** (`xtoolkit/rewriter.py`): Functions for pattern matching, expression instantiation, evaluation, and simplification using transformation rules.\n\n- **Simplifier** (`xtoolkit/simplifier.py`): A recursive simplifier that applies rewrite rules to expressions in a bottom-up manner, facilitating expression simplification.\n\n- **Tree Search Algorithms** (`xtoolkit/search/`): Algorithms for theorem proving and exploring expression spaces, including BFS, DFS, IDDFS, Best-First Search, A\\* Search, and Monte Carlo Tree Search.\n\n- **Predefined Mathematical Rules** (`xtoolkit/rules/`): A collection of rules for various mathematical domains such as algebra, calculus, trigonometry, limits, and more.\n\n- **Jupyter Notebooks** (`notebooks/`): Examples demonstrating the functionality of the package.\n\n## Representation of Rules and Expressions\n\n`xtoolkit` employs a powerful yet simple representation for rules and expressions, enabling efficient definition and manipulation of symbolic expressions.\n\n### Rewrite Rules: Pattern Matching and Skeleton Instantiation\n\n#### Abstract Syntax Tree (AST) Representation\n\nRewrite rules are defined using an abstract syntax tree (AST) representation, utilizing nested lists to represent expressions. Each rule consists of:\n\n- **Pattern**: Defines the structure of the expression to match.\n- **Skeleton**: A template for the replacement expression.\n\n##### Examples\n\n1. **Simplification Rule**: The sum of a variable `x` and zero simplifies to `x`.\n\n   ```python\n   [['+', ['?', 'x'], 0], [':', 'x']]\n   ```\n\n   - **Pattern**: `['+', ['?', 'x'], 0]`\n   - **Skeleton**: `[':', 'x']`\n\n2. **Derivative of a Constant**: The derivative of a constant `c` with respect to `x` is zero, \\( \\frac{d}{dx} c = 0 \\).\n\n   ```python\n   [['dd', ['?c', 'c'], ['?', 'x']], 0]\n   ```\n\n   - **Pattern**: `['dd', ['?c', 'c'], ['?', 'x']]`\n   - **Skeleton**: `0`\n\n#### Simplified Domain-Specific Language (DSL)\n\nFor enhanced readability, `xtoolkit` offers a simplified DSL for writing rules:\n\n```text\n# Derivative of a constant: d(c)/dx = 0\ndd (?c c) (?v x) = 0\n\n# Derivative of a variable with respect to itself: d(x)/dx = 1\ndd (?v x) (?v x) = 1\n\n# Product rule: d(f * g)/dx = f' * g + f * g'\ndd (* (? f) (? g)) (?v x) =\n    (+ (* (dd (: f) (: x)) (: g))\n       (* (: f) (dd (: g) (: x))))\n```\n\nIn the DSL:\n\n- `?c c`: Matches any constant and binds it to `c`.\n- `?v x`: Matches any variable and binds it to `x`.\n- `? f`, `? g`: Match any expressions and bind them to `f` and `g`.\n- `:` is used in the skeleton to refer to matched variables from the pattern.\n\n#### Alternative JSON Representation\n\nRules can also be represented as JSON objects, allowing for additional metadata:\n\n```json\n{\n  \"pattern\": [\"dd\", [\"?c\", \"c\"], [\"?v\", \"x\"]],\n  \"replacement\": 0,\n  \"name\": \"derivative_of_constant\",\n  \"description\": \"The derivative of a constant is zero.\"\n}\n```\n\n### Expressions\n\nExpressions are represented in the same AST format as rules:\n\n- `['+', 'x', 3]` represents \\( x + 3 \\).\n- `['*', ['+', 'x', 3], 4]` represents \\( (x + 3) \\times 4 \\).\n- `['dd', ['*', 2, 'x'], 'x']` represents \\( \\frac{d}{dx} (2x) \\).\n\n## Pattern Matching\n\nPattern matching is used to determine if a rule can be applied to an expression. The syntax includes:\n\n- **Exact Match**: An expression `foo` matches exactly `foo`.\n- **List Match**: An expression `[\"f\", \"a\", \"b\"]` matches a list with first element `\"f\"` and subsequent elements `\"a\"`, `\"b\"`.\n- **Pattern Variables**:\n  - `['?', 'x']`: Matches any expression and binds it to `x`.\n  - `['?c', 'c']`: Matches any constant and binds it to `c`.\n  - `['?v', 'x']`: Matches any variable and binds it to `x`.\n\nThis pattern-matching system is simple yet powerful, allowing for flexible expression transformations.\n\n## Skeleton Instantiation\n\nAfter matching, the skeleton is instantiated by replacing pattern variables with the matched expressions:\n\n- **Direct Substitution**: `[\"f\", \"a\", \"b\"]` remains unchanged.\n- **Variable Substitution**: `[':', 'x']` is replaced with the expression bound to `x`.\n\nFor example, if `x` is bound to `3`, then `[':', 'x']` instantiates to `3`.\n\n## Evaluation\n\nThe evaluator computes the value of instantiated skeleton expressions using a dictionary of bindings for operations and variables.\n\n### Example: Evaluating Expressions\n\n```python\nfrom xtoolkit import evaluate\n\n# Define the bindings\nbindings = {\n    '+': lambda x, y: x + y,\n    'x': 3,\n    'y': 4\n}\n\n# Evaluate the expression\nexpr = ['+', 'x', 'y']\nresult = evaluate(expr, bindings)\nprint(f\"evaluate({expr}, {bindings}) => {result}\")\n# Output: evaluate(['+', 'x', 'y'], {'+': <function>, 'x': 3, 'y': 4}) => 7\n```\n\nIn this example:\n\n- The evaluator replaces `'x'` and `'y'` with their values `3` and `4`.\n- It then applies the `+` operation to compute `7`.\n\n## Simplification Process\n\nSimplification involves recursively applying rewrite rules to an expression until it cannot be further reduced. The process works bottom-up, simplifying sub-expressions before moving up the expression tree.\n\n### The Simplification Process\n\nWe can visualize the simplification process as follows:\n\n```mermaid\ngraph TD\n    A0(( )) -->|Expression| A\n    B0(( )) -->|Pattern| A\n    C0(( )) -->|Bindings| A\n    D0(( )) -->|Skeleton| B\n    A[Matcher] -->|Augmented Bindings| B\n    B[Instantiator] -->|Instantiated Skeleton| C[Evaluator]\n    C -->|Simplified Expression| A\n\n    style A0 fill:none, stroke:none\n    style B0 fill:none, stroke:none\n    style C0 fill:none, stroke:none\n    style D0 fill:none, stroke:none\n```\n\n1. **Matcher**: Matches the pattern against the expression and generates bindings.\n2. **Instantiator**: Uses the bindings to instantiate the skeleton.\n3. **Evaluator**: Evaluates the instantiated skeleton to produce a simplified expression.\n4. **Recursive Application**: The process repeats until no further simplifications can be made.\n\n### Example: Simplifying Expressions\n\n**Simplify** `['+', 'x', 0]` using the rule that adding zero simplifies to the original expression.\n\n- **Rule**: `[['+', ['?', 'x'], 0], [':', 'x']]`\n\n#### Steps:\n\n1. **Match**:\n\n   - Pattern: `['+', ['?', 'x'], 0]`\n   - Expression: `['+', 'x', 0]`\n   - Binding: `{'x': 'x'}`\n\n2. **Instantiate**:\n\n   - Skeleton: `[':', 'x']`\n   - Instantiated Skeleton: `'x'`\n\n3. **Evaluate**:\n\n   - Result: `'x'`\n\nThe expression simplifies from `['+', 'x', 0]` to `'x'`.\n\n#### Example with Evaluation\n\nSimplify `['+', 3, 5]` using the addition operation defined in the evaluator.\n\n- **Bindings**: `{'x': 3, 'y': 5, '+': lambda x, y: x + y}`\n\n- **Expression**: `['+', 'x', 'y']`\n\n- **Evaluate**:\n\n  - Replace `'x'` and `'y'` with `3` and `5`.\n  - Apply `+` operation: `3 + 5 = 8`.\n\n- **Result**: `8`\n\n## Tree Search and Theorem Proving\n\nBeyond simplification, `xtoolkit` provides tree search algorithms for tasks such as theorem proving, where the goal is to find a sequence of rewrites that transforms an expression into a target form.\n\n### Search Algorithms\n\n- **Breadth-First Search (BFS)**: Explores all nodes at the current depth before moving deeper.\n- **Depth-First Search (DFS)**: Explores as far as possible along each branch before backtracking.\n- **Iterative Deepening DFS (IDDFS)**: Combines DFS's space efficiency with BFS's completeness.\n- **Best-First Search**: Uses a heuristic to explore more promising branches first.\n- **A\\* Search**: Combines path cost and heuristic information for optimal pathfinding.\n- **Monte Carlo Tree Search (MCTS)**: Uses randomness and statistical sampling to explore the search space.\n\nThese algorithms can be used to prove equivalence between expressions, find transformations that satisfy certain conditions, or explore the space of possible rewrites.\n\n## Modules\n\n### Core Modules\n\n- **`rewriter.py`**: Contains core functions for pattern matching, instantiation, and evaluation.\n\n  - `match(pattern, expression, bindings)`: Matches a pattern against an expression using the provided bindings.\n  - `instantiate(skeleton, bindings)`: Instantiates a skeleton using the bindings.\n  - `evaluate(expression, bindings)`: Evaluates an expression using the bindings.\n\n- **`simplifier.py`**:\n\n  - `simplifier(rules)`: Returns a function to simplify expressions using the provided rules.\n\n### Search Modules\n\nEach search algorithm is implemented in its own module under `search/`:\n\n- **`bfs.py`**: Breadth-First Search\n- **`dfs.py`**: Depth-First Search\n- **`iddfs.py`**: Iterative Deepening DFS\n- **`best_first.py`**: Best-First Search\n- **`astar.py`**: A\\* Search\n- **`mcts.py`**: Monte Carlo Tree Search\n\nThese modules provide functions to perform search operations on expression spaces. Next, we show how to use these modules to explore the space of possible rewrites.\n\n## Using Tree Search Algorithms: DFS and Best-First Search\n\n`xtoolkit` provides powerful tree search algorithms for tasks such as theorem proving, expression transformation, and exploring possible rewrites. This section demonstrates how to use Depth-First Search (DFS) and Best-First Search within `xtoolkit`.\n\n### Depth-First Search (DFS)\n\nDFS explores as far as possible along each branch before backtracking, making it suitable for finding deep solutions without excessive memory consumption.\n\n#### Example: Proving a Trigonometric Identity\n\n**Goal**: Prove the identity \\( \\sin^2 x + \\cos^2 x = 1 \\) by transforming the left-hand side (LHS) into the right-hand side (RHS) using DFS.\n\n##### Steps:\n\n1. **Define the Rewrite Rules**\n\n   We'll use fundamental trigonometric identities as rewrite rules.\n\n   ```python\n   # trigonometric_rules.py\n   rules = [\n       # Pythagorean identity\n       [['+', ['^', ['sin', ['?','x']], 2], ['^', ['cos', ['?','x']], 2]], 1],\n       # Expand sine squared\n       [['^', ['sin', ['?','x']], 2], ['-', 1, ['^', ['cos', [':','x']], 2]]],\n       # Expand cosine squared\n       [['^', ['cos', ['?','x']], 2], ['-', 1, ['^', ['sin', [':','x']], 2]]],\n       # Sine double angle\n       [['sin', ['*', 2, ['?','x']]], ['*', 2, ['sin', [':','x']], ['cos', [':','x']]]],\n       # Cosine double angle\n       [['cos', ['*', 2, ['?','x']]], ['-', ['^', ['cos', [':','x']], 2], ['^', ['sin', [':','x']], 2]]],\n       # Other relevant identities...\n   ]\n   ```\n\n2. **Set Up the Initial Expression and Goal Test**\n\n   ```python\n   initial_expr = ['+', ['^', ['sin', 'x'], 2], ['^', ['cos', 'x'], 2]]\n\n   # Define a goal test function\n   def goal_test(expr):\n       return expr == 1\n   ```\n\n3. **Implement DFS**\n\n   ```python\n   from xtoolkit.search.dfs import dfs_search\n\n   # Perform the search\n   solution = dfs_search(initial_expr, rules, goal_test)\n\n   if solution:\n       print(\"Proof found!\")\n       for step in solution:\n           print(step)\n   else:\n       print(\"No proof found.\")\n   ```\n\n4. **Run the Code**\n\n   Execute the script to see if the proof is found. The output should show the steps leading from the LHS to the RHS.\n\n#### Explanation\n\n- **dfs_search**: A function in `xtoolkit` that performs DFS given an initial expression, a set of rules, and a goal test.\n- **Goal Test Function**: Determines when the search should stop by checking if the current expression equals `1`.\n\n### Best-First Search\n\nBest-First Search uses a heuristic to prioritize exploration, making it efficient in finding optimal or near-optimal solutions.\n\n#### Example: Simplifying an Algebraic Expression\n\n**Goal**: Simplify the expression \\( (x^2 - 1) \\) into its factored form \\( (x - 1)(x + 1) \\).\n\n##### Proofs Steps\n\n1. **Define the Rewrite Rules**\n\n   ```python\n   # algebraic_rules.py\n   rules = [\n       # Difference of squares\n       [['-', ['^', ['?', 'x'], 2], ['^', ['?','y'], 2]],\n        ['*', ['+', [':','x'], [':','y']], ['-', [':','x'], [':','y']]]],\n       # Expand multiplication\n       [['*', ['+', ['?','a'], ['?','b']], ['+', ['?','c'], ['?','d']]],\n        ['+', ['*', [':','a'], [':','c']], ['*', [':','a'], [':','d']], ['*', [':','b'], [':','c']], ['*', [':','b'], [':','d']]]],\n       # Simplify exponents\n       [['^', ['^', ['?','x'], ['?','m']], ['?','n']],\n        ['^', [':','x'], ['*', [':','m', [':','n']]]],\n       # ... other algebraic rules\n   ]\n   ```\n\n2. **Set Up the Initial Expression and Goal Test**\n\n   ```python\n   initial_expr = ['-', ['^', 'x', 2], 1]\n   target_expr = ['*', ['-', 'x', 1], ['+', 'x', 1]]\n\n   # Define a goal test function\n   def goal_test(expr):\n       return expr == target_expr\n   ```\n\n3. **Define a Heuristic Function**\n\n   The heuristic estimates how \"close\" an expression is to the target expression.\n\n   ```python\n   def heuristic(expr):\n       # Simple heuristic: count matching elements with the target expression\n       def flatten(e):\n           return [e] if not isinstance(e, list) else sum(map(flatten, e), [])\n       expr_elements = set(flatten(expr))\n       target_elements = set(flatten(target_expr))\n       # Higher score if more elements match\n       return len(expr_elements & target_elements)\n   ```\n\n4. **Implement Best-First Search**\n\n   ```python\n   from xtoolkit.search.best_first import best_first_search\n\n   # Perform the search\n   solution = best_first_search(initial_expr, rules, goal_test, heuristic)\n\n   if solution:\n       print(\"Simplification found!\")\n       for step in solution:\n           print(step)\n   else:\n       print(\"No simplification found.\")\n   ```\n\n5. **Run the Code**\n\n   Execute the script to find the simplification steps from the initial expression to the factored form.\n\n#### Explanation of Best-First Search\n\n- **best_first_search**: A function in `xtoolkit` that performs Best-First Search using the provided heuristic.\n- **Heuristic Function**: Guides the search by estimating the similarity between the current expression and the target expression.\n\n### Notes on Usage\n\n- **Rule Completeness**: Ensure that the set of rules covers the transformations needed to reach the goal.\n- **Heuristic Design**: The effectiveness of Best-First Search heavily relies on the heuristic function's ability to estimate closeness accurately.\n- **Performance Considerations**: While DFS might explore irrelevant branches deeply, Best-First Search can be more efficient if the heuristic is well-designed.\n\n### Additional Tips\n\n- **Combining Searches**: Sometimes, combining different search strategies can yield better results.\n- **Custom Goal Tests**: For more complex goals, define custom goal test functions that capture the desired conditions.\n- **Debugging**: If the search isn't finding a solution, check the rules and heuristic for completeness and correctness.\n\n### Practical Applications\n\n- **Theorem Proving**: Use tree searches to find proofs for mathematical theorems by transforming premises into conclusions.\n- **Expression Optimization**: Find more efficient or simplified forms of expressions in computational settings.\n- **Automated Reasoning**: Implement logic-based systems that require exploring possible inferences.\n\n## Predefined Rewrite Rules\n\nThe `rules/` directory contains predefined rules for various mathematical domains:\n\n- **`deriv_rules.py`**: Rules for symbolic differentiation.\n- **`trig_rules.py`**: Trigonometric identities.\n- **`limit_rules.py`**: Rules for computing limits.\n- **`random_var_rules.py`**: Manipulations of random variables.\n- **`integral_rules.py`**: Rules for integration.\n- **`calculus_rules.py`**: General calculus rules.\n- **`algebra_rules.py`**: Algebraic manipulation rules.\n\nAdditional rules cover domains such as differential equations, logic, set theory, combinatorics, graph theory, group theory, ring theory, field theory, vector spaces, linear algebra, topology, measure theory, probability theory, and statistics.\n\n## Notebooks and Examples\n\nThe `notebooks/` directory contains Jupyter notebooks demonstrating the functionality of `xtoolkit`, including examples of simplification, evaluation, and theorem proving.\n\n## The Power of Language Design\n\nDesigning a domain-specific language (DSL) enables expressing complex ideas concisely and readably. In `xtoolkit`, the DSL allows users to define transformation rules effectively, leveraging the power of symbolic computation and rule-based systems.\n\nOur rules-based system is Turing-complete, capable of expressing any computable function. While powerful, such systems are better suited for symbolic computation, theorem proving, and other symbolic tasks rather than general-purpose programming."
    },
    {
        "id": 452613644,
        "node_id": "R_kgDOGvpWDA",
        "name": "algebraic.mle",
        "full_name": "queelius/algebraic.mle",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/algebraic.mle",
        "description": "Algebraic maximum likelihood estimators",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/algebraic.mle",
        "forks_url": "https://api.github.com/repos/queelius/algebraic.mle/forks",
        "keys_url": "https://api.github.com/repos/queelius/algebraic.mle/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/algebraic.mle/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/algebraic.mle/teams",
        "hooks_url": "https://api.github.com/repos/queelius/algebraic.mle/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/algebraic.mle/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/algebraic.mle/events",
        "assignees_url": "https://api.github.com/repos/queelius/algebraic.mle/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/algebraic.mle/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/algebraic.mle/tags",
        "blobs_url": "https://api.github.com/repos/queelius/algebraic.mle/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/algebraic.mle/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/algebraic.mle/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/algebraic.mle/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/algebraic.mle/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/algebraic.mle/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/algebraic.mle/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/algebraic.mle/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/algebraic.mle/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/algebraic.mle/subscription",
        "commits_url": "https://api.github.com/repos/queelius/algebraic.mle/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/algebraic.mle/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/algebraic.mle/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/algebraic.mle/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/algebraic.mle/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/algebraic.mle/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/algebraic.mle/merges",
        "archive_url": "https://api.github.com/repos/queelius/algebraic.mle/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/algebraic.mle/downloads",
        "issues_url": "https://api.github.com/repos/queelius/algebraic.mle/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/algebraic.mle/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/algebraic.mle/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/algebraic.mle/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/algebraic.mle/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/algebraic.mle/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/algebraic.mle/deployments",
        "created_at": "2022-01-27T09:12:55Z",
        "updated_at": "2022-05-30T10:38:37Z",
        "pushed_at": "2024-02-17T23:18:47Z",
        "git_url": "git://github.com/queelius/algebraic.mle.git",
        "ssh_url": "git@github.com:queelius/algebraic.mle.git",
        "clone_url": "https://github.com/queelius/algebraic.mle.git",
        "svn_url": "https://github.com/queelius/algebraic.mle",
        "homepage": "https://queelius.github.io/algebraic.mle/",
        "size": 163871,
        "stargazers_count": 1,
        "watchers_count": 1,
        "language": "R",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "gpl-3.0",
            "name": "GNU General Public License v3.0",
            "spdx_id": "GPL-3.0",
            "url": "https://api.github.com/licenses/gpl-3.0",
            "node_id": "MDc6TGljZW5zZTk="
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 1,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 120
            }
        ],
        "readme_content": "R package: `algebraic.mle`\n==========================\n\n<!-- badges: start -->\n\n[![GPL-3\nLicense](https://img.shields.io/badge/license-GPL--3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\n<!-- badges: end -->\n\n`algebraic.mle` is an R package that provides an algebra over Maximum\nLikelihood Estimators (MLEs). These estimators possess many desirable,\nwell-defined statistical properties which the package helps you\nmanipulate and utilize.\n\nInstallation\n------------\n\n`algebraic.mle` can be installed from GitHub by using the devtools\npackage in R:\n\n``` r\n#devtools::install_github(\"queelius/algebraic.mle\")\n#devtools::install_github(\"queelius/algebraic.dist\")\nlibrary(algebraic.dist)\n#> Registered S3 method overwritten by 'algebraic.dist':\n#>   method     from \n#>   print.dist stats\nlibrary(algebraic.mle)\n```\n\nPurpose\n-------\n\nThe likelihood function is a fundamental concept in statistics and\nparametric models. The `algebraic.mle` package enables you to manipulate\nand utilize MLEs in a way that is consistent with the underlying\nstatistical theory and according to a powerful, well-defined interface.\n\nAPI Overview\n------------\n\nThe main object in the `algebraic.mle` package is the `mle` object,\nwhich represents a fitted model. The package provides a number of\ngeneric methods designed for `mle` objects. A comprehensive list of\nfunctions is available in the [function\nreference](https://queelius.github.io/algebraic.mle/reference/index.html)\nfor `algebraic.mle`.\n\nFitting exponential models\n--------------------------\n\nHere is an example of fitting a conditional exponential model to some\ndata using `algebraic.mle`. The true DGP is given by `Y | x ~ X(x) + W`\nwhere `X(x) ~ EXP(rate(x))`, `W ~ N(0, 1e-3)`, and\n`rate(x) = exp(b0 + b1 * x)`.\n\nIn this analysis, we do not care how `x` is distributed, and we take it\nto be an observable exogenous variable. We are interested in the\nconditional distribution of `Y | x`.\n\nLet\u2019s fit a conditional exponential model to some data from this DGP.\nWhile the true DGP is a bit more complicated, the most salient part is\nthe exponential component, and the gaussian term may be thought of as\nadded noise, say, from imprecise measurement. Of course, the true DGP is\nunknown in practice, so arriving at an conditional exponential model is\na matter of judgement and domain knowledge.\n\nIn this model, `Y | x ~ EXP(rate(x))` where `rate(x) = exp(b0 + b1*x)`.\nFirst, let\u2019s define the DGP (data generating process):\n\n``` r\nb0 <- -.1\nb1 <- 0.5\n\ndgp <- function(n, x) {\n    # rate is the expected value of X\n    rate <- exp(b0 + b1 * x)\n    X <- rexp(n, rate)\n    # W is the random error\n    W <- rnorm(n, 0, 1e-3)\n    # Y | x is the observed value\n    Y <- X + W\n    return(Y)\n}\n```\n\nLet\u2019s generate some date:\n\n``` r\nn <- 75 # number of observations\nset.seed(1231) # for reproducibility\ndf <- data.frame(x = rep(NA, n), y = rep(NA, n))\nfor (i in 1:n) {\n    # We do not care how x is distributed, so we take it to be an observable\n    # exogenous variable that impacts the conditional mean of Y.\n    x <- runif(1, -10, 10)\n    y <- dgp(n = 1, x = x)\n    df[i, ] <- c(x, y)\n}\n```\n\nNow, we define three functions, `resp`, `rate`, and `loglik`, which will\nbe used to define the model.\n\n``` r\nresp <- function(df) df$y\nrate <- function(df, beta) exp(beta[1] + beta[2] * df$x)\nloglik <- function(df, resp, rate) {\n  function(beta) sum(dexp(x = resp(df), rate = rate(df, beta), log = TRUE))\n}\n```\n\nLet\u2019s fit the model. We\u2019ll use the `optim` function in `stats` to fit\nthe model and then wrap it into an `mle` object using `mle_numerical`.\n\n``` r\n# initial guess for the parameters\npar0 <- c(0, 0)\nnames(par0) <- c(\"b0\", \"b1\")\n\nsol <- algebraic.mle::mle_numerical(optim(par = par0,\n    fn = loglik(df, resp, rate),\n    control = list(fnscale = -1),\n    hessian = TRUE))\nsummary(sol)\n#> Maximum likelihood estimator of type mle_numerical is normally distributed.\n#> The estimates of the parameters are given by:\n#>         b0         b1 \n#> -0.2253626  0.4560893 \n#> The standard error is  0.1167634 0.02145606 .\n#> The asymptotic 95% confidence interval of the parameters are given by:\n#>          2.5%       97.5%\n#> b0 -0.4542147 0.003489406\n#> b1  0.4140362 0.498142415\n#> The MSE of the individual components in a multivariate estimator is:\n#>              [,1]         [,2]\n#> [1,] 0.0136336902 0.0003746527\n#> [2,] 0.0003746527 0.0004603623\n#> The log-likelihood is  -119.6977 .\n#> The AIC is  243.3954 .\n```\n\nLet\u2019s plot it:\n\n``` r\n# plot the x-y points from the data frame\nplot(df$x,df$y)\n\n# now overlay a plot of the conditional mean\nx <- seq(-10, 10, .1)\nb0.hat <- params(sol)[1]\nb1.hat <- params(sol)[2]\ny.hat <- 1/exp(b0.hat + b1.hat*x)\ny <- 1/exp(b0 + b1*x)\nlines(x, y, col = \"green\", lwd = 10)\nlines(x, y.hat, col = \"blue\", lwd = 10)\n```\n\n<img src=\"man/figures/README-unnamed-chunk-7-1.png\" width=\"100%\" />\n\n### Hypothesis test and model selection\n\nLet\u2019s test the hypothesis that `b0 = 0` using a likelihood ratio test.\nWe can use the LRT because this null model is a special case (nested) of\nthe full model. The null model is `Y | x ~ EXP(rate(x))` where\n`rate(x) = exp(b1*x)`, while the full model is `Y | x ~ EXP(rate(x))`\nwhere `rate(x) = exp(b0 + b1*x)`.\n\n``` r\n# construct null model where b1 = 0\nrate_b0_zero <- function(df, b1) exp(b1 * df$x)\n\n# initial guess for the parameters\n# fit the model under the null hypothesis\nsol2 <- mle_numerical(optim(par = 0,\n    fn = loglik(df, resp, rate_b0_zero),\n    control = list(fnscale = -1),\n    hessian = TRUE,\n    method = \"BFGS\"))\nsummary(sol2)\n#> Maximum likelihood estimator of type mle_numerical is normally distributed.\n#> The estimates of the parameters are given by:\n#> [1] 0.4617093\n#> The standard error is  0.01899941 .\n#> The asymptotic 95% confidence interval of the parameters are given by:\n#>             2.5%     97.5%\n#> param1 0.4244712 0.4989475\n#> The MSE of the estimator is  0.0003609774 .\n#> The log-likelihood is  -121.7164 .\n#> The AIC is  245.4328 .\n```\n\nLet\u2019s compute the likelihood ratio test statistic and p-value:\n\n``` r\n(lrt.sol2 <- -2 * (loglik_val(sol2) - loglik_val(sol)))\n#> [1] 4.037435\npchisq(lrt.sol2, df = 1, lower.tail = FALSE) # compute the p-value\n#> [1] 0.04450142\n```\n\nWe see that the `p < 0.05`, but just barely, so we say the data is not\ncompatible with the null hypothesis `b0 = 0`.\n\nIf we wanted to do model selection, we could use the AIC:\n\n``` r\naic(sol)\n#> [1] 243.3954\naic(sol2)\n#> [1] 245.4328\n```\n\nBy the AIC measure, since the full model has an AIC less than the null\nmodel, we would choose the full model. We actually know the DGP and both\nmodels are reasonable approximations, but the full model is a closer\napproximation.\n\n\u201cAll models are wrong, but some are useful.\u201d - George Box\n\nEventually, if we have a sufficiently large sample, any model that is\nnot the DGP can be discarded, but reality is so complex that we will\nnever have a large enough sample and we will never be able to come up\nwith a model that is exactly the DGP.\n\nLet\u2019s do another test, `b1 = 0`, i.e., it\u2019s an unconditional exponential\nmodel, or just a standard exponential distribution.\n\n``` r\nrate_b1_zero <- function(df, b0) exp(b0)\n# fit the model under the null hypothesis\nsol3 <- algebraic.mle::mle_numerical(optim(par = 0,\n    fn = loglik(df, resp, rate_b1_zero),\n    control = list(fnscale = -1),\n    hessian = TRUE,\n    method = \"BFGS\"))\n(lrt.sol3 <- -2 * (loglik_val(sol3) - loglik_val(sol)))\n#> [1] 285.0265\npchisq(lrt.sol3, df = 1, lower.tail = FALSE) # compute the p-value\n#> [1] 6.029289e-64\n```\n\nThis has a `p`-value of essentially zero, so we reject the null\nhypothesis that `b1 = 0`.\n\nLet\u2019s compare the confidence intervals for each of these models.\n\n``` r\nprint(confint(sol))\n#>          2.5%       97.5%\n#> b0 -0.4542147 0.003489406\n#> b1  0.4140362 0.498142415\nprint(confint(sol2))\n#>             2.5%     97.5%\n#> param1 0.4244712 0.4989475\nprint(confint(sol3))\n#>             2.5%     97.5%\n#> param1 -2.722463 -2.269829\n```\n\nWe see that the 95% confidence interval for `b0` does not include zero,\nso we reject the null hypothesis that `b0 = 0`. The 95% confidence\ninterval for `b1` does not include zero, so we reject the null\nhypothesis that `b1 = 0`.\n\nYou can see tutorials for more examples of using the package in the\n[vignettes](https://queelius.github.io/algebraic.mle/articles/index.html).\n",
        "github_pages": "https://queelius.github.io/algebraic.mle/"
    },
    {
        "id": 229463860,
        "node_id": "MDEwOlJlcG9zaXRvcnkyMjk0NjM4NjA=",
        "name": "algebraic_cipher_types",
        "full_name": "queelius/algebraic_cipher_types",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/algebraic_cipher_types",
        "description": "Algebraic cipher types",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/algebraic_cipher_types",
        "forks_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/forks",
        "keys_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/teams",
        "hooks_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/events",
        "assignees_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/tags",
        "blobs_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/subscription",
        "commits_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/merges",
        "archive_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/downloads",
        "issues_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/algebraic_cipher_types/deployments",
        "created_at": "2019-12-21T17:56:50Z",
        "updated_at": "2023-11-07T05:16:33Z",
        "pushed_at": "2022-05-27T15:00:08Z",
        "git_url": "git://github.com/queelius/algebraic_cipher_types.git",
        "ssh_url": "git@github.com:queelius/algebraic_cipher_types.git",
        "clone_url": "https://github.com/queelius/algebraic_cipher_types.git",
        "svn_url": "https://github.com/queelius/algebraic_cipher_types",
        "homepage": null,
        "size": 567,
        "stargazers_count": 1,
        "watchers_count": 1,
        "language": "C++",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "gpl-3.0",
            "name": "GNU General Public License v3.0",
            "spdx_id": "GPL-3.0",
            "url": "https://api.github.com/licenses/gpl-3.0",
            "node_id": "MDc6TGljZW5zZTk="
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 1,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 46
            }
        ],
        "readme_content": "# algebraic_cipher_types_code\nAlgebraic cipher types\n"
    },
    {
        "id": 165660656,
        "node_id": "MDEwOlJlcG9zaXRvcnkxNjU2NjA2NTY=",
        "name": "cipher_trapdoor_sets",
        "full_name": "queelius/cipher_trapdoor_sets",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/cipher_trapdoor_sets",
        "description": null,
        "fork": false,
        "url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets",
        "forks_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/forks",
        "keys_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/teams",
        "hooks_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/events",
        "assignees_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/tags",
        "blobs_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/subscription",
        "commits_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/merges",
        "archive_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/downloads",
        "issues_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/cipher_trapdoor_sets/deployments",
        "created_at": "2019-01-14T12:49:37Z",
        "updated_at": "2024-07-07T06:38:57Z",
        "pushed_at": "2024-07-07T06:38:53Z",
        "git_url": "git://github.com/queelius/cipher_trapdoor_sets.git",
        "ssh_url": "git@github.com:queelius/cipher_trapdoor_sets.git",
        "clone_url": "https://github.com/queelius/cipher_trapdoor_sets.git",
        "svn_url": "https://github.com/queelius/cipher_trapdoor_sets",
        "homepage": null,
        "size": 2662,
        "stargazers_count": 1,
        "watchers_count": 1,
        "language": "Jupyter Notebook",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 1,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 29
            }
        ],
        "readme_content": "# Cipher sets over trapdoors\n"
    },
    {
        "id": 831276824,
        "node_id": "R_kgDOMYxHGA",
        "name": "digistar",
        "full_name": "queelius/digistar",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/digistar",
        "description": null,
        "fork": false,
        "url": "https://api.github.com/repos/queelius/digistar",
        "forks_url": "https://api.github.com/repos/queelius/digistar/forks",
        "keys_url": "https://api.github.com/repos/queelius/digistar/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/digistar/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/digistar/teams",
        "hooks_url": "https://api.github.com/repos/queelius/digistar/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/digistar/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/digistar/events",
        "assignees_url": "https://api.github.com/repos/queelius/digistar/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/digistar/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/digistar/tags",
        "blobs_url": "https://api.github.com/repos/queelius/digistar/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/digistar/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/digistar/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/digistar/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/digistar/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/digistar/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/digistar/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/digistar/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/digistar/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/digistar/subscription",
        "commits_url": "https://api.github.com/repos/queelius/digistar/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/digistar/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/digistar/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/digistar/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/digistar/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/digistar/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/digistar/merges",
        "archive_url": "https://api.github.com/repos/queelius/digistar/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/digistar/downloads",
        "issues_url": "https://api.github.com/repos/queelius/digistar/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/digistar/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/digistar/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/digistar/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/digistar/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/digistar/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/digistar/deployments",
        "created_at": "2024-07-20T05:38:08Z",
        "updated_at": "2024-11-18T08:22:52Z",
        "pushed_at": "2024-11-18T08:22:48Z",
        "git_url": "git://github.com/queelius/digistar.git",
        "ssh_url": "git@github.com:queelius/digistar.git",
        "clone_url": "https://github.com/queelius/digistar.git",
        "svn_url": "https://github.com/queelius/digistar",
        "homepage": null,
        "size": 10098,
        "stargazers_count": 1,
        "watchers_count": 1,
        "language": "C++",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": false,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 1,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 13
            }
        ],
        "readme_content": "## Sandbox Space Simulation Game Design Document\n\n### Motivation\n\nThe primary motivation for this project is to create a highly interactive and scalable sandbox space simulation game. This game will simulate a vast number of \"big atoms\" interacting through various interesting forces, both global (e.g., gravity, electric fields) and local (e.g., repulsions, collisions). By leveraging GPU acceleration and optimized data structures like octrees, we aim to achieve high performance and handle a large number of simultaneous players and AI bots efficiently.\n\n### Purpose of the Game\n\nThe game aims to provide an immersive space simulation environment where players can explore, interact, and experiment with various physical phenomena. Key objectives include:\n\n- Simulating a dynamic universe with realistic physics.\n- Simulate interactions between \"big atoms\" based on fundamental forces and properties.\n- Because the constituent elements are fairly simple, the game can scale to a large number of big atoms, hopefully on the order of 10s of millions, making it possible to simulate complex multi-star systems each with hundreds of planets and moons and thousands of asteroids and comets, each of which may have different properties, behaviors, and resources.\n- Allowing players to manipulate and observe the behavior of \"big atoms\" under different interaction dynamics and forces.\n- Supporting a large number of concurrent players and AI bots for a rich multiplayer experience.\n- Provide a DSL for celestial mechanics, making it easy to reproduce known systems and to create new ones based on known physics.\n- Enable novel physics that can support relativistic-like effects, black hole formation, warp channels, and other exotic phenomena, all based on fundamental properties of the big atoms and their interactions.\n\n### Optimization Goals\n\nTo achieve the desired scale and performance, we will focus on several key optimizations:\n- **GPU Acceleration**: Offload computationally intensive tasks to the GPU to leverage parallel processing capabilities. We will use CUDA, kernel fusion, memory coalescing, and other GPU optimization techniques to make this possible.\n- **Efficient Data Structures**: Use octrees to manage spatial queries and force calculations efficiently. We will overload the octree to handle many different kinds of forces and interactions.\n- **Batch Processing**: Handle batch bounding box queries in parallel on the GPU to satisfy multiple queries simultaneously from different players and AI bots.\n\n### Core Features\n\n#### Physics Simulation\n- **Big Atoms**: Fundamental units of the simulation, each with properties such as position, velocity, mass, charge, radius, interaction vector, rotation, internal temperature, and magnetic moment.\n- **Force Fields**: Includes forces based on potential energy fields, such as gravity, electric fields, magnetic fields, Lennard-Jones potentials, and so on. Many of these forces can be approximated with \"cut-off\" distances to reduce computational complexity, although it may not even be necessary given the spatial indexing.\n- **Octree Structure**: Utilized for efficient spatial partitioning and force calculations.\n\n#### Bounding Box Queries\n- Efficiently handle multiple bounding box queries using batched processing on the GPU.\n- Utilize octrees to quickly determine atoms within specified regions, supporting dynamic game scenarios and AI behaviors.\n\n#### Networking\n- **RESTful Interface**: Provide a lightweight and fast HTTP-based interface for managing game state and interactions.\n- **Binary UDP Interface**: Handle high-throughput, low-latency communication for real-time multiplayer interactions, based on zeromq or similar libraries.\n- **Local IPC**: For local IPC, we use shared memory facilities that bypass system calls for maximum performance. This is particularly useful for AI bots and other high-frequency communication, such as between the physics engine and the rendering engine. The simulation server does not actually perform rendering, so the GPU can be completely dedicated to the physics simulation. \n\n#### Scripting and AI\n- **Python Integration**: Expose a rich API to the Python interpreter, allowing for flexible scripting and AI control.\n- **AI Bots**: Implement a base class `Agent` and derived class `SubsumptionAgent` to facilitate the creation of reactive, intelligent bots. More sophisticated AI frameworks to follow.\n- **Language Modles**: We are also curious about using open source small language models to generate text for the game, either for AI bots or for other purposes in the game.\n\n### **Future Work**\n\n- **Further Optimization**: Continuously profile and optimize GPU kernels and data structures.\n- **Advanced AI**: Develop more sophisticated AI behaviors and decision-making processes.\n- **Expanded Features**: Introduce new gameplay elements, force types, and interactive objects.\n\n### Conclusion\n\nThis design document outlines the foundational aspects of our sandbox space simulation game. By leveraging GPU acceleration, efficient data structures, and a robust networking and scripting framework, we aim to create a scalable and engaging simulation experience. This document serves as a reference for the initial implementation and future enhancements, guiding our development efforts toward achieving high performance and rich interactivity.\n"
    },
    {
        "id": 165903913,
        "node_id": "MDEwOlJlcG9zaXRvcnkxNjU5MDM5MTM=",
        "name": "encrypted_search_probabilistic_estimator_conf",
        "full_name": "queelius/encrypted_search_probabilistic_estimator_conf",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/encrypted_search_probabilistic_estimator_conf",
        "description": "Encrypted Search: A Probabilistic Estimator of Confiidentiality",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf",
        "forks_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/forks",
        "keys_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/teams",
        "hooks_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/events",
        "assignees_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/tags",
        "blobs_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/subscription",
        "commits_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/merges",
        "archive_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/downloads",
        "issues_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/encrypted_search_probabilistic_estimator_conf/deployments",
        "created_at": "2019-01-15T18:39:47Z",
        "updated_at": "2024-12-10T09:51:51Z",
        "pushed_at": "2023-10-19T16:31:01Z",
        "git_url": "git://github.com/queelius/encrypted_search_probabilistic_estimator_conf.git",
        "ssh_url": "git@github.com:queelius/encrypted_search_probabilistic_estimator_conf.git",
        "clone_url": "https://github.com/queelius/encrypted_search_probabilistic_estimator_conf.git",
        "svn_url": "https://github.com/queelius/encrypted_search_probabilistic_estimator_conf",
        "homepage": "https://queelius.github.io/encrypted_search_probabilistic_estimator_conf/",
        "size": 11956,
        "stargazers_count": 1,
        "watchers_count": 1,
        "language": "HTML",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [
            "bootstrap",
            "confidentiality",
            "encrypted-search",
            "entropy"
        ],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 1,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 7
            }
        ],
        "readme_content": "## Encrypted Search: A Probabilistic Estimator of Confidentiality\n\nThis repository contains research on measuring the confidentiality of encrypted\nsearch systems against an adversary that observes hidden queries to infer plaintext queries.\n\nThis paper is written in Bookdown and provides output options for PDF (pdfbook)\nand HTML (gitbook).\n\n### Abstract\nWe propose a confidentiality measure for plaintext queries against an adversary that observes corresponding hidden queries. An adversary employs a plaintext attack to infer a mapping from hidden to plaintext queries. We apply the estimator to an encrypted search system that maintains a minimum confidentiality level. A bootstrap method estimates the sampling distribution of confidentiality over query histories. This provides a probabilistic assessment of confidentiality, like the chance that an adversary infers over 70% of queries. We also propose mapping entropy to a lower bound on confidentiality.\n\n### Contents\n\n- `pdfbook/paper.pdf`: PDF version of the full paper\n- `gitbook/index.html`: HTML version of the full paper\n- `docs/`: Copy of `gitbook` directory, for GitHub Page hosting at: ...\n- `src/`: C++ simulation of Zipf study.\n- `data/`: Experimental results on confidentiality (Zipf simulation)\n\n",
        "github_pages": "https://queelius.github.io/encrypted_search_probabilistic_estimator_conf/"
    },
    {
        "id": 648893705,
        "node_id": "R_kgDOJq1VCQ",
        "name": "likelihood.model",
        "full_name": "queelius/likelihood.model",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/likelihood.model",
        "description": "Likelihood model framework",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/likelihood.model",
        "forks_url": "https://api.github.com/repos/queelius/likelihood.model/forks",
        "keys_url": "https://api.github.com/repos/queelius/likelihood.model/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/likelihood.model/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/likelihood.model/teams",
        "hooks_url": "https://api.github.com/repos/queelius/likelihood.model/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/likelihood.model/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/likelihood.model/events",
        "assignees_url": "https://api.github.com/repos/queelius/likelihood.model/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/likelihood.model/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/likelihood.model/tags",
        "blobs_url": "https://api.github.com/repos/queelius/likelihood.model/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/likelihood.model/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/likelihood.model/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/likelihood.model/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/likelihood.model/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/likelihood.model/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/likelihood.model/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/likelihood.model/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/likelihood.model/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/likelihood.model/subscription",
        "commits_url": "https://api.github.com/repos/queelius/likelihood.model/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/likelihood.model/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/likelihood.model/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/likelihood.model/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/likelihood.model/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/likelihood.model/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/likelihood.model/merges",
        "archive_url": "https://api.github.com/repos/queelius/likelihood.model/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/likelihood.model/downloads",
        "issues_url": "https://api.github.com/repos/queelius/likelihood.model/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/likelihood.model/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/likelihood.model/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/likelihood.model/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/likelihood.model/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/likelihood.model/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/likelihood.model/deployments",
        "created_at": "2023-06-03T05:48:59Z",
        "updated_at": "2023-06-10T18:24:10Z",
        "pushed_at": "2024-02-20T12:10:07Z",
        "git_url": "git://github.com/queelius/likelihood.model.git",
        "ssh_url": "git@github.com:queelius/likelihood.model.git",
        "clone_url": "https://github.com/queelius/likelihood.model.git",
        "svn_url": "https://github.com/queelius/likelihood.model",
        "homepage": "https://queelius.github.io/likelihood.model/",
        "size": 396,
        "stargazers_count": 1,
        "watchers_count": 1,
        "language": "R",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [
            "fisher-information-matrix",
            "likelihood",
            "maximum-likelihood-estimation",
            "sampling-distribution"
        ],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 1,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 20
            }
        ],
        "readme_content": "Likelihood model\n================\n\n# R package: `likelihood.model`\n\nThe R package `likelihood.model` is designed for specifying and using\nlikelihood models for statistical inference.\n\nThe basic likelihood model is a concept that, in order for your object\nto satisfy, must implement a number of generic functions/methods. The\npackage provides a class, `likelihood_contr_model`, which implements\nthese functions and serves as a flexible framework for specifying\nlikelihood models based on the idea of independent likelihood\ncontributions for different types of observations, e.g., right-censored\nversus exact observations.\n\nThe package is designed to be used with the\n[`algebraic.mle`](https://github.com/queelius/algebraic.mle) package,\nwhich provides a framework for performing maximum likelihood estimation\n(MLE).\n\n## Installation\n\nYou can install the development version of `likelihood.model` from\n[GitHub](https://github.com/queelius/likelihood.model) with:\n\n``` r\nif (!require(devtools)) {\n    install.packages(\"devtools\")\n}\ndevtools::install_github(\"queelius/likelihood.model\")\n```\n\nSee the [package website](https://queelius.github.io/likelihood.model/)\nfor more information.\n",
        "github_pages": "https://queelius.github.io/likelihood.model/"
    },
    {
        "id": 652776078,
        "node_id": "R_kgDOJuiSjg",
        "name": "likelihood.model.series.md",
        "full_name": "queelius/likelihood.model.series.md",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/likelihood.model.series.md",
        "description": "Likelihood model for series systems with masked component cause of failure and other censoring mechanisms",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/likelihood.model.series.md",
        "forks_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/forks",
        "keys_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/teams",
        "hooks_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/events",
        "assignees_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/tags",
        "blobs_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/subscription",
        "commits_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/merges",
        "archive_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/downloads",
        "issues_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/likelihood.model.series.md/deployments",
        "created_at": "2023-06-12T19:18:49Z",
        "updated_at": "2023-09-13T04:27:32Z",
        "pushed_at": "2023-09-09T01:14:06Z",
        "git_url": "git://github.com/queelius/likelihood.model.series.md.git",
        "ssh_url": "git@github.com:queelius/likelihood.model.series.md.git",
        "clone_url": "https://github.com/queelius/likelihood.model.series.md.git",
        "svn_url": "https://github.com/queelius/likelihood.model.series.md",
        "homepage": "https://queelius.github.io/likelihood.model.series.md",
        "size": 43850,
        "stargazers_count": 1,
        "watchers_count": 1,
        "language": "R",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "gpl-3.0",
            "name": "GNU General Public License v3.0",
            "spdx_id": "GPL-3.0",
            "url": "https://api.github.com/licenses/gpl-3.0",
            "node_id": "MDc6TGljZW5zZTk="
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 1,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 71
            }
        ],
        "readme_content": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# R Package: `likelihood.model.series.md`\n\nThis is an R package for estimating the parameters of a series system\nmodel from masked data. It provides a flexible and intuitive interface\nfor specifying the model and performing maximum likelihood estimation.\n\nThis R package provides a set of functions for generating MLEs for the\nlifetime parameters of the components in a series systems and other\nrelated characteristics from data that *masks* the component cause of\nfailure, and also the system lifetime.\n\nMasked data comes in a variety of forms:\n\n1.  The system lifetime can be masked in three related ways. Right\n    censoring occurs when the system under observation is only known to\n    have survived for some minimum length of time. Left censoring occurs\n    when the system under observation is only know to have survived for\n    some maximum length of time. Finally, interval censoring occurs when\n    the system under observation is only known to have survived between\n    some minimum and maximum length of time.\n    \n    In the unmasked situation, we know precisely how long the system\n    under observation survived.\n\n2.  Regardless of how the series system lifetime is masked, the lifetime\n    of the components may be masked in any of the ways described in item\n    (1). There is, additionally, another kind of masking we would like\n    to consider. What if we do not observe any of the component\n    lifetimes, and instead are only given a (potentially masked) series\n    system lifetime, and a *candidate set* of component indexes which\n    plausibly contains the failed component index.\n    \n    For a series system of\n    ![m](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;m\n    \"m\") components, the candidate sets are subsets of\n    ![\\\\{1,\\\\ldots,m\\\\}](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;%5C%7B1%2C%5Cldots%2Cm%5C%7D\n    \"\\\\{1,\\\\ldots,m\\\\}\").\n\n## Installation\n\nYou can install the development version from GitHub with:\n\n``` r\ndevtools::install_github(\"queelius/likelihood.model.series.md\")\n```\n\n## Usage\n\nThis package provides a comprehensive framework for maximum likelihood\nestimation (MLE) of series system parameters from masked data.\n\nIt is based on a likelihood contribution model, where each kind of\nmasking of component failures in a series system of some kind and number\nof components is handled by a set of likelihood contributions. The\nlikelihood contributions are then combined to form the likelihood model\nfor the kind of data and series system under consideration.\n\nIn general, masking models may characaterized by satisfy any (or none)\nof the following conditions:\n\nCondition 1: The probability that the failed component is in the\ncandidate set is 1.\n\nCondition 2: Given a candidate set of potential causes of failure, when\nwe condition on the component cause being any one of the components in\nthe candidate set at the given system failure time, the probability of\nthe candidate set is uniform.\n\nCondition 3: The distribution of candidate sets conditioned on a system\nfailure time and a component cause of failure is independent of the\nsystem parameter vector.\n\nWe provide several kinds of masking models, including:\n\n1.  Uninformed candidate sets that satisfy conditions 1, 2, and 3.\n\n2.  Candidate sets with relaxed conditions, e.g., informed candidate\n    sets.\n\nTogether, these masking models provide a flexible framework for handling\na wide variety of masking situations.\n\nWe also provide a method for analyzing the sensitivity of a likelihood\nmodel to violations of the masking assumptions. This is done by\nproviding a set of likelihood models that are constructed by relaxing\nthe masking assumptions in various ways. The likelihood models are then\ncompared using the likelihood ratio test.\n\nOther kinds of data and censoring are handled separately by the general\nlikelihood model as detailed in\n[likelihood.model](https://github.com/queelius/likelihood.model). This\nis the general framework for adding various kinds of contributions to\nthe likelihood model. This package is focused on providing contributions\nfor masking. The `likelihood.model` package provides a robust API to\nwork with likelihood models, e.g., for finding MLEs, bootstrapping\nconfidence intervals, and so on.\n\nWe also provide for data imputation, synthetic (implicit prior) data,\nand so on. These are often based on the conditions the model assumes,\nand so are provided in this package.\n\n# API\n\nWhen we construct a likelihood contribution model, we so so by\nspecifying the contributions of each observation type. For example, if\nwe have a series system with three components, and we observe the system\nlifetime and the lifetimes of the first two components, we would specify\nthe likelihood contributions as follows:\n\n``` r\nmy_model <- likelihood_contr_model$new(\n  obs_type = function(df) {\n    ifelse(df$right_censoring,\n           \"exact_fail_time_with_cand_set_c1_c2_c3\",\n           \"right_censored\")\n  },\n\n  logliks = list(\n    ...\n  )\n)\n```\n\nNow, we may call, for instance, `fit(my_model, data)` to fit the model.\nWe provide a default method for `fit` based on MLE, but you can also\nprovide your own method, e.g., based on a customized algorithm for\nefficiently finding estimates for a particular type of series system for\nparticular types of data.\n\nRegardless of the outcome, ideally it will return an `mle`-like object\n(from the [algebraic.mle](https://queelius.github.io/algebraic.mle)\npackage), in which case a host of additional methods are available to\nyou, such as `predict`, `confint`, `sample`, etc. This object makes it\neasy to perform various analyses on your fitted model.\n\n``` r\naic(fit)\nbias(fit)\nvcov(fit)\npredict(fit, new_data)\nconfint(fit)\nsample(fit, method = \"asymptotic\", n = 1000)\n```\n\nNote that the `likelihood.model.series.md` package provides a number of\nlikelihood contributions for common observation types. These are\ndescribed in the package documentation. You can also provide your own\nlikelihood contributions, and we provide a number of functions to make\nthis easier.\n\n# Assumptions\n\nSome of the models in this package make explicit assumptions about the\ndata. We provide various functions to help you check these assumptions,\nto impute data that satisfies these assumptions, and to generate fake\ndata that satisfies these assumptions.\n\nSometimes, we generate fake data to create an implicit prior\ndistribution for the parameters.\n\n# Model Selection\n\nWe provide some wrappers for model selection, such as AIC, BIC, and so\non. We also provide specializations and constraint functions for the\nparameters.\n\nFor example, we may have a strong belief that the components are Weibull\ndistributed, and furthermore, that they are more or less on the same\nscale with slight differences in shape. In this case, we can simplify\nthe model by assuming ![\\\\lambda\\_1 = \\\\cdots =\n\\\\lambda\\_m](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;%5Clambda_1%20%3D%20%5Ccdots%20%3D%20%5Clambda_m\n\"\\\\lambda_1 = \\\\cdots = \\\\lambda_m\") and then only fitting\n![\\\\hat\\\\lambda](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;%5Chat%5Clambda\n\"\\\\hat\\\\lambda\") and ![\\\\hat k\\_1, \\\\ldots, \\\\hat\nk\\_m](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;%5Chat%20k_1%2C%20%5Cldots%2C%20%5Chat%20k_m\n\"\\\\hat k_1, \\\\ldots, \\\\hat k_m\"), reducing a\n![2m](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;2m\n\"2m\") parameter model to a simpler\n![m+1](https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D&space;%5Cbg_white&space;m%2B1\n\"m+1\") parameter model. This is not an unrealistic assumption, since if\na series system is well-designed, then the components should be more or\nless on the same scale (i.e., have approximately the same MTTF).\n\n# Bootstrapping Statistics of the MLE and Likleihood Mode\n\nTo estimate various characteiristcs, such as the bias, BCa confidence\nintervals, etc, then bootstraping may be used. The\n`likelihood.md.series.systems` package relies upon the bootstrapping\nfunctionality in `boot` and `likelihood.model`, but provide special\nfunctions and methods that are particular to the masked data series\nsystem context.\n\n# Parametric Models\n\nA *general series system* model, and other kinds of series systems, are\nalso handled by external libraries, such as the [Dynamic Failure\nRate](https://github.com/queelius/dfr_dist) library, which can be used\nto construct hazard functions for components that may depend on\npredictors, including time, any other covariates.\n\n# Documentation\n\nFor more detailed information on how to use this package and what each\nfunction does, please refer to the package documentation. The\nseries\\_system function and its parameters are described in detail\nthere.\n\n# Contributing\n\nContributions are welcome\\! Please open an issue or submit a pull\nrequest on GitHub if you find any bugs or if you\u2019d like to suggest\nimprovements.\n"
    },
    {
        "id": 435437257,
        "node_id": "R_kgDOGfQ-yQ",
        "name": "md-series-systems-relaxed-candidate-set-models",
        "full_name": "queelius/md-series-systems-relaxed-candidate-set-models",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/md-series-systems-relaxed-candidate-set-models",
        "description": null,
        "fork": false,
        "url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models",
        "forks_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/forks",
        "keys_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/teams",
        "hooks_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/events",
        "assignees_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/tags",
        "blobs_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/subscription",
        "commits_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/merges",
        "archive_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/downloads",
        "issues_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/md-series-systems-relaxed-candidate-set-models/deployments",
        "created_at": "2021-12-06T09:36:36Z",
        "updated_at": "2024-11-18T11:14:04Z",
        "pushed_at": "2024-11-18T11:13:59Z",
        "git_url": "git://github.com/queelius/md-series-systems-relaxed-candidate-set-models.git",
        "ssh_url": "git@github.com:queelius/md-series-systems-relaxed-candidate-set-models.git",
        "clone_url": "https://github.com/queelius/md-series-systems-relaxed-candidate-set-models.git",
        "svn_url": "https://github.com/queelius/md-series-systems-relaxed-candidate-set-models",
        "homepage": "https://queelius.github.io/md-series-systems-relaxed-candidate-set-models",
        "size": 54096,
        "stargazers_count": 1,
        "watchers_count": 1,
        "language": "HTML",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "gpl-3.0",
            "name": "GNU General Public License v3.0",
            "spdx_id": "GPL-3.0",
            "url": "https://api.github.com/licenses/gpl-3.0",
            "node_id": "MDc6TGljZW5zZTk="
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 1,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 66
            }
        ],
        "readme_content": "This is not functional. I intend to use it to extend my master's project on estimating reliability of series system from masked data by relaxing some of its conditions.\n\nThe project is currently in an unknown state.\n",
        "github_pages": "https://queelius.github.io/md-series-systems-relaxed-candidate-set-models/",
        "images": [
            "exp_series_samp_dist.png"
        ]
    },
    {
        "id": 818236200,
        "node_id": "R_kgDOMMVLKA",
        "name": "ngram-projections",
        "full_name": "queelius/ngram-projections",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/ngram-projections",
        "description": null,
        "fork": false,
        "url": "https://api.github.com/repos/queelius/ngram-projections",
        "forks_url": "https://api.github.com/repos/queelius/ngram-projections/forks",
        "keys_url": "https://api.github.com/repos/queelius/ngram-projections/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/ngram-projections/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/ngram-projections/teams",
        "hooks_url": "https://api.github.com/repos/queelius/ngram-projections/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/ngram-projections/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/ngram-projections/events",
        "assignees_url": "https://api.github.com/repos/queelius/ngram-projections/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/ngram-projections/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/ngram-projections/tags",
        "blobs_url": "https://api.github.com/repos/queelius/ngram-projections/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/ngram-projections/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/ngram-projections/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/ngram-projections/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/ngram-projections/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/ngram-projections/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/ngram-projections/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/ngram-projections/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/ngram-projections/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/ngram-projections/subscription",
        "commits_url": "https://api.github.com/repos/queelius/ngram-projections/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/ngram-projections/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/ngram-projections/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/ngram-projections/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/ngram-projections/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/ngram-projections/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/ngram-projections/merges",
        "archive_url": "https://api.github.com/repos/queelius/ngram-projections/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/ngram-projections/downloads",
        "issues_url": "https://api.github.com/repos/queelius/ngram-projections/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/ngram-projections/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/ngram-projections/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/ngram-projections/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/ngram-projections/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/ngram-projections/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/ngram-projections/deployments",
        "created_at": "2024-06-21T11:50:22Z",
        "updated_at": "2024-12-10T09:12:05Z",
        "pushed_at": "2024-12-10T09:12:02Z",
        "git_url": "git://github.com/queelius/ngram-projections.git",
        "ssh_url": "git@github.com:queelius/ngram-projections.git",
        "clone_url": "https://github.com/queelius/ngram-projections.git",
        "svn_url": "https://github.com/queelius/ngram-projections",
        "homepage": null,
        "size": 145,
        "stargazers_count": 1,
        "watchers_count": 1,
        "language": "Python",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 1,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 7
            }
        ],
        "readme_content": "# Autoregressive Models: Inductive Biases and Projections\n\n### Abstract\n\nThis paper explores the use of inductive biases and projection functions in autoregressive (AR) models to enhance out-of-distribution (OOD) generalization. We revisit the concept of infini-grams, which leverage suffix arrays to manage arbitrary input (context) lengths efficiently. This approach is compared to traditional $n$-gram models, highlighting its advantages in sample efficiency and computational scalability. We delve into various inductive biases, such as the recency bias, shortest edit distance, and semantic similarity, illustrating their impact on AR model performance. By framing OOD generalization as a projection problem, we propose strategies to optimize these projections through meta-learning and nested optimization. Furthermore, we discuss the integration of classical information retrieval techniques and pre-trained language model embeddings to enhance the semantic relevance of projections. Our findings suggest that combining symbolic AI methods with deep learning representations can yield more interpretable and sample-efficient AR models, with broad applications in natural language processing, code generation, and scientific discovery.\n\n## Introduction\n\nThe infini-gram model is an autoregressive (AR) model that predicts the next token based on the longest suffix in the training data that matches the input. Essentially, they are finding some *projection* of the input to the training data to allow the AR model to generate coherent text continuations from inputs it has never seen before. This is known as out-of-distribution (OOD) generalization, where we are trying to generalize to tasks (like predict continuations of an input never seen before) that is not in the training data.\n\nSince the model converges in distribution to the data generating process (DGP) as the sample size goes to infinity, the key challenge is to find sample-efficient inductive biases that provide the model with more information about the task or the DGP, allowing it to generalize to OOD data more effectively and with fewer samples.\n\nIn this paper, we seek to formalize a class of inductive biases as *projections* of the input onto the training data.\n \n## AR Models\n\nAR models form a cornerstone in natural language processing, predicting the probability of a word $w_t$ given all preceding words $w_{<t}$ and the training data $D$:\n\n$$\n\\Pr\\!{}_D\\{w_t \\mid w_{<t}\\}.\n$$\n\nHistorically, the prefix $w_{<t}$ is limited to a fixed length $n$,\n\n$$\n\\Pr\\!{}_D\\{w_t \\mid w_{t-n:t}\\},\n$$\n\nwhere $a:b$ denotes the range $a, a+1, \\ldots, b-1$.\n\nInfini-gram models dynamically adjust the order of the  $n$-gram based on the longest suffix in the training data that matches the input:\n\n$$\n\\Pr\\!{}_D\\{w_t \\mid \\operatorname{longest\\_suffix}_D(w_{<t})\\},\n$$\n\nwhere $\\operatorname{longest\\_suffix}_D$ finds the longest suffix of the context $w_{<t}$ in the training data $D$.\n\nFor AR models to generate continuations of the input, $\\operatorname{longest\\_suffix}$ makes a lot of sense. It allows the model to find training data that is both similiar to the input and relevant to the task of predicting the next token from previous tokens.\n\nLet's be a bit formal about what $\\operatorname{longest\\_suffix}_D$ represents: it is a kind of *projection* of the input onto the training data $D$, which is an i.i.d. sample from some (unknown) data generating process (DGP). Let us denote the probability distribution of the DGP as $\\Pr{}_{\\!\\theta}$, where $\\theta$ are unknown parameters, and the probability distribution of the AR model as $\\Pr{}_{\\!\\hat\\theta}$, where $\\hat\\theta$ are the estimated parameters of the AR model based on the training data $D$.\n\nThe goal of the AR model is to estimate $\\theta$ from the training data, which will allow it to generalize to new data that the DGP would plausibly produce. A paricularly useful task is to predict what the DGP would plausibly produce *given* some input $w_{<t}$, where $w_{<t}$ is a sequence of tokens that the DGP has produced so far and may represent some task of interest, like \"What is the solution to \\<math problem\\>?\"\n\n\nThe distribution of $w_{t:t+k}$ conditioned on $w_{<t}$ is given by\n\n$$\n\\Pr{}_{\\!\\theta}\\{w_{t:t+k} \\mid w_{<t}\\} = \\frac{\\Pr{}_{\\!\\theta}\\{w_{1:(t+k)}\\}}{\\Pr{}_{\\!\\theta}\\{w_{1:t}\\}},\n$$\n\nwhere $w_{a:b}$ is a sub-sequence of tokens produced by the DGP from time $a$ to time $b$ (time is a *logical time* that just implies some ordering). The primary task is often to *generate* plausible continuations of the input, for which there are many possible *sampling* strategies to do this, like beam search, top-$k$ sampling, and nucleus sampling, all of which use the conditional probability distribution to generate continuations one token at a time. This approach is justfied by the chain rule of probability:\n\n$$\n\\Pr{}_{\\!\\theta}\\{w_t \\mid w_{<t}\\} = \\prod_{i=1}^t \\Pr{}_\\theta\\{w_i \\mid w_{<i}\\}.\n$$\n\nNotice that when we generate continuations of the input, we are not trying to find a sequence that *maximizes* the conditional probability:\n\n$$\nw_{t:(t+k)}^* = \\arg\\max_{w_{t:(t+k)}} \\Pr{}_{\\!\\theta}\\{w_{t:(t+k)} \\mid w_{<t}\\},\n$$\n\nbut rather we are *sampling* from the distribution. We identify a few justifications for doing this:\n\n1. The DGP $\\Pr{}_\\theta$ is often stochastic and we capture this stochasticity in our predictions or continuations. However, even if the DGP is not stochastic, we only have an uncertain estimate $\\Pr{}_{\\!\\hat\\theta}$ conditioned on data $D$ randomly sampled from data by the DGP. So, sampling from it is a way of generating continuations that reflect the uncertainty. See Appendix F: Bootstrapping the Sampling Distribution for a more rigorous way to estimate uncertainty in the model as opposed to the DGP.\n\n2. There is a trade-off between exploration and exploitation, where the model needs to balance between generating plausible continuations and exploring new possibilities.\n\n3. Finding the most likely sequence of tokens is NP-hard, so we often resort to approximate methods like greedily sampling from the conditional distribution one token at at time, or using more accurate but computationally expensive methods like beam search to find more likely sequences of tokens.\n\nSince we do know know the DGP $\\Pr_{\\!\\theta}$, we replace it with our AR model based on a training data $D$, $\\Pr{}_{\\!\\hat\\theta}$, and use the AR model to approximate the DGP. As the sample size goes to infinity, by the law of large numbers, the empirical distribution of the training data will converge to the true distribution of the DGP:\n\n$$\n\\Pr{}_{\\!\\hat\\theta}\\{w_t \\mid w_{<t}\\} \\rightarrow_d \\Pr{}_{\\!\\theta}\\{w_t \\mid w_{<t}\\}.\n$$\n\nThe Infini-gram model converges in distribution to the DGP, but we do not have *infinite* data. Thus, since virtually all inputs have never been senn before, we are interested in finding ways to allow the model to generalize *out-of-distribution* (OOD). On the task of next-token prediction, this means generating continuations of the input that the DGP would plausibly produce but are not in the training data.\n\nThis is a key challenge in machine learning. Ideally, we want the AR model to generate plausible continuations of any input from very small amounts of training data $D$. A primary way to do this is to *constrain* or *bias*, which we call an *inductive bias*.\n\nThe projection function $\\operatorname{longest\\_suffix}_D$ is an example of an inductive bias. It is a way for the model to find the most relevant part of the training data to the input to give it some ability to generalize OOD on the task of generating plausible continuations of the input.\n\nWe formalize this idea of projection as an inductive bias and discuss how it can be used to improve the sample efficiency of both $n$-gram models and AR models, like transformers, LSTMs, and RNNs.\n\n## Inductive Biases\n\nGiven two learning algorithms, $A$ and $B$, if $A$ requires fewer samples to do well on a task than $B$, then $A$ is more sample-efficient than $B$ on that task. In the context of $n$-gram models, the task is to predict the next token given a sequence of previous tokens. One way to improve sample efficiency is to choose an inductive bias that provides the model with more information about the task or the DGP, allowing it to generalize to OOD data more effectively and with fewer samples.\n\nThe $\\operatorname{longest\\_suffix}_D$ projection is an inductive bias that we might label the *recency bias*. The recency bias has some advantages:\n\n1. It is computationally efficient, as shown by the suffix array data structure used in the infini-gram model. It only requires a linear scan of the training data to find the longest suffix. This scalability is crucial for training on large datasets, as the time complexity of the recency bias is $O(n)$, where $n$ is the length of the context.\n\n2. It corresponds to a simple inductive bias that is easy to understand, implement, and justify. If the future is like the past, then the most recent past is often the most relevant data point. This is particularly relevant for tasks like language modeling, where the context is often a sequence of words that are related to each other in a temporal order and in which the most recent words are often the most relevant for predicting the next word.\n\nThe recency bias may not always help to find the most relevant context in the training data, e.g., the most relevant context may be at the start of a document. However, even when the most relevnat context is the most recent, the $\\operatorname{longest\\_suffix}$ may fail to properly use it. For example, if the context is `the dog ran after the` and we ask it to predict the next word, but the training data only contains `the dog chased the cat`, the longest suffix is the highly uninformative word `the`. We see that the naive longest suffix match fails to take into account slight variations, even if those slight variations have essentially identical meanings.\n\nThese challenges suggest some possible inductive biases that can be used to improve the OOD generalization of $\\Pr{}_{\\hat\\theta}$. We consider the set of inductive biases that can be formulated as *projections* of the input (context) onto the training data. Let us formally write down the problem of OOD generalization in the context of AR models as a projection problem:\n\n$$\n\\Pr\\!{}_D\\{w_t \\mid \\operatorname{proj}_D(w_{<t})\\},\n$$\nwhere $\\operatorname{proj}_D$ is a function that maps the input $w_{<t}$ to a subset of the training data $D$ that is most relevant for producing continuations of the $w_{<t}$ that the DGP would *likely* produce.\n\n## Learing the Projection Function\n\nLet us parameterize the projection function as\n\n$$\n\\mathcal{F} = \\{ \\operatorname{proj}_D(x; \\beta) \\mid \\beta \\in \\mathcal{B} \\},\n$$\n\nwhere $\\beta$ is an index or label that specifies the projection. For example, $\\beta = 1$ could be a label\nfor $\\operatorname{longest\\_suffix}_D$, or it could be something more complicated based on the\nspace of possible projections $\\mathcal{F}$.\n\nWe can choose a projection function from $\\mathcal{F}$ by choosing a $\\beta$ in $\\mathcal{B}$, which is frequently a discrete set of possible projections.\n\nWe choose the projection function in one or two ways:\n\n- Utilize domain-knowledge expertise (hand-crafted feature engineering). By lessons of the bitter kind, we observe that this appraoch often does not scale with increasing compute and data, as it requires human expertise that is often scarce and limited.\n\n- Treat it as an optimization (search or learning) problem, where $\\beta$ is a tunable parameter of the model.\n\nThe second approach is more general and can be used to optimize the projection function based on the data $D$ and the task we are measuring performance on. Note that because the projection function $\\operatorname{proj}_D(\\cdot;\\beta)$ is intended to improve OOD generalization performance, we do not optimize it on the training data $D$ but on a held-out test data $D'$.\n\nThe optimization problem is then conceptualized as an iterated two-stage process.\n\n1. **Initialize:** Set $i$ to $1$ and choose a $\\beta_0$ based on prior knowledge.\n\n2. **Stage 1:** Optimize the parameters of the AR model $\\theta$ on the training data $D$ using $\\operatorname{proj}_D(\\cdot;\\beta_{i-1})$:\n\n    $$\n    \\hat\\theta_i = \\arg\\max_{\\theta} \\prod_{t=1}^T \\Pr{}_{\\!\\theta}(w_t \\mid \\operatorname{proj}_{D}(w_{<t}; \\beta_{i-1})).\n    $$\n\n3. **Stage 2:** Optimize the parameters of the projection function indexed by $\\beta_i$ on the test data $D'$ using the AR model indexed by $\\hat\\theta_i$:\n    $$\n    \\hat\\beta_i = \\arg\\max_{\\beta} \\prod_{t=1}^T\n    \\Pr{}_{\\!\\hat\\theta_i}(w_t \\mid \\operatorname{proj}_{D'}(w_{<t}; \\hat\\beta_i)),\n    $$\n    where $D'$ is test data $D'$ (e.g., held-out test data) used to estimate the quality of the projection function.\n\n\n4. **Convergence Test:** If the parameters $\\hat\\theta_i$ and $\\hat\\beta_i$ have converged, stop. Otherwise, set $i = i + 1$ and go to step 2 (Stage 1).\n\nTo mitigate overfitting on the test data, we can use strategies like early stopping, where we stop the optimization process before convergence, or choose different test data at each iteration.\n\nIf the set of projection functions do not affect the performance of the AR model on the training data $D$, then convergence is obtained after one iteration. Since the parameters $\\beta$ and $\\theta$ are usually disjoint (they do no share parameters),\nthe primary way in which a projection function can affect the performance of the AR model on the training data is by changing the distribution of the training data that the AR model sees. For instance, $\\beta$ may include a parameter that limits the\nmaximum length of the context, which can change the parameters of the AR model that are estimated from the data.\n\nNext, we consider the space of possible projection functions $\\mathcal{F}$.\n\n## Hypothesis Space of Projection Functions (Inductive Biases)\n\nTo formalize notation, we denote the space of projection functions $\\mathcal{F}$ with the type\n\n$$\n    \\mathcal{T}^* \\mapsto \\mathcal{T}^*,\n$$\n\nwhere $\\mathcal{T}$ are the set of *tokens* (words, characters, etc.) and $\\mathcal{T}^*$ is the set of sequences of tokens. The projection function $\\operatorname{proj}_D$ maps a sequence of tokens to another sequence of tokens, which is (ideally) a subset of the training data $D$ such that the Infini-gram model can generate plausible continuations of the input based on suffix matches in the training data.\n\nThis space is of course too large to search over, so we need to make some assumptions about the structure of the space of projection functions. We can consider a few simple projection functions that can be used to improve the sample efficiency of AR models:\n\n1. **Recency Bias:** The recency bias is a simple projection function that finds the longest suffix of the input in the training data. It is a kind of *greedy* projection that assumes the most recent tokens are the most relevant for predicting the next token. The recency bias is a simple and computationally efficient inductive bias that can be used to improve the sample efficiency of AR models. This is the *default* behavior of the Infini-gram model, and by construction all other projection functions incorporate the recency bias.\n\n2. **Similarity Bias:** The similarity bias is a more complex projection function that finds the most similar sequence in the training data to the input. Because this could distort the input too much, we constrain the similarity bias to only apply so-called suffix extensions to the left.\n\n\nWe can draw inspiration from techniques developed in information retrieval (IR),\nnatural language processing (NLP), and classical AI informed search strategies\nto design projections (inductive biases) that yield more sample efficient\nalgorithms that improve OOD generalization. It is worth pointing out that in\nhigh-dimensional spaces, essentially every input is OOD, so designing effective\ninductive biases (projections) is crucial for generalization.\n\nSince the longest suffix projection function is already given, in the next section we consider ways to extend approximations of the input suffix to find longer and potentially more relevant context in the training data.\n\n## Extending The Suffix\n\nWhen we project the input onto the training data and obtain the longest matching suffix, we necessarily lose information about the rest of the input.\n\nWe have a predictive model, the Infini-gram model itself, that can be used to go extend the suffix in a way that projects onto the training data.\n\nLet us formalize this. We have an input $w_{<t}$ and a training data $D$. We project the input onto the training data to find the longest matching suffix $w_{t':t}$ in the training data, where $t' \\leq t$.\n\nWe know that $w_{t'-1:t}$ does not match the training data $D$ but the suffix $w_{t':t}$ does. Thus, $w_{t'-1}$ needs to be substituted\nfor a different token for the suffix to have a chance at finding a match in the training data. \n\nLet us denote this $t'-1$-th token as $w'_{t'-1}$. It is a random variable that we can sample from the AR model. That is, we can use the AR model to compute the conditional probability of $w'_{t'-1}$ given $w_{t':t}$ as a way of sampling extensions of the suffix to the left:\n\n$$\n\\Pr{}_{\\!\\hat\\theta}\\{w_{t'-1} \\mid w_{t':t}\\} = \\frac{\\Pr{}_{\\!\\hat\\theta}\\{w_{t'-1:t}\\}}{\\Pr{}_{\\!\\hat\\theta}\\{w_{t':t}\\}}.\n$$\n\nWe can compute joint probabilities using the AR model, and thus we can use the AR model to cosnider realizations of $w'_{t'-1}$ given $w_{t':t}$ that the model (training data) would likely produce.\n\nThis is mostly a *computational* trick, since we do not want to randomly sample tokens that are unlikely to be produced by the DGP (and thus unlikely to project onto the training data).\n\nWe may rewrite the conditional probability as:\n\n$$\n\\Pr{}_{\\!\\hat\\theta}\\{w'_{t'-1} \\mid w_{t':t}\\} \\propto \\Pr{}_{\\!\\hat\\theta}\\{w_{t'-1}\\} \\prod_{i=t'}^t \\Pr{}_{\\!\\hat\\theta}\\{w_i \\mid w_{t'-1:i}\\},\n$$\n\nwhich is something that the Infini-gram model can compute very efficiently. Thus, we can generate the conditional distribution of $w_{t'-1}$ given $w_{t':t}$ and sample from this distribution to consider suffix extensions.\n\nHowever, we have to have some similarity measure to determine when to stop extending the suffix, as we may end up with a very long suffix that is not very relevant to the input. We can use the earlier similarity measures discussed.\n\nWe can sample multiple left-extensions of the suffix, compute the similarity of each extension to the input, and use some strategy to either stop extending the suffix or to accept an extension based on the similarity to the input, such as $\\arg\\max$ or sampling based on the similarity.\n\n\n### Challenges\n\nLearning sample efficient representations of the data is the primary driver of OOD generalization. *Deep Learning* is about learning these representations from the data. We can use pre-trained models like BERT and GPT to learn representations of the data (sequences of tokens), also known as embeddings, that are a more sample-efficient representation than the token sequences in our Infini-gram model.\n\nIn particular, these embeddings can be used to compute the similarity between tokens. A canonical example is `word2vec`, which learns an embedding of words that allows a kind of semantic algebra on words such linear combinations of embeddings often result in\nmeaningful embeddings. The canoncial example is:\n\n$$\n\\operatorname{embed}(\\text{king}) - \\operatorname{embed}(\\text{man}) + \\operatorname{embed}(\\text{woman}) \\approx \\operatorname{embed}(\\text{queen}).\n$$\n\nWe can use these embeddings to compute the semnatic similarity between tokens, and\nthus try to find suffix extensions of the input that oth retain the meaning of the input and project onto the training data.\n\n#### Sequence Embeddings {-}\n\nSuffix extensions using token embeddings like `word2vec` may be too simplistic, as they operate at the level of atomic tokens. Most of the *meaning* of a sequence of tokens is in the relationships and order of the tokens, not just the tokens themselves. This is a well-studied problem in NLP, and there are many models that model the semantics of a language, from classical models \n\n#### Computational Complexity {-}\n\nIf we use LLM embeddings, it may be costly to compute the similarity between the input and all segments in the training data. We could, however, take the training data and compute embeddings for each segment and store them in a vector storage database for fast retrieval:\n\n$$\n\\operatorname{proj}_D(x;\\beta) = \\arg\\max_{y \\in \\operatorname{segments}_\\beta(D)} \\operatorname{similarity}_\\beta(\\operatorname{embed}(x), \\operatorname{embed}(y)),\n$$\n\nwhere $\\operatorname{embed}$ is a function that maps tokens or sequences to embeddings. Since we have all of the embeddings in a vector storage database, the above $\\arg\\max$ operation can be computed very efficiently at the cost of precomputing and storing the embeddings.\n\n\n## Uncertainty Estimation\n\nWhile infini-gram models provide point estimates for token probabilities, understanding the uncertainty in these estimates is crucial for robust decision-making and for gaining insights into model confidence. \n\nWe can apply bootstrapping to Infini-gram models by repeatedly sampling with replacement from the training data to create multiple bootstrap samples. For each sample, we train an Infini-gram model and use it to produce next-token probabilities for a given input. This process allows us to construct confidence intervals for our probability estimates.\n\nMore precisely, we estimate the *sampling* distribution of the model estimate by resampling from the data $D$. The bootstrapped sampling distribution is given by\n$$\n\\{\\hat\\theta^j\\}_{j=1}^R,\n$$\nwhere $R$ is the number of resamples (with replacement) from $D$ and\n$$\n\\hat\\theta_b^j = \\arg\\max_{\\theta} \\prod_{t=1}^T \\Pr{}_{\\!D^j}\\{w_t \\mid w_{<t}\\},\n$$\nis the $j$-th estimate based on the resampled data and $D^j$ is the $j$-th resample of the data $D$.\nSince $\\hat\\theta^j$ is an estimate of the model parameters based on the resampled data $D^j$, by the plug-in principle, we can estimate the sampling distribution of the model as\n$$\n\\Bigl \\{ \\Pr{}_{\\!\\hat\\theta^j} \\Bigr\\}_{j=1}^R.\n$$\n\n### Confidence Intervals\n\nTo generate confidence intervals of, say, the predictive\ndistribution of the model, we can sample a model from the sampling distribution and provide the input to the model to produce the set of next-token probabilities. We can do this $B$ times to get a set of $B$ next-token probabilities, and thus for each next-token, we can generate a confidence interval for its probability.\n\nThis is not easy to do with the neural language models because they are computationally expensive to train. For the Infini-gram model, we can just resample the documents in the training data $D$.\n\n### Implications for LLMs\n\nInterestingly, the confidence intervals derived from bootstrapped infini-gram models may provide valuable insights into the uncertainty of larger language models (LLMs) trained on the same data. While LLMs are more complex and capture higher-order dependencies, the fundamental uncertainties present in the training data should affect both types of models.\nFor instance, if an infini-gram model shows wide confidence intervals for certain contexts or token predictions, it suggests high variability or insufficient data in those areas. An LLM trained on the same data might also struggle with these contexts, even if it doesn't explicitly compute confidence intervals.\nThis connection opens up possibilities for using simpler, more interpretable models like infini-grams as proxies for understanding the uncertainties in more complex models. It could provide a computationally efficient way to estimate when an LLM might be less confident, without needing to compute expensive uncertainty estimates directly on the LLM itself.\n\nConsider a scenario where both an infini-gram model and an LLM are trained on a corpus of scientific papers. If the infini-gram model shows wide confidence intervals when predicting terms in a specific scientific domain, it might indicate that the LLM should also be less confident when generating content in that domain, even if the LLM doesn't explicitly calculate confidence intervals.\n\nWhile this approach shows promise, it's important to note that the relationship between infini-gram uncertainty and LLM uncertainty is not guaranteed to be straightforward. Factors such as the LLM's ability to leverage long-range dependencies and its more complex training process may lead to divergences. Future work could involve empirically studying the correlation between infini-gram confidence intervals and LLM performance or uncertainty estimates derived through other means.\n\n## Experimental Results\n\nWe can compare the performance of the recency bias, shortest edit distance, and semantic similarity bias on a language modeling task. We can use perplexity as a measure of the model's performance on the task, where lower perplexity indicates better performance.\n\n### Python Code\n\n\n```python\n# code here\n```\n\nFor more details, see the [GitHub repository](https://github.com/queelius/ngram-projections) for this project.\n\n\n## Conclusion\n\nWe have reframed of OOD generalization in the context of AR models as a context reduction and matching problem and explored various inductive biases to improve sample efficiency.\n\nEven hand-crafted inductive biases like the recency bias and similarity bias can significantly enhance AR models' performance, but utilizing learned embeddings from pre-trained models like BERT and GPT can likely yield more effective results.\n\nIn either case, we see that the goal is to reduce or rewrite the context to increase the probability of finding a match in the training data. This is a discrete optimization problem that can be solved using techniques from information retrieval and natural language processing, and so we can leverage these techniques to design more sample-efficient learning algorithms that search over the space of possible context reductions and rewrites to find the most relevant training data to facilitate OOD generalization.\n\nEven if an exact match is found in the training data, we often still want to explore a larger space of possibilities to make new discoveries and generate novel and creative outputs.\n\nFurther research into optimizing these techniques and seamlessly integrating them into AR frameworks promises to advance natural language processing, driving innovation in computational linguistics and machine learning, and help facilitate the development of more intelligent and creative AI systems that can be more easily explained and understood than current neural models, which are often seen as black boxes with inscrutable decision-making processes.\n\nBy leveraging a LLMs embeddings for sample efficient representatations and classical symbolic AI techniques for context reduction and matching, we can build more interpretable and efficient AR models that can be used in a wide range of applications, from chatbots to code generation to scientific discovery and beyond.\n\n\n## Appendices\n\n### A: Reward Functions {-}\n\nPreviously, we discussed the idea of projecting the input onto the training data to find the most relevant context for predicting the next token that the DGP is likely to produce.\n\nHowever, we are normally not interesed in predicting the next token, but *biasing* the model to generate outputs that are more likely to score well on some task. For example, if the task is to generate a coherent text continuation, we want to bias the model to generate text continuations that are coherent and correct, even if the the DGP, given the input, is more likely to generate very different continuations (e.g., toxic, incoherent, or incorrect).\n\nOne way to fine-tune the model to generate more effective outputs is to use a reward function that scores the outputs based on some task-specific criteria. A nearly universal approach is to take your reward function and\nproduce $k$ samples from the model, then score each sample using the reward function, and then sample these outputs based on their scores, e.g., $\\Pr{}_{\\hat\\theta}\\{w_{t:(t+k)} \\mid w_{<t}\\} \\propto \\exp\\{R(w_{1:(t+k)})\\}$.\n\nHowever, what if we want to go beyond predicting the DGP's next token and instead generate outputs that are more effective at solving a particular task?\n\n### B: Data Transformation {-}\n\nThe training data $D$ is the primary source of information we have about the DGP. However, the training data may not be in the optimal form for solving the task we have in mind.\n\nSo, a final inductive bias we can consider is data transformation. We can transform the training data into a more suitable form for solving the task at hand. One way which can be particularly effective at improving the\nsample efficiency of the model is to transform the training data into a more abstract representation space.\n\nThere are a lot of fancy things you can do, but in interest of transparency and interpretability, we will consider a simple transformation: stemming or lemmatization.\n\nBoth of these are computationally efficient techniques that reduce the vocabulary size and thus increase the probability of finding relevant projections of the input onto the training data. They are also simple to\nimplement and understand, making them a good choice for a first pass at data transformation.\n\nEssentially, this transformation allows for \"reasoning\" over more abstract representations of the DGP, facilitating OOD generalization but at a loss of some information and expressiveness.\n\n> Predictive modeling now takes place over this more abstract representation space, which can be more sample efficient. However, when we generate sequences, if the end product is, say, high-quality text, we may have to decode the stemmed or lemmatized representations back to unstemmed or unlemmatized forms, which can be a challenge.\n\n### C: Other Kinds of Inductive Biases {-}\n\nWe formalized most of our inductive biases as projections of the input onto the training data. However, we can consider other kinds of inductive biases that can be used to improve the sample efficiency of AR models\nthat directly affect the AR model's probabilty distribution.\n\nIn particular, we can also consider more complex inductive biases that involve pattern matching and context-free grammars. For example, we can use a context-free grammar to define the space of possible continuations of the input.\n\nIn theory, we could have a number of production rules on the input that restrict the set of possible continuations to some CFG. This is a more hand-crafted inductive bias that requires more domain knowledge and human expertise to implement, but it may be appropriate in some circumstances, such as when the task requires generating text that follows a specific structure or format, like JSON or Python code.\n\n### D: Similarity Bias: Shortest Edit Distance {-}\n\nShortest edit distance finds the shortest sequence of operations (e.g., swaps, insertions, deletions, and substitutions) transforming the current context $w_{<t}$ into a sequence in $D$.\n\nThe recency bias can be seen as a special case of the similarity bias where we only allow deletions from the end of the context until a match is found.\n\nA justification for using shortest edit distance is based on the idea of similarity: if two sequences are similar, they are more likely to have similar continuations. Edit distance is a way to measure the similarity between two sequences based on the minimum number of operations needed to transform one into the other.\n\n#### Example {-}\n\nLet's use the earlier example, where we have as input \"the dog ran after the\" and the training data\n$D$ contains the following:\n\n1. \"a dog chased the cat in the garden\"\n2. \"the dog chased the cat, but the cat climbed a tree and got away\"\n3. \"the mouse ran from the cheese trap after setting it off\"\n\nThe longest suffix is \"the\". What is shortest edit distance to find a match in the training data? We can perform the following two edits: substitute \"ran\" with \"chased\" and delete \"after\", resulting in \"the dog chased the\" which has a longest suffix match equal to \"the dog chased the\" (2), and so the next\ntoken predicted is \"cat\". Thus, a completion by the model might be: \"the dog ran after the cat, but the cat climbed a tree and got away\". The training data does not contain this completion, but the shortest edit distance found a *relevant* projection to the training data.\n\nWhat else could we have found within two edits? We could have substituted \"dog\" with \"mouse\" and \"after\" with \"from\", resulting in the input \"the mouse ran from the\" and the completion \"the dog ran after the cheese trap after setting it off\". This is a less plausible completion for the DGP, and things could go much worse, but we see that just counting the number of edits can lead to a poor projection onto the training data.\n\n#### Challenges {-}\n\nAs the example demonstrated, a primary challenge with shortest edit distance is that it treats all single edits as having a uniform cost. Ideally, when we edit the input, we want to preserve the \"meaning\" of the context. Thus, some edits should be more costly than others, based on how much they change the meaning\nof the input.\n\nAlso, the shortest (least-cost) edit distance, particularly when we combine it with non-uniform costs, is more computationally intensive than the longest prefix projection. However, it is tractable, e.g., graph\nsearch in GOFAI. Approximate methods like Monte Carlo Tree Search (MCTS) can also be used to find\napproximate solutions.\n\n### E: Semantic Similarity: Least-Cost Edit Distance {-}\n\nA significant issue with *shortest edit distance* is that it treats each edit as having a uniform cost (a kind of uninformed search). A simple extension is to add a cost to each edit based on some measure of semantic similarity between tokens or sequences.\n\nOnce we have a cost in place, we can use classical search techniques, like A* search, to find relevant sequences in the training data to the current context.\n\nClassical IR (Information Retrieval) techniques like BM25, query expansion, and semantic similarity measures can be used to assign costs to edits.\n\n1. Input expansion (query expansion): Expand the input to multiple possible sequences that are similar to the input.\n\n2. Treat the input like a search query in IR and use BM25 or other similarity measures to find the most similar sequences in the training data. We then define the projection function as:\n\n$$\n\\operatorname{proj}_D(x;\\beta) = \\arg\\max_{y \\in \\operatorname{segments}_\\beta(D)} \\operatorname{similarity}_\\beta(x, y),\n$$\n\nwhere $\\operatorname{segments}_\\beta(D)$ is a segmentation strategy of the data $D$ into segments (e.g., sentences paragraphs) and $\\operatorname{similarity}_\\beta$ is a similarity measure between the input $x$ and the segment $y$, e.g., cosine similarity or Euclidean distance between embeddings or some tf-idf measure, like BM25.\n\nWe can use the inferred $\\beta$ to find the most relevant segments in the training data to the input, and then use the AR model to generate continuations of the input based on these segments.\n"
    },
    {
        "id": 637221012,
        "node_id": "R_kgDOJfs4lA",
        "name": "numerical.mle",
        "full_name": "queelius/numerical.mle",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/numerical.mle",
        "description": "Numerical MLE solvers",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/numerical.mle",
        "forks_url": "https://api.github.com/repos/queelius/numerical.mle/forks",
        "keys_url": "https://api.github.com/repos/queelius/numerical.mle/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/numerical.mle/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/numerical.mle/teams",
        "hooks_url": "https://api.github.com/repos/queelius/numerical.mle/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/numerical.mle/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/numerical.mle/events",
        "assignees_url": "https://api.github.com/repos/queelius/numerical.mle/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/numerical.mle/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/numerical.mle/tags",
        "blobs_url": "https://api.github.com/repos/queelius/numerical.mle/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/numerical.mle/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/numerical.mle/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/numerical.mle/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/numerical.mle/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/numerical.mle/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/numerical.mle/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/numerical.mle/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/numerical.mle/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/numerical.mle/subscription",
        "commits_url": "https://api.github.com/repos/queelius/numerical.mle/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/numerical.mle/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/numerical.mle/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/numerical.mle/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/numerical.mle/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/numerical.mle/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/numerical.mle/merges",
        "archive_url": "https://api.github.com/repos/queelius/numerical.mle/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/numerical.mle/downloads",
        "issues_url": "https://api.github.com/repos/queelius/numerical.mle/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/numerical.mle/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/numerical.mle/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/numerical.mle/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/numerical.mle/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/numerical.mle/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/numerical.mle/deployments",
        "created_at": "2023-05-06T22:02:22Z",
        "updated_at": "2024-12-10T09:51:53Z",
        "pushed_at": "2023-05-06T22:05:53Z",
        "git_url": "git://github.com/queelius/numerical.mle.git",
        "ssh_url": "git@github.com:queelius/numerical.mle.git",
        "clone_url": "https://github.com/queelius/numerical.mle.git",
        "svn_url": "https://github.com/queelius/numerical.mle",
        "homepage": "https://queelius.github.io/numerical.mle/",
        "size": 521,
        "stargazers_count": 1,
        "watchers_count": 1,
        "language": "R",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "other",
            "name": "Other",
            "spdx_id": "NOASSERTION",
            "url": null,
            "node_id": "MDc6TGljZW5zZTA="
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [
            "estimation",
            "mle",
            "mle-estimation",
            "numerical-methods",
            "statistics"
        ],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 1,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 2
            }
        ],
        "readme_content": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# R package: `numerical.mle`\n\n<!-- badges: start -->\n\n<!-- badges: end -->\n\nA set of numeric MLE solvers.\n\nThis is very early alpha. I just started this project and it is not\nready for use yet. I just took a bunch of numerical code from\n`algebraic.mle` and put it in this separate package. I will be adding\nmore numerical solvers and more examples in the future. Most of the code\nprobably does not even work yet, since I haven\u2019t tested it.\n\n## Installation\n\nYou can install `numerical.mle` from\n[GitHub](https://github.com/queelius/numerical.mle) with:\n\n``` r\ninstall.packages(\"devtools\")\ndevtools::install_github(\"queelius/numerical.mle\")\n```\n\n## API\n\nA set of methods for fitting log-likelihood functions to data. We\nprovide various adapters for log-likelihood functions, including penalty\nadapters (for constrained MLEs) and transformation adapters (for\ntransformed MLEs).\n\nThe object representing a fitted model is a type of `mle` object, the\nmaximum likelihood estimator of the model with respect to observed data.\nWe use the R package for this purpose. (See\n[here](https://github.com/queelius/algebraic.mle)).\n\nThe API mostly consists of generic methods with implementations for\nvarious `mle` type objects. For a full list of functions, see the\n[function\nreference](https://queelius.github.io/numerical.mle/reference/index.html)\nfor `numerical.mle`.\n\n## Examples\n\n### Fitting a linear regression model\n\n``` r\nlibrary(numerical.mle)\nlibrary(algebraic.mle)\n```\n",
        "github_pages": "https://queelius.github.io/numerical.mle/"
    },
    {
        "id": 165661060,
        "node_id": "MDEwOlJlcG9zaXRvcnkxNjU2NjEwNjA=",
        "name": "rd_ph_filter",
        "full_name": "queelius/rd_ph_filter",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/rd_ph_filter",
        "description": null,
        "fork": false,
        "url": "https://api.github.com/repos/queelius/rd_ph_filter",
        "forks_url": "https://api.github.com/repos/queelius/rd_ph_filter/forks",
        "keys_url": "https://api.github.com/repos/queelius/rd_ph_filter/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/rd_ph_filter/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/rd_ph_filter/teams",
        "hooks_url": "https://api.github.com/repos/queelius/rd_ph_filter/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/rd_ph_filter/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/rd_ph_filter/events",
        "assignees_url": "https://api.github.com/repos/queelius/rd_ph_filter/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/rd_ph_filter/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/rd_ph_filter/tags",
        "blobs_url": "https://api.github.com/repos/queelius/rd_ph_filter/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/rd_ph_filter/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/rd_ph_filter/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/rd_ph_filter/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/rd_ph_filter/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/rd_ph_filter/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/rd_ph_filter/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/rd_ph_filter/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/rd_ph_filter/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/rd_ph_filter/subscription",
        "commits_url": "https://api.github.com/repos/queelius/rd_ph_filter/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/rd_ph_filter/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/rd_ph_filter/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/rd_ph_filter/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/rd_ph_filter/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/rd_ph_filter/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/rd_ph_filter/merges",
        "archive_url": "https://api.github.com/repos/queelius/rd_ph_filter/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/rd_ph_filter/downloads",
        "issues_url": "https://api.github.com/repos/queelius/rd_ph_filter/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/rd_ph_filter/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/rd_ph_filter/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/rd_ph_filter/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/rd_ph_filter/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/rd_ph_filter/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/rd_ph_filter/deployments",
        "created_at": "2019-01-14T12:52:04Z",
        "updated_at": "2023-03-18T01:09:41Z",
        "pushed_at": "2023-06-19T21:52:04Z",
        "git_url": "git://github.com/queelius/rd_ph_filter.git",
        "ssh_url": "git@github.com:queelius/rd_ph_filter.git",
        "clone_url": "https://github.com/queelius/rd_ph_filter.git",
        "svn_url": "https://github.com/queelius/rd_ph_filter",
        "homepage": null,
        "size": 1835,
        "stargazers_count": 1,
        "watchers_count": 1,
        "language": "TeX",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 1,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 43
            }
        ],
        "readme_content": "Rate-distorted perfect hash filter\r\n==================================\r\n\r\nThe library `rd_ph_filter`, which standards for rate-distorted perfect hash filter,\r\nmodels the concept of a bernoulli set. It is a very practical implementation of\r\nthe concept.\r\n\r\nThe rate-distortion occurs in two independent ways, yielding two different types\r\nof rate-distortion. The first distortion is given by perfectly hashing each element\r\nof the objective set, and then storing its hash (not the perfect hash, but a\r\nstandard hash) at the index the perfect hash function assigns to it. There is a\r\nsmall chance that a random element not in the objective set will hash to the same\r\nvalue. This causes a type of rate distortion denoted the false positive rate.\r\n\r\nThe second kind of rate distortion occurs as a function of the rate-distortion in the\r\nperfect hash function. If the perfect hash function fails to perfectly hash a particular\r\nelement of the objective set, then it will collide with another element in the objective\r\nset. When this occurs, most likely it will fail to test positive for membership.\r\nThis type of rate distortion is known as the false negative rate.\r\n\r\nThere is an opportunity to store the hashes in an arbitrary whole number of bits\r\nwith something like a *packed matrix*, but we did not consider it\r\nworth the extra cost to implement for this particular data structure.\r\n"
    },
    {
        "id": 665913386,
        "node_id": "R_kgDOJ7EIKg",
        "name": "reliability-estimation-in-series-systems",
        "full_name": "queelius/reliability-estimation-in-series-systems",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/reliability-estimation-in-series-systems",
        "description": "Reliability Estimation in Series Systems: Maximum Likelihood Techniques for Right-Censored and Masked Failure Data",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems",
        "forks_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/forks",
        "keys_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/teams",
        "hooks_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/events",
        "assignees_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/tags",
        "blobs_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/subscription",
        "commits_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/merges",
        "archive_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/downloads",
        "issues_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/reliability-estimation-in-series-systems/deployments",
        "created_at": "2023-07-13T09:25:36Z",
        "updated_at": "2024-08-23T12:36:55Z",
        "pushed_at": "2024-08-23T12:36:51Z",
        "git_url": "git://github.com/queelius/reliability-estimation-in-series-systems.git",
        "ssh_url": "git@github.com:queelius/reliability-estimation-in-series-systems.git",
        "clone_url": "https://github.com/queelius/reliability-estimation-in-series-systems.git",
        "svn_url": "https://github.com/queelius/reliability-estimation-in-series-systems",
        "homepage": "https://queelius.github.io/reliability-estimation-in-series-systems",
        "size": 252948,
        "stargazers_count": 1,
        "watchers_count": 1,
        "language": "HTML",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": false,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 1,
        "default_branch": "bookdown",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 297
            }
        ],
        "readme_content": "\n![bg left height:7in](pres/title.png)\n\n## Reliability Estimation in Series Systems: Maximum Likelihood Techniques for Right-Censored and Masked Failure Data\n\nAlex Towell\nEmail: [lex@metafunctor.com](mailto:lex@metafunctor.com)\nGitHub: [github.com/queelius](https://github.com/queelius)\n\n---\n## Abstract\n\n> This paper investigates maximum likelihood techniques to estimate component reliability from masked ailure data in series systems. A likelihood model accounts for right-censoring and candidate sets indicative of masked failure causes. Extensive simulation studies assess the accuracy and precision of maximum likelihood estimates under varying sample size, masking probability, and right-censoring time for components with Weibull lifetimes. The studies specifically examine the accuracy and precision of estimates, along with the coverage probability and width of BCa confidence intervals. Despite significant masking and censoring, the maximum likelihood estimator demonstrates good overall performance. The bootstrap yields correctly specified confidence intervals even for small sample sizes. Together, the modeling framework and simulation studies provide rigorous validation of statistical learning from masked reliability data.\n\nSee: [https://github.com/queelius/reliability-estimation-in-series-systems/blob/bookdown/pdfbook/AlexTowellPaper.pdf](https://github.com/queelius/reliability-estimation-in-series-systems/blob/bookdown/pdfbook/AlexTowellPaper.pdf)\n\n---\n\n## Context & Motivation\n\n**Reliability** in **Series Systems** is like a chain's strength -- determined\nby its weakest link.\n- Essential for system design and maintenance.\n \n**Main Goal**: Estimate individual component reliability from *failure data*.\n\n**Challenges**:\n\n- *Masked* component-level failure data.\n- *Right-censoring* system-level failure data.\n\n**Our Response**:\n\n- Derive techniques to interpret such ambiguous data.\n- Aim for precise and accurate reliability estimates for individual components\n  using maximum likelihood estimation (MLE)\n- Quantify uncertainty in estimates with bootstrap confidence intervals (CIs).\n\n---\n## Core Contributions\n\n**Likelihood Model** for **Series Systems**.\n\n- Accounts for *right-censoring* and *masked component failure*.\n\n**Specifications of Conditions**:\n\n- Assumptions about the masking of component failures.\n- Simplifies and makes the model more tractable.\n\n**Simulation Studies**:\n\n- Components with *Weibull* lifetimes.\n- Evaluate MLE and confidence intervals under different scenarios.\n\n**R Library**: Methods available on GitHub.\n\n- See: [www.github.com/queelius/wei.series.md.c1.c2.c3](https://github.com/queelius/wei.series.md.c1.c2.c3)\n\n---\n## What Is A Series System?\n\n![100%\"](pres/series-white-bg.png)\n\n**Critical Components**: Complex systems often comprise *critical* components.\nIf any component fails, the entire system fails.\n\n- We call such systems *series systems*.\n- **Example**: A car's engine and brakes.\n\n**System Lifetime** is dictated by its shortest-lived component:\n\n$$\nT_i = \\min(T_{i 1}, \\ldots, T_{i 5})\n$$\n\nwhere:\n\n- $T_i$ is the lifetime of $i^{\\text{th}}$ system.\n- $T_{i j}$ is the $j^{\\text{th}}$ component of $i^{\\text{th}}$ system.\n\n---\n## Reliability Function\n\n**Reliability Function** represents the probability that a system or component functions\nbeyond a specified time.\n\n- Essential for understanding longevity and dependability.\n\n**Series System Reliability**: Product of the reliability of its components:\n\n$$\nR_{T_i}(t;\\theta) = \\prod_{j=1}^m R_j(t;\\theta_j).\n$$\n\n- If any component has low reliability, it can impact the whole system.\n\n- Here, $R_{T_i}(t;\\theta)$ and $R_j(t;\\theta_j)$ are the reliability\n  functions for the system $i$ and component $j$, respectively.\n\n---\n## Hazard Function: Understanding Risks\n\n**Hazard Function**: Measures the immediate risk of failure at a given time,\nassuming survival up to that moment.\n\n- Reveals how the risk of failure evolves over time.\n- Guides maintenance schedules and interventions.\n\n**Series System Hazard Function**: Sum of the component hazard functions:\n\n$$\nh_{T_i}(t;\\theta) = \\sum_{j=1}^m h_j(t;\\theta_j).\n$$\n\n- Components' risks are additive.\n\n---\n## Joint Distribution of Component Failure and System Lifetime\n\nOur likelihood model depends on the **joint distribution** of the system\nlifetime and the component that caused the failure.\n\n- **Formula**: Product of the failing component's hazard function and the system reliability function:\n\n$$\nf_{K_i,T_i}(j,t;\\theta) = h_j(t;\\theta_j) R_{T_i}(t;\\theta).\n$$\n\n- Here, $K_i$ denotes component cause of $i^{\\text{th}}$ system's failure.\n\n---\n## Component Cause of Failure\n\nWe can use the joint distribution to calculate the probability of component\ncause of failure.\n\n- Helps predict the cause of failure.\n- **Derivation**: Marginalize the joint distribution over the system lifetime:\n\n$$\n\\Pr\\{K_i = j\\} = E_{\\theta} \\biggl[ \\frac{h_j(T_i;\\theta_j)} {h_{T_i}(T_i;\\theta_l)} \\biggr].\n$$\n\n- **Well-Designed Series System**: Components exhibit comparable chances of\ncausing system failures.\n- **Relevance**: Our simulation study employs a (reasonably) well-designed\nseries system.\n\n---\n## Likelihood Model: Data Generating Process\n\n![bg left width:6.4in](pres/dep-model-white-bg.png)\n\nThe data generating process (DGP) is the underlying process that generates the data.\n*Green* elements are observed, *red* elements are latent:\n\n- **Right-Censored** lifetime: $S_i = \\min(T_i, \\tau_i)$\n- **Event Indicator**: $\\delta_i = 1_{\\{T_i < \\tau_i\\}}$\n- **Candidate Set**: $\\mathcal{C}_i$ related to components\n\n---\n# Likelihood Function\n\n**Likelihood Function** measures how well model explains the data:\n\n- **Right-Censored** data ($\\delta_i = 0$).\n- **Candidate Sets** or **Masked Failure** data ($\\delta_i = 1$)\n\n## Masked Data\n\n| Sys | Right-Censored Lifetime ($S_i$) | Event ($\\delta_i$) | Candidate ($\\mathcal{C}_i$) |\n|--------|---------------------------------|------------------------------|------------------------------|\n| 1      | $1.1$                           | 1                            | $\\{1,2\\}$                    |\n| 2      | $5$                             | 0                            | $\\emptyset$                  |\n\n---\n## Likelihood Function: Total Likelihood\n\nEach system contributes to *total likelihood* via its *likelihood contribution*:\n\n$$\nL(\\theta|\\text{data}) = \\prod_{i=1}^n L_i(\\theta|\\text{data}_i)\n$$\n\nwhere data$_i$ is for $i^{\\text{th}}$ system and $L_i$ is its contribution.\n\n---\n## Likelihood Contribution: Right-Censoring\n\n**Right-Censoring**: For the $i^{\\text{th}}$ system, if right-censored ($\\delta_i = 0$)\nat duration $\\tau$, its likelihood contribution is proportional to the system reliability function evaluated at $\\tau$:\n\n$$\nL_i(\\theta) \\propto R_{T_i}(\\tau;\\theta).\n$$\n\n- We only know that a failure occurred after the right-censoring time.\n- This is captured by the system reliability function.\n\n**Key Assumptions**:\n\n- Censoring time ($\\tau$) independent of parameters.\n- Event indicator ($\\delta_i$) is observed.\n- **Reasonable** in many cases, e.g., right-censoring time $\\tau$ predetermined by length of study.\n\n---\n## Likelihood Contribution: Candidate Sets\n\n**Masking Component Failure**: If the $i^{\\text{th}}$ system fails ($\\delta_i = 1$),\nit is masked by a candidate set $\\mathcal{C}_i$. Its likelihood contribution is complex and\nwe use simplifying assumptions to make it tractable.\n\n- **Condition 1**: The candidate set includes the failed component: $\\Pr\\\\{K_i \\in \\mathcal{C}_i\\\\} = 1$.\n\n---\n## Likelihood Contribution: Candidate Sets (Cont'd)\n- **Condition 2**: The condition probability of a candidate set given a cause of failure and a system lifetime is constant across conditioning on different failure causes within the candidate set: \n\n$$\n\\Pr\\\\{C_i = c_i | T_i = t_i, K_i = j\\\\} = \\Pr\\\\{C_i = c_i | T_i = t_i, K_i = j'\\\\} \\text{ for $j,j' \\in c_i$.}\n$$\n\n- **Condition 3**: The masking probabilities when conditioned on the system lifetime and the failed component aren't functions of the system parameter.\n\n---\n### Likelihood Contribution: Derivation for Candidate Sets\n\nTake the **joint distribution** of $T_i$, $K_i$, and $\\mathcal{C}_i$ and marginalize over $K_i$:\n\n$$\nf_{T_i,C_i}(t_i,c_i;\\theta) = \\sum_{j=1}^m f_{T_i,K_i}(t_i,j;\\theta)\\Pr{}_{\\!\\theta}\\\\{C_i = c_i | T_i = t_i, K_i = j\\\\}.\n$$\n\nApply **Condition 1** to get a sum over candidate set:\n\n$$\nf_{T_i,C_i}(t_i,c_i;\\theta) = \\sum_{j \\in c_i} f_{T_i,K_i}(t_i,j;\\theta)\\Pr{}_{\\theta}\\\\{C_i = c_i | T_i = t_i, K_i = j\\\\}.\n$$\n\n---\n### Likelihood Contribution: Derivation for Candidate Sets (Cont'd)\n\nApply **Condition 2** to move probability outside the sum:\n\n$$\nf_{T_i,C_i}(t_i,c_i;\\theta) = \\Pr_{\\theta} \\\\{C_i = c_i | T_i = t_i, K_i = j'\\\\}\n  \\sum_{j \\in c_i} f_{T_i,K_i}(t_i,j;\\theta).\n$$\n\nApply **Condition 3** to remove the masking probability's dependence on $\\theta$:\n\n$$\nf_{T_i,C_i}(t_i,c_i;\\theta) = \\beta_i \\sum_{j \\in c_i} f_{T_i,K_i}(t_i,j;\\theta).\n$$\n\n**Result**: $L_i(\\theta) \\propto \\sum_{j \\in c_i} f_{T_i,K_i}(t_i,j;\\theta) = R_{T_i}(t_i;\\theta) \\sum_{j \\in c_i} h_j(t_i;\\theta_j)$.\n\n---\n## Bootstrap Confidence Intervals (CIs)\n\n**Confidence Intervals (CI)** help capture the *uncertainty* in our estimate.\n\n- **Normal** assumption for constructing CIs may not be accurate.\n  - *Masking* and *censoring*.\n- **Bootstrapped CIs**: Resample data and obtain MLE for each.\n  - Use **percentiles** of bootstrapped MLEs for CIs.\n- **Coverage Probability**: Probability the interval covers the true parameter value.\n  - **Challenge**: Actual coverage may deviate to bias and skew in MLEs.\n- **BCa** adjusts the CIs to counteract bias and skew in the MLEs.\n\n---\n## Challenges with Masked Data\n\nLike any model, ours has its challenges:\n\n- **Convergence Issues**: Nearly flat likelihood regions can occur.\n  - Ambiguity in masked, censored data\n  - Complexities of estimating latent parameters.\n\n- **Bootstrap Issues**: Relies on the empirical sampling distribution.\n  - May not represent true variability for small samples.\n  - *Censoring* and *masking* compound issue by reducing the **effective** sample size.\n\n---\n## Challenges with Masked Data (Cont'd)\n\n- **Mitigation**: In simulation, discard non-convergent samples for MLE on\n  original data but retain all resamples for CIs.\n  - More robust assessment at the cost of possible bias towards \"well-behaved\" data.  \n  - **Convergence Rates** reported to provide context.\n\n---\n# Simulation Study: Series System with Weibull Components\n\nWe consider the following series system parameters in our simulation study.\n\n| Component | Shape $(k_j)$ | Scale ($\\lambda_j$) | Failure Probability ($\\Pr\\{K_i\\}$) |\n|-----------|-------|--------|--------------|\n| 1         | 1.26  | 994.37 | 0.17         |\n| 2         | 1.16  | 908.95 | 0.21         |\n| 3         | 1.13  | 840.11 | 0.23         |\n| 4         | 1.18  | 940.13 | 0.20         |\n| 5         | 1.20  | 923.16 | 0.20         |\n\n---\n\n## Series System Parameters (Cont'd)\n\n**Lifetime** of $j^{\\text{th}}$ component of $i^{\\text{th}}$ system: $T_{i j} \\sim \\mathrm{Weibull}(k_j,\\lambda_j)$.\n\n- Based on (Guo, Niu, and Szidarovszky 2013)\n- Extended to include components 4 and 5\n  - Shapes greater than 1 indicates wear-outs.\n  - Probabilities comparable: reasonably **well-designed**.\n- Focus on Components 1 and 3 (most and least reliable) in study.\n\n---\n## Synthetic Data and Simulation Values\n\nHow is the data generated in our simulation study?\n\n- **Component Lifetimes** (latent $T_{i 1}, \\cdots, T_{i m}$) generated for each system.\n  - **Observed Data** is a function of latent components.\n- **Right-Censoring** amount controlled with simulation value $q$.\n  - Quantile $q$ is probability system won't be right-censored.\n  - Solve for right-censoring time $\\tau$ in $\\Pr\\\\{T_i \\leq \\tau\\\\} = q$.\n  - $S_i = \\min(T_i, \\tau)$ and $\\delta_i = 1_{\\\\{T_i \\leq \\tau\\\\}}$.\n- **Candidate Sets** are generated using the *Bernoulli Masking Model*.\n  - Masking level controlled with simulation value $p$.\n  - Failed component (latent $K_i$) placed in candidate set (observed $\\mathcal{C}_i$).\n  - Each functioning component included with probability $p$.\n\n---\n## Bernoulli Masking Model: Satisfying Masking Conditions\n\nThe Bernoulli Masking Model *satisfies* the masking conditions:\n\n- **Condition 1**: The failed component deterministically placed in candidate set. \n- **Condition 2** and **3**: Bernoulli probability $p$ is same for all components\nand fixed by us.\n  - Probability of candidate set is constant conditioned on component failure within set.\n  - Probability of candidate set, conditioned on a component failure, only\n    depends on the $p$.\n\n**Future Research**: Realistically conditions may be violated.\n\n  - Explore sensitivity of likelihood model to violations.\n\n---\n## Performance Metrics\n\n**Objective**: Evaluate the MLE and BCa confidence intervals' performance across\nvarious scenarios.\n\n- Visualize the **simulated** sampling distribution of MLEs and $95\\\\%$ CIs.\n- **MLE Evaluation**:\n  - **Accuracy**: Bias \n  - **Precision**: Dispersion of MLEs\n    - $95\\\\%$ quantile range of MLEs.\n- **95\\\\% CI Evaluation**:\n  - **Accuracy**: Coverage probability (CP).\n    - *Correctly Specified* CIs: CP near $95\\\\%$ ($>90\\\\%$ acceptable).\n  - **Precision**: Width of median CI.\n  \n---\n## Scenario: Impact of Right-Censoring\n\nAssess the impact of right-censoring on MLE and CIs.\n\n- **Right-Censoring**: Failure observed with probability $q$: $60\\\\%$ to $100\\\\%$.\n  - Right censoring occurs with probability $1-q$: $40\\\\%$ to $0\\\\%$.\n- **Bernoulli Masking Probability**: Each component is a candidate with probability $p$ fixed at $21.5\\\\%$.\n  - Estimated from original study (Guo, Niu, and Szidarovszky 2013).  \n- **Sample Size**: $n$ fixed at $90$.\n  - Small enough to show impact of right-censoring.\n\n---\n## Scale Parameters\n\n\n![height:4.25in](pres/plot-q-vs-scale.1-mle_plot-q-vs-scale.3-mle.png)\n\n- **Dispersion**: Less censoring improves MLE precision.\n  - Most reliable component more affected by censoring.\n- **Bias**: MLE *positively* biased; decreases with less censoring.\n- **Median CIs**: Tracks MLE dispersion.\n\n\n---\n## Shape Parameters\n\n![height:5.2in](pres/plot-q-vs-shape.1-mle_plot-q-vs-shape.3-mle.png)\n\n- Show a similar pattern as scale parameters.\n\n---\n## Coverage Probability and Convergence Rate\n\n\n![height:4in](pres/plot-q-vs-cp_q_vs_convergence.png)\n\n- **Coverage** (left figure): CIs show good empirical coverage.\n  - Scale parameters *correctly specified* (CP $\\approx 95\\\\%$)\n  - Shape parameters *good enough* (CP $> 90\\\\%$).\n- **Convergence Rate** (right figure): Increases with less censoring.\n  - **Caution**: Dips below $95\\\\%$ with more than $30\\\\%$ censoring.\n\n---\n## Key Takeaways: Right-Censoring\n\nRight-censoring has a notable impact on the MLE:\n\n- **MLE Precision**:\n  - Improves notably with reduced right-censoring levels.\n  - More reliable components benefit more from reduced right-censoring.\n- **Bias**:\n  - MLEs show positive bias, but decreases with reduced right-censoring.\n- **Convergence Rates**:\n  - MLE convergence rate improves with reduced right-censoring.\n  - Dips: $< 95\\\\%$ at $> 30\\\\%$ right-censoring.\n\nBCa confidence intervals show good empirical coverage.\n\n  - CIs offer reliable *empirical coverage*.\n  - Scale parameters *correctly specified* across all right-censoring levels.\n\n---\n## Scenario: Impact of Failure Masking\n\nAssessing the impact of the failure masking level on MLE and CIs.\n\n- **Bernoulli Masking Probability**: Vary Bernoulli probability $p$ from $10\\\\%$ to $70\\\\%$.\n- **Right-Censoring**: $q$ fixed at $82.5\\\\%$.\n  - Right-censoring occurs with probability $1-q$: $17.5\\\\%$.\n  - Censoring less prevalent than masking.\n- **Sample Size**: $n$ fixed at $90$.\n  - Small enough to show impact of masking.\n\n---\n### Shape Parameters\n\n![height:4.5in](pres/plot-p-vs-shape.1-mle_plot-p-vs-shape.3-mle.png)\n\n- **Dispersion**: Precision decreases with masking level ($p$).\n- **Bias**: MLE *positively* biased and increases with masking level.\n  - Applies a right-censoring like effect to the components.\n- **Median CIs**: Tracks MLE dispersion.\n\n---\n### Scale Parameters\n\n![height:5.2in](pres/plot-p-vs-scale.1-mle_plot-p-vs-scale.3-mle.png)\n\n- These graphs resemble the last ones for shape parameters.\n\n---\n### Coverage Probability and Convergence Rate\n\n![width:8in](pres/plot-p-vs-cp_p_vs_convergence.png)\n\n- **Coverage**: Caution advised for severe masking with small samples.\n  - Scale parameter CIs show acceptable coverage across all masking levels.\n  - Shape parameter CIs dip below $90\\\\%$ when $p > 0.4$.\n- **Convergence Rate**: Increases with less masking.\n  - **Caution**: Dips under $95\\\\%$ when $p > 0.4$ (consistent with CP behavior).\n\n---\n### Key Takeaways: Masking\n\nThe masking level of component failures profoundly affects the MLE:\n\n- **MLE Precision**:\n  - Decreases with more masking.\n- **MLE Bias**:\n  - Positive bias is amplified with increased masking.\n  - Masking exhibits a right-censoring-like effect.\n- **Convergence Rate**:\n  - Commendable for Bernoulli masking levels $p \\leq 0.4$.\n    - *Extreme* masking: some masking occurs $90\\\\%$ of the time at $p = 0.4$.\n\nThe BCa confidence intervals show good coverage:\n\n- **Scale** parameters maintain good coverage across all masking levels.\n- **Shape** parameter coverage dip below $90\\\\%$ when $p > 0.4$.\n  - Caution advised for severe masking with small samples.\n\n---\n## Scenario: Impact of Sample Size\n\nAssess the mitigating affects of sample size on MLE and CIs.\n\n- **Sample Size**: We vary the same size $n$ from 50 to 500..\n- **Right-Censoring**: $q$ fixed at $82.5\\\\%$\n  - $17.5\\\\%$ chance of right-censoring.\n- **Bernoulli Masking Probability**: $p$ fixed at $21.5\\\\%$\n  - Some masking occurs $62\\\\%$ of the time.\n\n---\n### Scale Parameters\n\n![bg left height:3.2in](pres/plot-n-vs-scale.1-mle_plot-n-vs-scale.3-mle.png)\n\n- **Dispersion**: Increasing sample size improves MLE precision.\n  - Extremely precise for $n \\geq 250$.\n- **Bias**: Large *positive* bias initially, but diminishes to zero.\n  - Large samples counteract right-censoring and masking effects.\n- **Median CIs**: Track MLE dispersion. Very tight for $n \\geq 250$.\n\n---\n### Shape Parameters\n\n![bg left height:3.2in](pres/plot-n-vs-shape.1-mle_plot-n-vs-shape.3-mle.png)\n\n- These graphs resemble the last ones for scale parameters.\n\n---\n### Coverage Probability and Convergence Rate\n\n![bg left height:3.2in](pres/plot-n-vs-cp_n_vs_convergence.png)\n\n- **Coverage**: Good empirical coverage.\n  - Correctly specified CIs for $n > 250$.\n\n- **Convergence Rate**: Total convergence for $n \\geq 250$.\n  - Caution advised for estimates with $n < 100$ in specific setups.\n\n---\n### Key Takeaways: Sample Size\n\nSample size has a notable impact on the MLE:\n\n- **Precision**: Very precise for large samples ($n > 200$).\n- **Bias**: Diminishes to near zero for large samples.\n- **Coverage**: Correctly specified CIs for large samples.\n- **Convergence Rate**: Total convergence for large samples.\n\n### **Summary** \nLarger samples lead to more accurate, unbiased, and reliable estimations.\n\n  - Mitigates the effects of right-censoring and masking.\n\n---\n# Conclusion\n\n**MLE Performance**:\n\n- Right-censoring and masking introduce positive bias for our setup.\n  - More reliable components are more affected.\n- Shape parameters harder to estimate than scale parameters.\n- Large samples can mitigate the affects of masking and right-censoring.\n\n**BCa Confidence Interval Performance**:\n\n- Width of CIs tracked MLE dispersion.\n- Good empirical coverage in most scenarios.\n\n### Big Picture\nMLE and CIs robust despite masking and right-censoring challenges.\n\n---  \n# Future Work and Discussion\n\nDirections to enhance learning from masked data:\n\n- **Relax Masking Conditions**: Assess sensitivity to violations and and explore alternative likelihood models.\n- **System Design Deviations**: Assess estimator sensitivity to deviations.\n- **Homogenous Shape Parameter**: Analyze trade-offs with the full model.\n- **Bootstrap Techniques**: Semi-parametric approaches and prediction intervals.\n- **Regularization**: Data augmentation and penalized likelihood methods.\n- **Additional Likelihood Contributions**: Predictors, etc.\n",
        "github_pages": "https://queelius.github.io/reliability-estimation-in-series-systems/"
    },
    {
        "id": 833733343,
        "node_id": "R_kgDOMbHC3w",
        "name": "RPSDG",
        "full_name": "queelius/RPSDG",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/RPSDG",
        "description": null,
        "fork": false,
        "url": "https://api.github.com/repos/queelius/RPSDG",
        "forks_url": "https://api.github.com/repos/queelius/RPSDG/forks",
        "keys_url": "https://api.github.com/repos/queelius/RPSDG/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/RPSDG/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/RPSDG/teams",
        "hooks_url": "https://api.github.com/repos/queelius/RPSDG/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/RPSDG/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/RPSDG/events",
        "assignees_url": "https://api.github.com/repos/queelius/RPSDG/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/RPSDG/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/RPSDG/tags",
        "blobs_url": "https://api.github.com/repos/queelius/RPSDG/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/RPSDG/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/RPSDG/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/RPSDG/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/RPSDG/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/RPSDG/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/RPSDG/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/RPSDG/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/RPSDG/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/RPSDG/subscription",
        "commits_url": "https://api.github.com/repos/queelius/RPSDG/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/RPSDG/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/RPSDG/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/RPSDG/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/RPSDG/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/RPSDG/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/RPSDG/merges",
        "archive_url": "https://api.github.com/repos/queelius/RPSDG/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/RPSDG/downloads",
        "issues_url": "https://api.github.com/repos/queelius/RPSDG/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/RPSDG/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/RPSDG/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/RPSDG/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/RPSDG/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/RPSDG/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/RPSDG/deployments",
        "created_at": "2024-07-25T16:24:45Z",
        "updated_at": "2024-08-06T14:00:18Z",
        "pushed_at": "2024-08-06T14:00:15Z",
        "git_url": "git://github.com/queelius/RPSDG.git",
        "ssh_url": "git@github.com:queelius/RPSDG.git",
        "clone_url": "https://github.com/queelius/RPSDG.git",
        "svn_url": "https://github.com/queelius/RPSDG",
        "homepage": null,
        "size": 260,
        "stargazers_count": 1,
        "watchers_count": 1,
        "language": "Python",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 1,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 4
            }
        ],
        "readme_content": "# Reverse-Process Synthetic Data Generation: Automatically Generating Training Language Models for Complex Problem Solving\n\n## Abstract:\nThis paper introduces a methodology for generating high-quality, diverse training data for Language Models (LMs) in complex problem-solving domains. Our approach, termed \"Reverse-Process Synthetic Data Generation\" (RPSDG), inverts traditionally difficult problems to create an abundance of training examples with known solutions,\ne.g., symbolically taking the deriative of a function, $f \\mapsto f'$, versus solving antiderivatives of $f'$. By automating the generation of problems of graduating difficulty, we create datasets that enable process-supervised training of LLMs. We demonstrate the efficacy of this method for training mathematical reasoning. Our results show significant improvements in LLMs' problem-solving capabilities, particularly in areas requiring multi-step reasoning and creative insights. This methodology not only enhances model performance but also provides a framework for generating explainable AI solutions, as the step-by-step problem-solving process is inherent in the training data.\n\n## Table of Contents:\n\n- Introduction\n\n   - The challenge of training data for complex problem-solving\n   - Overview of Reverse-Process Synthetic Data Generation (RPSDG)\n   - Potential impact on AI capabilities and explainability\n\n- Methodology\n\n   - Core principles\n   - Automating generation of process supervision training data\n   - Curriculum learning and problem difficulty progression\n\n- Mathematics\n\n   - Algebra: Equation solving and manipulation\n   - Calculus: From differentiation to integration\n   \n- Implementation and Results\n\n   - Data generation pipelines\n   - Transformer-based LMs\n   - Self-Supervised Learning\n   - Evals and benchmarks\n   \n- Discussion\n\n   - Implications for AI problem-solving capabilities\n   - Enhancing explainability and transparency\n   - Limitations and challenges of the RPSDG approach using SSL\n\n- Future Work\n\n   - Expanding to new domains and problem types\n   - Reinforcement learning to reward multi-step reasoning even without a known (but verifiable) solution\n\n- Conclusion\n\n   - Summary of key findings\n   - Broader impact on AI research and applications\n\n## Introduction\n\nIn \"The Bitter Lesson,\" Richard Sutton argues that learning algorithms that scale with compute and data will eventually outperform handcrafted algorithms.\n\nThe next frontier in AI research is finding ways to acquire high-quality data that can be used to train models to predict the latent structure and processes in the world. A significant portion of the world's data is latent, where the processes that generate the data are not observable (e.g., not written down). For example, in mathematics, the way in which a proof was discovered is often not demonstrated and instead only a polished proof is presented, hiding the creative process and the \"dark matter\" that led to the proof. Understanding and modeling the latent structure in our processes can lead to significant improvements in AI capabilities.\n\nIn this paper, we are interested in exploring *algorithmic* data generation, where we apply classical algorithms (GOFAI) to automatically generate high-quality step-by-step (process supervision) training data for LMs. In particular, we are interested in exploring problems which have the feature of being easy to solve in one direction, but hard to solve in the other direction, such as\n\n## Taking Derivatives vs. Integrating Functions\n\nIn mathematics, computing derivatives of functions is generally easier than finding their antiderivatives (integrals). This inherent asymmetry allows us to use the more straightforward differentiation process to generate a rich dataset for training language models (LLMs) by reversing the problem-solving direction: starting with derivatives and deriving the original functions.\n\n### Generating Integral Calculus Training Data By Solving Derivatives and Reversing the Process\n\n1. **Starting with Known Functions:**\n   - Select functions \\( f(x) \\) that have closed-form solutions and well-defined derivatives.\n   - Examples include polynomials, trigonometric functions, exponential functions, and logarithmic functions.\n   - To ensure the training data covers a wide range of functions and their transformations, we create a variety of functions with different complexities and forms.\n\n2. **Formulating the Reverse Process:**\n   - Take the derivative of \\( f(x) \\) to generate \\( f'(x) \\).\n\n3. **Reversing the Process:**\n   - Generate the RPSDG by reversing the problem and solution steps, starting with \\( f'(x) \\)$ to show how to arrive at a corresponding integral \\( f(x) \\).\n   - Ensure that each step in this process is well-documented, capturing the intermediate transformations.\n\nThis approach allows us to generate integration problems of graduating difficulty, leveraging the inherent asymmetry between differentiation and integration. By automating this process, we create a diverse dataset for training LLMs to predict solutions in integral calculus.\n\n## Generating a Theorem Proof vs. Verifying a Proof\n\nOne of the key challenges in mathematics and logic is generating proofs for given theorems. While verifying a proof is generally straightforward, generating the proof itself can be significantly more complex. Our methodology leverages this asymmetry by focusing on the reverse process: starting with randomly generated expressions and using rewrite rules to create both theorems and their proofs.\n\n### Generating Theorem Proofs\n\n1. **Random Walks in Expression Space:**\n   - Begin with a randomly generated expression \\( e_{\\text{start}} \\).\n   - Apply a series of rewrite rules \\( r_1, r_2, \\ldots, r_n \\) to generate a sequence of intermediate expressions \\( e_1, e_2, \\ldots, e_n \\), ultimately arriving at a final expression \\( e_{\\text{end}} \\).\n   - Each step \\( e_i \\rightarrow e_{i+1} \\) represents a proof step within a logical or mathematical framework.\n\n2. **Forming Theorems and Proofs:**\n   - The pair \\( (e_{\\text{start}}, e_{\\text{end}}) \\) represents a theorem, where \\( e_{\\text{start}} \\) is the hypothesis and \\( e_{\\text{end}} \\) is the conclusion.\n   - The sequence of intermediate steps provides the proof for this theorem.\n   - This method effectively generates theorems and their corresponding proofs by random exploration of the expression space.\n\n3. **Reversibility and Bidirectional Processes:**\n   - The reverse process can also be applied, starting with \\( e_{\\text{end}} \\) and working backward to \\( e_{\\text{start}} \\).\n   - Intermediate steps that involve complex operations (e.g., integration) can often be reversed into simpler operations (e.g., differentiation).\n   - This bidirectional approach ensures a rich dataset with varied difficulty levels for training models.\n\n4. **Automated Proof Generation:**\n   - By applying rewrite rules to random starting points and ending at random points, we automatically generate both theorems and proofs.\n   - This method circumvents the traditional difficulty of finding a theorem to prove and then discovering its proof.\n   - The randomness ensures a diverse set of theorems and proofs, capturing a wide range of logical and mathematical concepts.\n\nThis methodology allows us to systematically generate a large volume of training data for LLMs. By focusing on problems that are easy in one direction but complex in the other, we create a diverse dataset that captures a wide range of logical and mathematical challenges. This not only enhances the problem-solving capabilities of LLMs but also provides a framework for generating explainable AI solutions, as the step-by-step problem-solving process is inherent in the training data.\n"
    },
    {
        "id": 755032049,
        "node_id": "R_kgDOLQDf8Q",
        "name": "sluug-talk-llm",
        "full_name": "queelius/sluug-talk-llm",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/sluug-talk-llm",
        "description": null,
        "fork": false,
        "url": "https://api.github.com/repos/queelius/sluug-talk-llm",
        "forks_url": "https://api.github.com/repos/queelius/sluug-talk-llm/forks",
        "keys_url": "https://api.github.com/repos/queelius/sluug-talk-llm/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/sluug-talk-llm/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/sluug-talk-llm/teams",
        "hooks_url": "https://api.github.com/repos/queelius/sluug-talk-llm/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/sluug-talk-llm/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/sluug-talk-llm/events",
        "assignees_url": "https://api.github.com/repos/queelius/sluug-talk-llm/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/sluug-talk-llm/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/sluug-talk-llm/tags",
        "blobs_url": "https://api.github.com/repos/queelius/sluug-talk-llm/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/sluug-talk-llm/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/sluug-talk-llm/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/sluug-talk-llm/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/sluug-talk-llm/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/sluug-talk-llm/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/sluug-talk-llm/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/sluug-talk-llm/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/sluug-talk-llm/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/sluug-talk-llm/subscription",
        "commits_url": "https://api.github.com/repos/queelius/sluug-talk-llm/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/sluug-talk-llm/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/sluug-talk-llm/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/sluug-talk-llm/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/sluug-talk-llm/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/sluug-talk-llm/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/sluug-talk-llm/merges",
        "archive_url": "https://api.github.com/repos/queelius/sluug-talk-llm/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/sluug-talk-llm/downloads",
        "issues_url": "https://api.github.com/repos/queelius/sluug-talk-llm/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/sluug-talk-llm/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/sluug-talk-llm/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/sluug-talk-llm/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/sluug-talk-llm/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/sluug-talk-llm/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/sluug-talk-llm/deployments",
        "created_at": "2024-02-09T09:45:34Z",
        "updated_at": "2024-02-23T13:17:49Z",
        "pushed_at": "2024-02-23T22:42:56Z",
        "git_url": "git://github.com/queelius/sluug-talk-llm.git",
        "ssh_url": "git@github.com:queelius/sluug-talk-llm.git",
        "clone_url": "https://github.com/queelius/sluug-talk-llm.git",
        "svn_url": "https://github.com/queelius/sluug-talk-llm",
        "homepage": null,
        "size": 9150,
        "stargazers_count": 1,
        "watchers_count": 1,
        "language": "Jupyter Notebook",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": false,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "mit",
            "name": "MIT License",
            "spdx_id": "MIT",
            "url": "https://api.github.com/licenses/mit",
            "node_id": "MDc6TGljZW5zZTEz"
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 1,
        "default_branch": "main",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 23
            }
        ],
        "readme_content": "---\nmarp: true\n#theme: uncover\nmath: mathjax\n---\n\n# SLUUG Talk: Large Language Models\n\nThis repository contains the slides and code for the talk:\n\n- Demystifying Large Language Models (LLMs) on Linux: From Theory to Application\n\nIt was given for the St. Louis Unix Users Group (SLUUG) on 2024/2/22 @ 6:30 PM CST.\n\n- SLUUG: https://www.stllinux.org/ :link:\n\n- Meetup: https://www.meetup.com/saint-louis-unix-users-group/events/290697932/ :link:\n\n---\n\n# Alex Towell\n\n- lex@metafunctor.com :email:\n- https://metafunctor.com :link:\n- https://github.com/queelius :rocket:\n- https://twitter.com/queelius :bird:\n\n- Important URLs for this talk:\n    - Talk link: https://github.com/queelius/sluug-talk-llm :link:\n    - Colab notebook on n-gram model: https://colab.research.google.com/drive/1ak4kOtbIQGXE5kuhhGTd55xu4qRpeZd7?usp=sharing\n    - ElasticSearch NLQ demo (down): http://lab.metafunctor.com:6789 (API: http://lab.metafunctor.com:6789/docs)\n\n---\n\n# Outline of Talk\n\n- Theoretical Background\n\n- Go over a simple language model\n    - $n$-gram model (Jupyter Notebook)\n    - Easy to understand and helps us understand some aspects of LLMs.\n\n- Show an application of LLMs:\n    - Try to make a database search API intelligent (NLP)\n    with small LLMs.\n\n- Open Discussion\n\n---\n\n# Good-Old-Fashioned AI (GOFAI)\n\n- Find a way to symbolically represent the problem and\n  then use logic or rules to solve it.\n\n    - Programming :computer:\n\n    - Rule-based systems :robot:\n\n    - First-order logic\n\n- LLMs are *good* at using these tools. :hammer:\n\n    - Integrate Prolog with LLM tool-use to help with planning and reasoning?\n\n---\n### Reductive Reasoning\n\n![bg left height:3.2in](./symbolic.png)\n\nGOFAI works for a lot of problems we care about:\n\n- Filter everything through our small working memory.\n    - Inductive bias: Makes assumptions about the world.\n    - Help us generalize out-of-distribution. :brain:\n- Take big problems and break down into simpler problems.\n- Solve simpler problems and combine.\n\n---\n# Limits of GOFAI\n\nMany problems are hard to break down into simpler parts.\n\n- Whole greater than the sum of its parts.\n\n- Too complex to solve reductively.\n    - We can't program computers to do it. :shrug:\n    - Identifying cats in pictures? :cat:\n    - > The hard problems are easy and the easy problems are hard.\n        -- Steven Pinker\n    - Playing with legos is hard but multivariate calculus is easy (for a computer).\n---\n# How Do Our Brains Work?\n\n![bg left height:3.5in](./subsymbolic.png)\n\nBrains programmed by evolution to survive in a complex world.\n\n- It's a prediction engine: it learns to predict the world.\n- The unconscious mind is not limited by a small \"working memory\"\n- It can do things we don't understand how to do.\n- Brain is a black box. (See: *Interpretable ML*)\n\n---\n\n# Machine Learning\n\n:bulb: Let's have the computer learn from data.\n\n- Since the real world is too complex, let's have the computer learn from data like we do.\n\n- There are three main types of learning.\n\n    - Supervised Learning (SL)\n    - Unsupervised Learning \ud83d\udd25\n    - Reinforcement Learning (RL) \ud83d\udca3\n\n- _Spoiler_: LLMs use self-supervised learning (SSL) and RL (RLHF).\n\n---\n\n## Type of Learning (1): Supervised Learning\n\n**Learning from labeled data**. We have some input and output data, and we want to learn how to map the input to the output.\n\n- Given an (unknown) function $f$ and a set of input-output pairs $(x, f(x))$, learn a function $\\hat{f}$ that approximates $f$ on the input-output pairs.\n\n- E.g., classification: $f$ : [ :cat: or :dog: ] \u21a6 { :cat: , :dog: }.\n\n    - Use $\\hat{f}$ to predict :cat: or :dog: for new images.\n\n- Easiest problem to solve in ML. But: limited by data.\n\n- **Fine-Tuning** LLMs is supervised learning: improve it on specific labeled tasks.\n\n---\n## Type of Learning (2): Unsupervised Learning\n\n**No labeled data**. Learn the underlying structure of the data.\n\n- Clustering: Grouping similar data points. (See: *RAG*)\n\n- Dimensionality Reduction: Learn *efficient* representations of the data.\n    - Very hard and one of the most important problems in ML.\n\n- Density Estimation: Stochastic estimate of process that generated the observed data. Say the process generates $(x, y)$ pairs and we estimate its density $\\Pr(x, y)$.\n    - Classification (supervised): $\\Pr(y|x) = \\Pr(x, y) / \\Pr(x)$\n\n- **Pre-training LLMs** is like unsupervised learning. Learn a good representation and probability distribution of the *raw* text using self-supervised learning (SSL).\n\n---\n\n## Final Type of Learning (3): Reinforcement Learning\n\nThis is an agentic approach to learning. Agent interacts with environment and learns from the rewards it receives.\n- *Goal*: maximize the expected sum of rewards.\n- *Spoiler*: Agentic frameworks that include LLMs as a prediction component is a very active area of research.\n- `Prediction + Search = Planning`\n    - Counterfactual reasoning\n- Hypothesis: `Compression = Prediction = Intelligence`\n- Big reason a lot of people are excited about Sora.\n    - Has everyone seen the Sora videos?\n    - \"Intuitive\" world simulation (embedded in the weights of a giant NN).    \n\n---\n\n# Early Failures in ML\n\nEarly efforts in ML were not very successful. Reality is complicated:\n$$\n(x_1, x_2, \\ldots, x_n),\n$$\n$n$ extremely large and each $x_i$ some complex object.\n\n- Overfitting, curse of dimensionality, lack of data/compute.\n\n- To combat lack of data/compute, clever solutions developed.\n\n- Many of these methods are no longer around.\n    > \"The biggest lesson that can be read from 70 years of AI research is that general methods that leverage computation are ultimately the most effective, and by a large margin.\"\n    -- Richard Sutton's Bitter Lesson\n---\n\n# Neural Networks\n\n![bg left height:6in](./NN.jpg)\n\nNeural Networks (NN) are one the solutions that stuck around.\n\n- It fell out of favor for a while, but it's back.\n- Universal function approximator.\n    - Can learn to represent any function.\n    - But: need a lot of data to do so and be difficult to train.\n- NNs seem to scale to as much data and compute as we can throw at them.\n\n---\n# Inductive Bias\n\nObservations may have an infinite set of hypothesis that are compatible with the data.\n\n- **Inductive Bias**: The set of assumptions that the model makes about the data.\n\n- **Occam's Razor**: choose the simplest hypothesis that is compatible with the data. (See _Solomonoff Induction_.)\n\n- Generalizing out-of-distribution (OOD) from inputs not in the training data.\n\n- **Problem**: We are almost *always* out-of-distribution.\n    - Except in toy problems (see: early successes)\n\n- Good inductive biases are necessary for generalization.\n\n- **No Free Lunch Theorem**: No model is optimal for all tasks.\n---\n\n# Era of Deep Learning\n\n![bg left height:4in](./imagenet.png)\n\nOne of the hardest parts is learning sample efficient representation of the data.\n\n- Layers of NN learn progressively higher-level representations: `Pixels -> Edges -> Objects`\n\n- AlexNet (2012) was the first to show that deep learning could work well on large-scale datasets.\n\n---\n\n# Era of Deep Learning (cont.)\n\n![bg left height:4.1in](./image-4.png)\n\nDNNs (feed-forward) learn little circuit programs that can generate parts of the training data. (Image stolen from Jeff Dean's slides.)\n\n- Hundreds of layers: can learn pretty complicated programs.\n\n- (What a human can do in a half a second, a DNN can do?)\n\n\n\n---\n# Era of Generative AI\n\n![bg left height:4.1in](image-5.png)\n\nGenerative AI \"reverses\" the arrows\n    - Image to text, image to image, etc.\n\n- They learn something about the data generating process (DGP).\n- They have completely changed our expectations of what computers can do.\n\n---\n# Era of Generative AI (cont.)\n\nWe now have computers that can see, hear, understand, and generate all of these things.\n\nLet's go look at **Sora**: generative video, or world(s) simulator?\n\n- **Scaling**: And increasing the scale (data, compute) increase their capabilities. See: Scaling laws.\n\n    - Need a lot more *compute*.\n    - It's going to get wild(er).\n    - Hypothesis: `Prediction = Compression = Intelligence`.\n\n\n---\n# Large Language Models (LLMs)\n\nAutoregressive (AR) models learn a probability distribution over training data by using self-supervised learning (SSL):\n\n$$\n\\Pr(x_1, x_2, \\ldots, x_T) = \\prod_{t=1}^T \\Pr(x_t | x_1, \\ldots, x_{t-1})\n$$\n\n- This is hard to learn, but with enough data and compute, a lot seems possible.\n- LLMs have a nice advantage since language is designed to have a very low dimensionality and have a high signal to noise ratio.\n    - Representation learning is easier in language than in other domains.\n        - Still learns representations (`word2vec`)\n- **Language** represents much of the things that humans care and think about, so learning to predict it is a kind of general intelligence. (See: Sparks of AGI by Microsoft)\n\n---\n\n# Sampling from LLMs\n\nThere are many different ways to sample from LLMs and change the behavior of the model.\n\n- **Temperature**: Rescaling the logits before applying the softmax function.\n    - $T = 1$: estimates the probability distribution.\n    - $T < 1$: reduces randomness, i.e., more predictable outputs.\n    - $T > 1$: increases randomness, i.e., more unpredictable outputs.\n\nGood for controlling *exploitation* vs *exploration* if repeatedly sampling from the model to generate new or different outputs.\n\n- **Top-k and Top-p Sampling**: Choose the top-$k$ or top-$p$ tokens and sample from them.\n\n- **Beam Search**: Explore multiple paths and sample based on that joint probability.\n\n---\n## Prompting Strategies\n\nEarly models were very sensitive to the prompt.\n- Makes sense, they were trained to generate the data.\n- If you condition on crazy data, you get crazy outputs.\n\n$$\n\\Pr(\\text{more crazy}|\\text{crazy})\n$$\n\nVarious prompting strategies have been developed to help the model generate more reliable outputs:\n\n- Chain-of-thought (CoT)\n- Tree-of-thought (ToT)\n- and so on...\n\n---\n\n# LLM Overview\n\nBasic idea: train a model to predict the next token in a sequence of tokens.\n\n- **Task**: Given a sequence of tokens, predict the next token.\n    - Pre-Train model to learn raw data distribution using SSL.\n    - Fine-tune model to a specific dataset that is more relevant to a task.\n    - RLHF model to bias it to produce outputs that people prefer.\n\n- **Goal**: Enable the generation of new data points for a given task.\n\n---\n## OOD Generalization\n\nAt inference, outputs are almost always out-of-distribution (OOD).\n\n- *In-Context Learning*: Transformers seem to be pretty good at generalizing from data that was not seen during training.\n\n- Learning to predict the next token when the data is sufficiently complicated may require a general kind of intelligence.\n\n- *Causal inductive bias*: The model is biased to predict the next token based on the evidence of the previous tokens.\n\n*Example*: \"Based on all the previous evidence, I conclude that the murderer is ___\". To do this well, it seems you must be able to reason about the evidence.       \n \n---\n## Naive N-Gram Model (AR) Over Bytes\n\n![bg left height:6in](./naive-ngram/expr_tree.png)\n\nWe consider an AR-LM over bytes (256 tokens):\n\n- *Algorithmic training data*: Partial expression trees.\n    - *Sparse* markov chain of order $O(256^n)$ states.\n- Analyze how well model predicts the next token given the context.\n- How well does model capture the underlying process?\n    - *Spoiler*: It doesn't do well.\n\n---\n### Implementation Notes\n\n- We represent our $n$-gram model as a dictionary of dictionaries:\n    - Outer dictionary is indexed by context.\n    - Inner dictionary is indexed by next token.\n    - Each `token | context` maps frequency in training data.\n\n- This is simple model and simple data\n    - Hopefully, exploring its properties can help us understand LLMs.\n\n---\n## Colab\n\nLet's go to the notebook.\n\n- If you want to follow along, Colab is available at: https://colab.research.google.com/drive/1ak4kOtbIQGXE5kuhhGTd55xu4qRpeZd7?usp=sharing :link:\n- See my GitHub: https://github.com/queelius/sluug-talk-llm :link:\n\n---\n### Colab Comments\n\n*Inductive Bias*: Throwing away oldest bytes is a strong inductive bias:\n- Not necessarily true that the next byte is less dependent on the oldest bytes.\n\n*Generative Model*: generate text by starting with a any context and then sampling from the probability distribution for that context to get the next token.\n- Repeat until we have generated the desired number of tokens.\n- Same way LLMs work (but they work well).\n\n---\n### Colab: Advantages of Our Model\n\nOur model has some advantages compared to AR-LLMs. Since we simply *store* the data:\n- Easy to implement.\n- Easy to make it a lifelong learner. Store *more data*.\n\n---\n### Colab: Disadvantages of Our Model\n\nBut, compared to more sophisticated models, they have huge disadvantages:\n\n- $n$-gram model is not able to capture long-range dependencies in the data.\n    - Number of states grows exponentially with the order of the model.\n    - It cannot scale to large contexts, and therefore cannot understand\n    nuances in the data.\n\n- $n$-gram model does not generalize out-of-distribution very well.\n    - Since language is a high-dimensional space, *most* contexts have never been seen before.\n\n---\n### Colab: Conclusion\n\nKey concept in ML: A *good* model *compresses* the data.\n\n- There is a notion that *compression* is a proxy for *understanding*.\n- Take a *physics simulation*: we don't need to store the position and velocity of every particle.\n    - We can just store the starting conditions and then let the laws of physics play out.\n    - Not perfect, but perfect prediction impossible.\n        - Only need to predict it well enough to make informed decisions.\n\n- `Prediction = compression = intelligence`\n    - The brain may be a good example of this.\n\n---\n## Finite State Machines\n\nWe can view AR-LMs as finite state machines (if deterministic) otherwise Markov chains without loss of generality.\n\n- Computers are FSMs, just very large ones.\n- LLMs are also very large FSMs.\n\nhttps://www.lesswrong.com/posts/7qSHKYRnqyrumEfbt\n\n- Thus, AR-LLMs are differentiable computers that can learn from examples.\n\n---\n# Tool-Use\n\nThere is a lot of training data about how to use tools and APIs.  \ud83d\udd28\n\n- Large LLMs like GPT-4 do a good job predicting when and how they should use tools.\n\n- Let's go over to the ElasticSearch NLQ demo. \ud83d\udd26\n\n---\n# ElasticSearch Demo\n\n- Making all endpoints on the internet and UIs intelligent with small and fast LLMs.\n\n- As a trial, we are using ElasticSearch as a backend to enable natural language queries (NLQs) on ElasticSearch indexes (databases).\n\n- Key take-aways: GPT-4 / GPT-3.5 are good, small LLMs not quite there yet.\n  \n  - We have some ways to possibly improve them though. More on that later.\n\n  - And, of course, today's large models are tomorrow's small models.\n    - Desperately need more compute!\n\n---\n## ElasticSearch: What Is It?\n\n* An open source, scalable search engine.\n* Supports complex queries, aggregations, and full-text search.\n* Can be difficult to use.\n* Suppose we have `articles` index with `author` and `title` fields and want to count the number of articles by author:\n\n```json\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"articles_by_author\": {\n      \"terms\": { \"field\": \"author\" }\n    }\n  }\n}\n```\n\n---\n## FastAPI: What Is It and How Do We Use It?\n\n* A fast web framework for building APIs with Python.\n* We are trying two things:\n  + Using ElasticSearch backend for storage and search.\n  + Using LLMs to convert natural language queries (NLQ) to ElasticSearch queries.\n* We expose a single endpoint `/{index}/nlq` that takes an\nindex and an NLQ and returns a result from ElasticSearch.\n  - Hopefully the result is useful!\n* Later, remind me to open my firewall to allow access.\n\n---\n## Structure of Indexes\n\nI populated ElasticSearch with a two example indexes:\n\n* `articles`: A simple index with `author`, `title`, and 'publication_date' fields.\n\n* `gutenberg`: A more complex index with `author`, `publication_date`,`title`, and `content` fields.\n\n---\n## Code\n\nLet's look at some code. We'll switch to the code editor. There are\na few files we need to look at:\n\n* `main.py`: The FastAPI app. We can probe it using the Swagger UI at `http://lab.metafunctor.com:6789/docs`.\n* There is a crude frontend at `http://lab.metafunctor.com:6789/`.\n  - I made the frontend by chatting with ChatGPT-4. By chatting, I mean asked two ill-formed questions and copied its code blocks.\n  - See this link: https://chat.openai.com/share/9c95ba2e-94e7-4d9f-ae89-095357fc39bd\n* `nlq.py`: The module that handles the NLQ to ElasticSearch query conversion.\n* `examples.py`: A crude example database. We'll talk about this in a bit.\n\n---\n## Issues\n\n* GPT-4 is good at converting NLQs to ElasticSearch queries, but it's slow and expensive to use at scale.\n  + We only need to use an LLM for a relatively narrow task.\n  + Maybe we don't need the full power of GPT-4?\n* Small LLMs, like `llama2`, did poorly on converting NLQs to ElasticSearch queries.\n\n---\n## Idea #1: Use GPT-4 to \"Teach\" Smaller Models\n\nUse GPT-4 to generate high-quality examples for smaller LLMs.\n\n* Feed examples into the context of the small LLM to do In-Context Learning (ICL).\n\n    + **ICL**: a model can generalize to new NLQs\n\n* How? Every now and then, use GPT-4 to do the task and store its NLQ to ElasticSearch query in example database.\n\n* Let's look at the `examples.py` code.\n    - DB is just a Python `{}` that doesn't persist.\n    - Didn't have the time to use a proper database.       \n        - Ironic considering this is all about how to use ElasticSearch!\n\n---\n### Issues\n\nThe smaller models, like `llama2:13b` , do not seem to generalize\nfrom the examples very well.\n  + They often do better without \"polluting\" their context\n  with too much information.\n  + More tweaking? Or are these small models simply not up to the task.\n\n---\n## Idea #2: RAG (Retrieval-Augmented Generation)\n\nMaybe the smaller models need to be fed with more *relevant* examples. Use RAG to find relevant examples for the given index and NLQ :bulb:\n\n- Send the context through a language model to get a dense representation.\n\n- Store the representation of the examples in the database.\n\n- Find examples closest to the context of the NLQ and sample from them.\n\n- Insert the high-quality examples into the context of the small LLM to do ICL.\n\n---\n## Idea #3: Fine-Tuning\n\n* Fine-tune the smaller models on far more high-quality examples.\n\n* Small LLMs won't have to In-Context Learn as much.\n\n* See my GitHub repo: https://github.com/queelius/elasticsearch-lm\n\n  - Its README has a lot of verbiage.\n\n  - I just ran it through GPT-4 and didn't bother to edit it much.\n\n\n---\n\n\n# Discussion\n\n![bg left height:3.5in](./image-6.png)\n",
        "images": [
            "NN.jpg",
            "image-1.png",
            "image-2.png",
            "image-3.png",
            "image-4.png",
            "image-5.png",
            "image-6.png",
            "image.png",
            "imagenet.png",
            "subsymbolic.png",
            "symbolic.png"
        ]
    },
    {
        "id": 749120759,
        "node_id": "R_kgDOLKas9w",
        "name": "taskd",
        "full_name": "queelius/taskd",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/taskd",
        "description": "`taskd`: Task Daemon for Decentralized Task Execution for Long-Running Tasks",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/taskd",
        "forks_url": "https://api.github.com/repos/queelius/taskd/forks",
        "keys_url": "https://api.github.com/repos/queelius/taskd/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/taskd/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/taskd/teams",
        "hooks_url": "https://api.github.com/repos/queelius/taskd/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/taskd/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/taskd/events",
        "assignees_url": "https://api.github.com/repos/queelius/taskd/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/taskd/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/taskd/tags",
        "blobs_url": "https://api.github.com/repos/queelius/taskd/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/taskd/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/taskd/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/taskd/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/taskd/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/taskd/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/taskd/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/taskd/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/taskd/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/taskd/subscription",
        "commits_url": "https://api.github.com/repos/queelius/taskd/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/taskd/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/taskd/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/taskd/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/taskd/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/taskd/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/taskd/merges",
        "archive_url": "https://api.github.com/repos/queelius/taskd/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/taskd/downloads",
        "issues_url": "https://api.github.com/repos/queelius/taskd/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/taskd/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/taskd/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/taskd/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/taskd/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/taskd/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/taskd/deployments",
        "created_at": "2024-01-27T16:35:06Z",
        "updated_at": "2024-05-31T14:36:30Z",
        "pushed_at": "2024-05-25T13:21:52Z",
        "git_url": "git://github.com/queelius/taskd.git",
        "ssh_url": "git@github.com:queelius/taskd.git",
        "clone_url": "https://github.com/queelius/taskd.git",
        "svn_url": "https://github.com/queelius/taskd",
        "homepage": "https://queelius.github.io/taskd",
        "size": 15,
        "stargazers_count": 1,
        "watchers_count": 1,
        "language": "Python",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": false,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [
            "long-running-task",
            "task",
            "task-manager",
            "task-runner"
        ],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 1,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 5
            }
        ],
        "readme_content": "# `taskd`: Task Daemon for Decentralized Task Execution for Long-Running Tasks\n\nThe project `taskd` is a web service for script execution environment with workspace management. It allows you to create a workspace, upload a script, execute the script, and delete the workspace.\n\n## Workflow\n\n1. Create a workspace\n2. Upload a script\n3. Execute a script\n4. Delete a workspace\n\n## Getting Started\n\nTo get the server up and running, follow these steps:\n\n1. Install dependencies:\n\n    ```bash\n    pip install -r requirements.txt\n    ```\n\n2. Install and run `redis-server`:\n    - On Linux, you can install Redis using `apt-get install redis-server` and run it using `sudo systemctl start redis-server`\n3. Install and run `rq worker`:\n    - On Linux, you can install RQ using `pip install rq` and run it using `rq worker`\n4. Run `rq-dashboard`:\n    - On Linux, you can install RQ Dashboard using `pip install rq-dashboard` and run it using `rq-dashboard`\n5. Run `uvicorn main:app --reload`:\n    - On Linux, you can install Uvicorn using `pip install uvicorn` and run it using `uvicorn main:app --reload`\n6. Open `http://localhost:8000/docs` for the docs\n\n## API Endpoints\n\nThe application provides several API endpoints for managing workspaces and executing scripts. These are defined in [`routes.py`](routes.py).\n\n## Script Execution\n\nScripts are executed in their respective workspaces. The output of the script execution is logged to a file in the workspace. This is handled by the `execute_script` function in [`utils.py`](utils.py).\n\n## Documentation\n\nFor more detailed information about the application and its usage, refer to the [docs](docs/index.md).",
        "github_pages": "https://queelius.github.io/taskd/"
    },
    {
        "id": 165633296,
        "node_id": "MDEwOlJlcG9zaXRvcnkxNjU2MzMyOTY=",
        "name": "bernoulli_data_type",
        "full_name": "queelius/bernoulli_data_type",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/bernoulli_data_type",
        "description": "Bernoulli data type",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/bernoulli_data_type",
        "forks_url": "https://api.github.com/repos/queelius/bernoulli_data_type/forks",
        "keys_url": "https://api.github.com/repos/queelius/bernoulli_data_type/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/bernoulli_data_type/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/bernoulli_data_type/teams",
        "hooks_url": "https://api.github.com/repos/queelius/bernoulli_data_type/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/bernoulli_data_type/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/bernoulli_data_type/events",
        "assignees_url": "https://api.github.com/repos/queelius/bernoulli_data_type/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/bernoulli_data_type/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/bernoulli_data_type/tags",
        "blobs_url": "https://api.github.com/repos/queelius/bernoulli_data_type/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/bernoulli_data_type/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/bernoulli_data_type/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/bernoulli_data_type/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/bernoulli_data_type/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/bernoulli_data_type/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/bernoulli_data_type/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/bernoulli_data_type/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/bernoulli_data_type/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/bernoulli_data_type/subscription",
        "commits_url": "https://api.github.com/repos/queelius/bernoulli_data_type/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/bernoulli_data_type/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/bernoulli_data_type/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/bernoulli_data_type/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/bernoulli_data_type/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/bernoulli_data_type/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/bernoulli_data_type/merges",
        "archive_url": "https://api.github.com/repos/queelius/bernoulli_data_type/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/bernoulli_data_type/downloads",
        "issues_url": "https://api.github.com/repos/queelius/bernoulli_data_type/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/bernoulli_data_type/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/bernoulli_data_type/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/bernoulli_data_type/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/bernoulli_data_type/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/bernoulli_data_type/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/bernoulli_data_type/deployments",
        "created_at": "2019-01-14T09:29:11Z",
        "updated_at": "2024-06-29T01:25:35Z",
        "pushed_at": "2024-06-24T10:47:41Z",
        "git_url": "git://github.com/queelius/bernoulli_data_type.git",
        "ssh_url": "git@github.com:queelius/bernoulli_data_type.git",
        "clone_url": "https://github.com/queelius/bernoulli_data_type.git",
        "svn_url": "https://github.com/queelius/bernoulli_data_type",
        "homepage": "https://queelius.github.io/bernoulli_data_type/",
        "size": 32819,
        "stargazers_count": 2,
        "watchers_count": 2,
        "language": "Mathematica",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 2,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 114
            }
        ],
        "readme_content": "This is a repo that I will use to develop my Bernoulli data type concept, which is a general framework for understanding and constructing\na lot of interesting new data types and compuational trade-offs. It can also be used as a foundation for constructing oblivious programs\nas a composition of oblivious data types / obvious functions.\n\nI doubt any of it will compile -- I actually hadn't looked at this in years, while I battled sickness and cancer, but now that I'm feeling\nbetter, I'm revisting some old projects. Look at my repo for other things I'm working on, and https://metafunctor.com for my personal web site.\n\nHere are some markdown files in the repo. I've throw it all into Doxygen, but I haven't had time to make it work properly yet.\nHere are the files:\n\n- [Bernoulli Map](BERNOULLI_MAP.md) for info on the most generic type, which can be used to in theory model any computable function.\nWe also show how even traditional algorithms, like the Miller-Rabin primality test, can be understood in th framework of the Bernoulli model.\n    * [The random approximate values over algebraic types](bernoulli_data_type.pdf)\n        - I'm not sure if this is correct. The markdown files I have should be more up\n        to date and more correct, so stick with this for grokking the concept. This PDF\n        is more for historical purposes, and to show how I was thinking about it at the time.\n- [Bernoulli Bool](BERNOULLI_BOOL.md) for an example of the simplest Bernoulli type, useful for understanding.\n- [Bernoulli Set](BERNOULLI_SET.md) for information on the most common kind of Bernoulli data type. The Bloom filtr is a special case.\nHere are some PDF files related to this:\n    * [Bernoulli sets: a model for modeling sets with random errors](bernoulli.set.pdf) and corresponding random binary classification measures.\n        - A lot of the material in this section is obsolete, but there is still a lot of good information here.\n    * [An algebra of random approximate sets](bernoulli_sets_higher_order.pdf) with derivations of higher-order random approximate sets induced by set-theoretic operations on random approximate sets with corresponding random binary classification measures.\n        - Again, a lot of obsolete content. Much of this comes prior to my generalization of the result for\n        Bernoulli types, and before I had a proper appreciation for the correct definition. However, as a separate\n        result, if we ignore some of the details, it has a lot of interesting information.\n- [Codec](CODEC.md) for more information codecs. I will eventually use this to describe how to automatically generate any Bernoulli map,\nincluding Cipher maps (Oblivious data type). The idea will be to use the universal Bernoulli map constructor\n- [Regular Type](REGULAR_TYPE_CONCEPT.md) for more information about regular types, and how the Bernoulli model fails this basic requirement\nin many ways. It's not intended as a criticism, because in some ways it's desirable (say in the oblivious type use-case), only to\nexplain why some predicates like equality are not necessarily accurate (equality itself return a Bernoulli Boolean).\n\nSee the [API Documentation](docs/html/index.html) for more details, but there isn't much there yet. I'll be working\non the code + doxygen comments soon.\n\n\n",
        "github_pages": "https://queelius.github.io/bernoulli_data_type/",
        "images": [
            "plot_maj_vote.png"
        ]
    },
    {
        "id": 615367259,
        "node_id": "R_kgDOJK3CWw",
        "name": "femtograd",
        "full_name": "queelius/femtograd",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/femtograd",
        "description": "Like micrograd, but worse.",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/femtograd",
        "forks_url": "https://api.github.com/repos/queelius/femtograd/forks",
        "keys_url": "https://api.github.com/repos/queelius/femtograd/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/femtograd/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/femtograd/teams",
        "hooks_url": "https://api.github.com/repos/queelius/femtograd/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/femtograd/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/femtograd/events",
        "assignees_url": "https://api.github.com/repos/queelius/femtograd/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/femtograd/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/femtograd/tags",
        "blobs_url": "https://api.github.com/repos/queelius/femtograd/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/femtograd/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/femtograd/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/femtograd/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/femtograd/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/femtograd/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/femtograd/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/femtograd/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/femtograd/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/femtograd/subscription",
        "commits_url": "https://api.github.com/repos/queelius/femtograd/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/femtograd/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/femtograd/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/femtograd/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/femtograd/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/femtograd/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/femtograd/merges",
        "archive_url": "https://api.github.com/repos/queelius/femtograd/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/femtograd/downloads",
        "issues_url": "https://api.github.com/repos/queelius/femtograd/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/femtograd/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/femtograd/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/femtograd/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/femtograd/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/femtograd/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/femtograd/deployments",
        "created_at": "2023-03-17T14:32:36Z",
        "updated_at": "2024-12-09T22:51:50Z",
        "pushed_at": "2023-05-19T10:10:01Z",
        "git_url": "git://github.com/queelius/femtograd.git",
        "ssh_url": "git@github.com:queelius/femtograd.git",
        "clone_url": "https://github.com/queelius/femtograd.git",
        "svn_url": "https://github.com/queelius/femtograd",
        "homepage": "https://queelius.github.io/femtograd/",
        "size": 493,
        "stargazers_count": 2,
        "watchers_count": 2,
        "language": "R",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "gpl-3.0",
            "name": "GNU General Public License v3.0",
            "spdx_id": "GPL-3.0",
            "url": "https://api.github.com/licenses/gpl-3.0",
            "node_id": "MDc6TGljZW5zZTk="
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 2,
        "default_branch": "main",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 26
            }
        ],
        "readme_content": "femtograd\n================\n\n- <a href=\"#exponential-distribution\"\n  id=\"toc-exponential-distribution\">Exponential distribution</a>\n- <a href=\"#automatic-differentiation-ad\"\n  id=\"toc-automatic-differentiation-ad\">Automatic differentiation (AD)</a>\n\nHere\u2019s a quick demonstration of how to use the\n[`femtograd`](https://github.com/queelius/femtograd) R package.\n\nLoad it like this:\n\n``` r\nlibrary(femtograd)\n#> \n#> Attaching package: 'femtograd'\n#> The following object is masked from 'package:utils':\n#> \n#>     data\n```\n\n## Exponential distribution\n\nLet\u2019s create a simple loglikelihood function for the exponential\ndistribution paramterized by $\\lambda$ (failure rate).\n\nWe have\n\n$$\n  f_{T_i}(t_i | \\lambda) = \\lambda \\exp(-\\lambda t_i).\n$$\n\nSo, the loglikelihood function is just\n\n$$\n  \\ell(\\lambda) = n \\log \\lambda - \\lambda \\sum_{i=1}^n t_i.\n$$\n\nLet\u2019s generate $n=30$ observations.\n\n``` r\nn <- 30\ntrue_rate <- 7.3\ndata <- rexp(n,true_rate)\nhead(data)\n#> [1] 0.102432677 0.009849689 0.037429092 0.093926112 0.033046038 0.181780460\n\n(mle.rate <- abs(1/mean(data)))\n#> [1] 6.245535\n```\n\nWe see that the MLE $\\hat\\theta$ is 6.2455349.\n\n# Automatic differentiation (AD)\n\nFinding the value (argmax) that maximizes the\nlog-likelihood function is trivial to solve in this case, and it has a\nclosed-form solution. However, to demonstrate the use of `femtograd`, we\nwill construct a `loglike_exp` function generator that returns an object\nthat can be automatically differentiated (AD) using backpropogation,\nwhich is an efficient way of applying the chain-rule to expressions\n(like $\\exp\\{y a x^2\\}$ using a *computational graph* that represents\nthe expression.\n\nThese kind of computational graphs have the nice property that for any\ndifferentiable expression that we can model in software, its partial\nderivative with respect to some node in the graph can be efficiently and\naccurately computed without resorting to numerical finite difference\nmethods or slow, potentially difficult to compose symbolic methods.\n\nThere are many libraries that do this. This library itself is based on\nthe excellent work by Karpathy who developed the Python library known as\n[`micrograd`](https://github.com/karpathy/micrograd), which was\ndeveloped for the explicit purpose of teaching the basic concept of AD\nand backpropagation for minimizing loss functions for neural networks.\n\nLet\u2019s solve for the MLE iteratively as a demonstration of how to use\n[`femtograd`](https://github.com/queelius/femtograd). First, we\nconstruct the log-likelihood generator:\n\n``` r\nloglike_exp <- function(rate, data)\n{\n  return(log(rate)*length(data) - rate * sum(data))\n}\n```\n\nInitially, we guess that $\\hat\\lambda$ is $1$, which is a terrible\nestimate.\n\n``` r\nrate <- val(1)\n```\n\nGradient clipping is a technique to prevent taking too large of a step\nwhen gradients become too large (remember that gradients are a *local*\nfeature, so we generally should not use it to take too big of a step)\nduring optimization, which can cause instability or overshooting the\noptimal value. By limiting the step size, gradient clipping helps ensure\nthat the optimization takes smaller, more stable steps.\n\nHere is the R code:\n\n``` r\n# Takes a gradient `g` and an optional `max_norm` parameter, which defaults\n# to 1. It calculates the gradient's L2 norm (Euclidean norm) and scales the\n# gradient down if its norm exceeds the specified max_norm. This is used during\n# the gradient ascent loop to help ensure stable optimization.\ngrad_clip <- function(g, max_norm = 1) {\n  norm <- sqrt(sum(g * g))\n  if (norm > max_norm) {\n    g <- (max_norm / norm) * g\n  }\n  g\n}\n```\n\nWe find the MLE using a simple iteration (200 loops).\n\n``` r\nloglik <- loglike_exp(rate, data)\nlr <- 0.2 # learning rate\nfor (i in 1:200)\n{\n  zero_grad(loglik)\n  backward(loglik)\n\n  data(rate) <- data(rate) + lr * grad_clip(grad(rate))\n  if (i %% 50 == 0)\n    cat(\"iteration\", i, \", rate =\", data(rate), \", drate/dl =\", grad(rate), \"\\n\")\n}\n#> iteration 50 , rate = 6.238781 , drate/dl = 0.006148105 \n#> iteration 100 , rate = 6.245533 , drate/dl = 1.447689e-06 \n#> iteration 150 , rate = 6.245535 , drate/dl = 3.418377e-10 \n#> iteration 200 , rate = 6.245535 , drate/dl = 8.082424e-14\n```\n\nDid the gradient ascent method converge to the MLE?\n\n``` r\n(converged <- (abs(mle.rate - data(rate)) < 1e-3))\n#> [1] TRUE\n```\n\nIt\u2019s worth pointing out that we did not update `loglik` in the gradient\nascent loop, since we only needed the gradient (score) in this case. If,\nhowever, we had needed to know the log-likelihood for some reason, such\nas when using a line search method to avoid overshooting, we would need\nto update with `loglik <- loglike_exp(rate, data)` each time through the\nloop.\n",
        "github_pages": "https://queelius.github.io/femtograd/"
    },
    {
        "id": 759798665,
        "node_id": "R_kgDOLUmbiQ",
        "name": "hypothesize",
        "full_name": "queelius/hypothesize",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/hypothesize",
        "description": "hypothesize",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/hypothesize",
        "forks_url": "https://api.github.com/repos/queelius/hypothesize/forks",
        "keys_url": "https://api.github.com/repos/queelius/hypothesize/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/hypothesize/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/hypothesize/teams",
        "hooks_url": "https://api.github.com/repos/queelius/hypothesize/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/hypothesize/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/hypothesize/events",
        "assignees_url": "https://api.github.com/repos/queelius/hypothesize/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/hypothesize/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/hypothesize/tags",
        "blobs_url": "https://api.github.com/repos/queelius/hypothesize/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/hypothesize/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/hypothesize/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/hypothesize/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/hypothesize/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/hypothesize/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/hypothesize/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/hypothesize/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/hypothesize/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/hypothesize/subscription",
        "commits_url": "https://api.github.com/repos/queelius/hypothesize/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/hypothesize/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/hypothesize/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/hypothesize/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/hypothesize/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/hypothesize/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/hypothesize/merges",
        "archive_url": "https://api.github.com/repos/queelius/hypothesize/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/hypothesize/downloads",
        "issues_url": "https://api.github.com/repos/queelius/hypothesize/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/hypothesize/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/hypothesize/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/hypothesize/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/hypothesize/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/hypothesize/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/hypothesize/deployments",
        "created_at": "2024-02-19T11:02:17Z",
        "updated_at": "2024-09-06T21:18:42Z",
        "pushed_at": "2024-05-19T15:33:32Z",
        "git_url": "git://github.com/queelius/hypothesize.git",
        "ssh_url": "git@github.com:queelius/hypothesize.git",
        "clone_url": "https://github.com/queelius/hypothesize.git",
        "svn_url": "https://github.com/queelius/hypothesize",
        "homepage": "https://queelius.github.io/hypothesize",
        "size": 60,
        "stargazers_count": 2,
        "watchers_count": 2,
        "language": "R",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": false,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": null,
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [
            "hypothesis-testing",
            "likelihood",
            "statistics"
        ],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 2,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 7
            }
        ],
        "readme_content": "`hypothesize`: Statistical Tests in R\n=====================================\n\n`hypothesize` is a simple hypothesis testing API in R.\nIt is mostly designed to be used by other libraries so that they can wrap\ntheir own hypothesis tests in a consistent way.\n\nWe define the API as a set of generic methods. We also\nprovide implementations for the likelihood ration test (LRT) and the Wald test.\n\nInstallation\n------------\n\nYou can install the development version of `hypothesize` from GitHub\nwith:\n\n    # install.packages(\"devtools\")\n    devtools::install_github(\"queelius/hypothesize\")\n\nLoad the Package\n----------------\n\n    library(hypothesize)\n\nThe `hypothesize` API\n---------------------\n\n`hypothesize` defines an API for retrieving hypothesis test results. An object\nsatisfies the concept of a hypothesis test if it implements the following generic\nmethods:\n\n-   `pval()`: Extracts the p-value from an object that models a hypothesis test.\n\n-   `dof()`: Retrieves the degrees of freedom associated with a\n    hypothesis test.\n\n-   `test_stat()`: Obtains the test statistic from the hypothesis test.\n\n-   `is_significant_at()`: Determines if the hypothesis test is\n    significant at a specified significance level.\n\nImplementation: `hypothesis_test`\n---------------------------------\n\nWe provide an implementations for `hypothesize`. It it has a\nconstructor that takes a statistical test (stat), p-value (p.value),\na degree-of-freedom (dof), and optionally a list of superclasses and\nany additional arguments that will be passed into the object. Here\nis its type signature:\n\n    `hypothesis_test <- function(stat, p.value, dof, superclasses = NULL, ...) `\n\nIt creates a `hypothesis_test` object that implements all of the generic\nmethods required by `hypothesize`. The `hypothesis_test` object also\nimplements `print` for summary outputs.\n\nWe use this constructor for two tests we implement, the LRT and Wald tests:\n\n-   `lrt()`: Performs a Likelihood Ratio Test based on log-likelihood\n    values from nested models.\n\n-   `wald_test()`: Performs a Wald test to compare a parameter estimate\n    to a specified value.\n\nExample: Using `lrt`\n--------------------\n\nThe `lrt` function is particularly useful for comparing nested models \u2014\nwhere one model (the null model) is a special case of another (the\nalternative model).\n\n### Scenario\n\nSuppose we have two models that aim to explain the same dataset. Model 1\n(the null model) is simpler, with fewer parameters, while Model 2 (the\nalternative model) includes additional parameters. We wish to test if\nthe complexity of Model 2 is justified by a significantly better fit to\nthe data.\n\n### Step-by-Step Example\n\n1.  **Define Log-Likelihoods**: Assume we have calculated the\n    log-likelihoods for both models on the same dataset. For the null\n    model, the log-likelihood is -100, and for the alternative model, it\n    is -99. Assume that the difference in degrees of freedom between the\n    two models is 2.\n\n2.  **Perform LRT**: We use `lrt` to perform the Likelihood Ratio Test.\n\n<!-- -->\n\n    # Perform LRT\n    stat <- lrt(null_loglik = -100, alt_loglik = -96.105, dof = 3)\n    print(stat)\n    #> Hypothesis test ( likelihood_ratio_test )\n    #> -----------------------------\n    #> Test statistic:  7.79 \n    #> P-value:  0.0506 \n    #> Degrees of freedom:  3 \n    #> Significant at 5% level:  FALSE\n\nWe show the output of the `stat` object, which includes all the relevant\ninformation about the test. However, we might want to look at its parts\nindependently, particularly if we need programmatic accees to relevant\nparts of the test.\n\n1.  **Evaluate Significance**: Determine if the difference in\n    log-likelihoods is significant at the 5% level.\n\n<!-- -->\n\n    # Check significance\n    is_significant_at(stat, 0.05)\n    #> [1] FALSE\n\nA negative test result indicates that the alternative model is not\ncompatible with the data at the 5% significance level. However, we might\nwant to extract the test statistic, p-value, and degrees of freedom to\narrive at a more nuanced interpretation.\n\n1.  **Examine the Test Result**: Extract and examine the test statistic,\n    p-value, and degrees of freedom to evaluate the significance.\n\n<!-- -->\n\n    # Extract test statistic\n    test_stat(stat)\n    #> [1] 7.79\n\n    # Extract p-value\n    pval(stat)\n    #> [1] 0.0506\n\n    # Extract degrees of freedom\n    dof(stat)\n    #> [1] 3\n\nWe see that the *p*-value is only slightly above our (arbitrarily)\nspecified *\u03b1*\u2004=\u20040.05. This suggests that the alternative model may be\nreasonable to consider, but it is not a clear-cut decision. In practice,\nwe would likely want to consider other factors, such as the practical\nsignificance of the additional complexity, or collecting more data to\nreduce uncertainty, before making a final decision.\n\nExample: Using Wald Test\n------------------------\n\nThe Wald test is also implemented in `hypothesize`. Tis test is used to\ncompare the value of a parameter to a specified value, and is often used\nin the context of regression models.\n\n    # Example: Wald Test\n    print(wald_test(estimate = 1.5, se = 0.5, null_value = 1))\n    #> Hypothesis test ( wald_test )\n    #> -----------------------------\n    #> Test statistic:  1 \n    #> P-value:  0.317 \n    #> Degrees of freedom:  1 \n    #> Significant at 5% level:  FALSE\n",
        "github_pages": "https://queelius.github.io/hypothesize/"
    },
    {
        "id": 800031754,
        "node_id": "R_kgDOL6-ECg",
        "name": "ollama_data_tools",
        "full_name": "queelius/ollama_data_tools",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/ollama_data_tools",
        "description": null,
        "fork": false,
        "url": "https://api.github.com/repos/queelius/ollama_data_tools",
        "forks_url": "https://api.github.com/repos/queelius/ollama_data_tools/forks",
        "keys_url": "https://api.github.com/repos/queelius/ollama_data_tools/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/ollama_data_tools/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/ollama_data_tools/teams",
        "hooks_url": "https://api.github.com/repos/queelius/ollama_data_tools/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/ollama_data_tools/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/ollama_data_tools/events",
        "assignees_url": "https://api.github.com/repos/queelius/ollama_data_tools/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/ollama_data_tools/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/ollama_data_tools/tags",
        "blobs_url": "https://api.github.com/repos/queelius/ollama_data_tools/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/ollama_data_tools/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/ollama_data_tools/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/ollama_data_tools/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/ollama_data_tools/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/ollama_data_tools/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/ollama_data_tools/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/ollama_data_tools/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/ollama_data_tools/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/ollama_data_tools/subscription",
        "commits_url": "https://api.github.com/repos/queelius/ollama_data_tools/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/ollama_data_tools/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/ollama_data_tools/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/ollama_data_tools/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/ollama_data_tools/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/ollama_data_tools/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/ollama_data_tools/merges",
        "archive_url": "https://api.github.com/repos/queelius/ollama_data_tools/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/ollama_data_tools/downloads",
        "issues_url": "https://api.github.com/repos/queelius/ollama_data_tools/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/ollama_data_tools/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/ollama_data_tools/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/ollama_data_tools/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/ollama_data_tools/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/ollama_data_tools/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/ollama_data_tools/deployments",
        "created_at": "2024-05-13T15:13:03Z",
        "updated_at": "2024-05-24T12:09:53Z",
        "pushed_at": "2024-05-19T17:19:41Z",
        "git_url": "git://github.com/queelius/ollama_data_tools.git",
        "ssh_url": "git@github.com:queelius/ollama_data_tools.git",
        "clone_url": "https://github.com/queelius/ollama_data_tools.git",
        "svn_url": "https://github.com/queelius/ollama_data_tools",
        "homepage": "https://queelius.github.io/ollama_data_tools/",
        "size": 90,
        "stargazers_count": 2,
        "watchers_count": 2,
        "language": "Python",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": false,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "mit",
            "name": "MIT License",
            "spdx_id": "MIT",
            "url": "https://api.github.com/licenses/mit",
            "node_id": "MDc6TGljZW5zZTEz"
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 2,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 22
            }
        ],
        "readme_content": "# Ollama Data Tools\n\n![PyPI version](https://img.shields.io/pypi/v/ollama_data_tools.svg)\n\n## Requirements\n\n- Python 3.x\n\n## Installation\n\nClone the repository and install the necessary dependencies:\n\n```sh\ngit clone https://github.com/queelius/ollama_data_tools.git\ncd ollama_data_tools\npip install -r requirements.txt\npip install -e .\n```\n\n## Ollama Data Tools\n\nThe `OllamaData` class is the core module of the Ollama Data Tools, allowing users to work programmatically with Ollama model data. This class provides methods to access, search, and filter model information.\n\n### Features\n\n- Retrieve the schema of the OllamaData object.\n- Access models by name or index.\n- List all available models.\n- Perform JMESPath queries and apply regex filters on the model data.\n- Cache model data for efficient repeated access.\n\n### Class Methods\n\n#### `OllamaData.get_schema() -> Dict[str, Any]`\nReturns the schema of the `OllamaData` object.\n\n#### `OllamaData.__init__(cache_path: str = '~/.ollama_data/cache', cache_time: str = '1 day')`\nInitializes the `OllamaData` object.\n\n- `cache_path`: The path to the cache file.\n- `cache_time`: The duration the cache is valid.\n\n#### `OllamaData.__len__() -> int`\nReturns the number of models.\n\n#### `OllamaData.__getitem__(index: int) -> Dict[str, Any]`\nGets a model by index.\n\n- `index`: The index of the model.\n\n#### `OllamaData.get_model(name: str) -> Dict[str, Any]`\nGets the model by name. Returns the most specific model that starts with the given name.\n\n- `name`: The name of the model.\n\n#### `OllamaData.get_models() -> Dict[str, Any]`\nGets the models. Caches the model data to avoid repeated regeneration.\n\n#### `OllamaData.search(query: str = '[*]', regex: Optional[str] = None, regex_path: str = '@') -> Dict[str, Any]`\nQueries, searches, and views the models using a JMESPath query, regex filter, and exclude keys.\n\n- `query`: The JMESPath query to filter and provide a view of the models.\n- `regex`: The regex pattern to match against the output.\n- `regex_path`: The JMESPath query for the regex pattern.\n\n### Usage Example\n\nHere is an example of how to use the `OllamaData` class programmatically:\n\n```python\nimport ollama_data as od\n\n# Initialize the OllamaData object\nmodels = od.OllamaData(cache_path='~/.ollama_data/cache', cache_time='1 day')\n\n# Get the schema of the OllamaData object\nprint(\"Schema:\", models.get_schema())\n\n# List all models\nprint(\"Models:\", ollama_data.get_models())\n\n# Get a specific model by name\nmodel = models.get_model('mistral')\nprint(\"Specific Model:\", model['name'])\n\n# Search models using a JMESPath query\nquery_result = models.search(query=\"[*].{name: name, size: total_weights_size}\")\nprint(\"Query Result:\", query_result)\n\n# Search models using a JMESPath query and regex filter\nquery_regex_result = models.search(\n    query=\"[*].{name: name, size: total_weights_size}\",\n    regex=\"mistral\", regex_path=\"name\")\nprint(\"Query Regex Result:\", query_regex_result)\n```\n\n## Ollama Data Query\n\nThe `ollama_data_query.py` script allows users to search and filter Ollama models using JMESPath queries and regular expressions. This tool is designed to help users explore and retrieve specific information about the models in their Ollama registry.\n\n### Features\n\n- Perform JMESPath queries to filter model data.\n- Use regular expressions to match specific patterns within the model data.\n- Print the JSON schema of the models.\n- Support for piped input queries.\n\n### Arguments\n\n- `query`: The JMESPath query to filter results.\n- `--regex`: Regular expression to match.\n- `--regex-path`: The JMESPath query for the regex pattern to apply against (default: `@`).\n- `--schema`: Print the JSON schema.\n- `--debug`: Set logging level to DEBUG.\n- `--cache-time`: Time to keep the cache file (default: `1 hour`).\n- `--cache-path`: The path to the cache file (default: `~/.ollama_data/cache`).\n\n### Usage\n\nTo perform a JMESPath query:\n\n```sh\nollama_data_query \"max_by(@, &total_weights_size).{name: name, size: total_weights_size}\"\n```\n\nTo use a regular expression to filter results:\n\n```sh\nollama_data_query --regex \"mistral:latest\" --regex-path name \"[*].{name: name, size: total_weights_size}\"\n```\n\nTo pipe a query from a file or another command:\n\n```sh\ncat query.txt | ollama_data_query\n```\n\nUsing regex and regex-path with a piped query:\n\n```sh\necho \"[*].{info: { name: name, other: weights}}\" | ollama_data_query --regex 14f2 --regex-path \"info.other[*].file_name\"\n```\n\n### Examples\n\n#### Query for the Largest Model\n\n```sh\nollama_data_query \"max_by(@, &total_weights_size).{name: name, sz: total_weights_size}\"\n```\n\n#### Filter Models Using Regex\n\n```sh\nollama_data_query --regex \"mistral|llama3\" --regex-path name \"[*].{name: name, size: total_weights_size}\"\n```\n\n#### Pipe a Query from a File\n\n```sh\ncat query.txt | ollama_data_query\n```\n\n#### Use Regex with a Piped Query\n\n```sh\necho \"[*].{info: { name: name, other: weights}}\" | ollama_data_query --regex 14f2 --regex-path \"info.other[*].file_name\"\n```\n\n## Ollama Data Export\n\nThe `ollama_data_export` script allows users to export Ollama models to a specified directory. This tool creates soft links for the model weights and saves the model metadata in the output directory.\n\n### Features\n\n- Export specified models to a self-contained directory.\n- Create soft links for model weights.\n- Save model metadata in JSON format.\n- Enable debug logging for detailed output.\n\n### Arguments\n\n- `outdir`: The output directory where the models will be exported.\n- `--models`: Comma-separated list of models to export. If not specified, all models will be exported.\n- `--cache-path`: The path to the cache file (default: `~/.ollama_data/cache`).\n- `--cache-time`: The time to keep the cache file (default: `1 day`).\n- `--debug`: Enable debug logging.\n- `--hash-length`: The length of the hash to use for the weight soft-links (default: `8`).\n\n### Usage\n\nTo export specified models to a directory:\n\n```sh\nollama_data_export --models model1,model2 --outdir /path/to/export\n```\n\nTo export all models to a directory:\n\n```sh\nollama_data_export /path/to/export\n```\n\n### Examples\n\n#### Export Specified Models\n\n```sh\nollama_data_export --models mistral,llama3 --outdir /path/to/export\n```\n\n#### Export All Models\n\n```sh\nollama_data_export --ourdir /path/to/export\n```\n\n#### Enable Debug Logging\n\n```sh\nollama_data_export --models mistral --outdir /path/to/export --debug\n```\n\n#### Specify Hash Length for Soft Links\n\n```sh\nollama_data_export --models mistral --outdir /path/to/export --hash-length 2\n```\n\n## Ollama Data Adapter\n\nThe `ollama_data_adapter` script adapts Ollama models for use with other inference engines, such as `llamacpp`. This tool is designed to reduce friction when experimenting with local LLM models and integrates with other tools for viewing, searching, and exporting Ollama models.\n\n### Features\n\n- List available engines and models.\n- Run models with specified engines.\n- Show the template for a given model.\n- Pass additional arguments to the inference engine.\n- Debugging information for advanced users.\n\n### Arguments\n\n- `model`: The model to run.\n- `engine`: The engine to use.\n- `--engine-path`: The path to the engine (required).\n- `--list-engines`: List available engines.\n- `--list-models`: List available models.\n- `--cache-path`: The path to the cache file (default: `~/.ollama_data/cache`).\n- `--cache-time`: The time to keep the cache file (default: `1 day`).\n- `--engine-args`: Arguments to pass through to the engine.\n- `--debug`: Print debug information.\n- `--show-template`: Show the template for the model.\n\n### Usage\n\nTo list all available engines:\n\n```sh\nollama_data_adapter --list-engines\n```\n\nTo list all available models:\n\n```sh\nollama_data_adapter --list-models\n```\n\nTo show the template for a specific model:\n\n```sh\nollama_data_adapter mistral --show-template\n\n## The template for the model has the following forms:\n## - [INST] {{ .System }} {{ .Prompt }} [/INST]\n```\n\nTo run a specific model with an engine:\n\n```sh\nollama_data_adapter model engine --engine-path /path/to/engine --engine-args 'arg1' ... 'argn'\n```\n\n### Example\n\nTo use the `llamacpp` inference engine with the `mistral` model (assuming\nit is available in your `Ollama` registry), you might use the following\narguments:\n\n```sh\nollama_data_adapter\n    mistral                          # Also matches `mistral:latest`\n    llamacpp                         # Use the llamacpp engine\n    --engine-path /path/to/llamacpp  # Path to engine, e.g. ~/llamacpp/main\n    --engine-args                    # Pass these arguments into the engine \n        '--n-gpu-layers 40'\n        '--prompt \"[INST] You are a helpful AI assistant. [/INST]\"'\n```\n\nThe `--prompt` engine pass-through argument follows the template shown by\nthe `ollama_data_adapter mistral --show-template`.\n\nWe place a lot of burden on the end-user to get the formatting right. These\nmodels are very sensitive to how you prompt them, so some experimentation\nmay be necessary.\n\nYou may also want to use `ollama_data_query` to show the system message\nor other properties of a model, so that you can further customize the\npass-through arguments to better fit its training data.\n\n## Contributing\n\nContributions are welcome! Please submit a pull request or open an issue to discuss changes.\n\n## License\n\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.\n\n## Author\n\nAlex Towell\n- Email: lex@metafunctor.com\n- Twitter: [@queelius](https://twitter.com/queelius)\n- Website: [metafunctor](https://metafunctor.com)\n- GitHub: [@queelius](https://github.com/queelius)\n",
        "github_pages": "https://queelius.github.io/ollama_data_tools/"
    },
    {
        "id": 669782173,
        "node_id": "R_kgDOJ-wQnQ",
        "name": "wei.series.md.c1.c2.c3",
        "full_name": "queelius/wei.series.md.c1.c2.c3",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/wei.series.md.c1.c2.c3",
        "description": "Weibull series system estimation from data with censored lifetimes and masked component cause of failure.",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3",
        "forks_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/forks",
        "keys_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/teams",
        "hooks_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/events",
        "assignees_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/tags",
        "blobs_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/subscription",
        "commits_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/merges",
        "archive_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/downloads",
        "issues_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/wei.series.md.c1.c2.c3/deployments",
        "created_at": "2023-07-23T12:12:30Z",
        "updated_at": "2024-02-19T16:20:46Z",
        "pushed_at": "2024-02-19T20:03:11Z",
        "git_url": "git://github.com/queelius/wei.series.md.c1.c2.c3.git",
        "ssh_url": "git@github.com:queelius/wei.series.md.c1.c2.c3.git",
        "clone_url": "https://github.com/queelius/wei.series.md.c1.c2.c3.git",
        "svn_url": "https://github.com/queelius/wei.series.md.c1.c2.c3",
        "homepage": "https://queelius.github.io/wei.series.md.c1.c2.c3/",
        "size": 1488,
        "stargazers_count": 2,
        "watchers_count": 2,
        "language": "R",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": true,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 0,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "gpl-3.0",
            "name": "GNU General Public License v3.0",
            "spdx_id": "GPL-3.0",
            "url": "https://api.github.com/licenses/gpl-3.0",
            "node_id": "MDc6TGljZW5zZTk="
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [
            "likelihood-model",
            "masked-data",
            "maximum-likelihood-estimation",
            "reliability-analysis",
            "right-censoring",
            "series-system",
            "weibull-distribution"
        ],
        "visibility": "public",
        "forks": 0,
        "open_issues": 0,
        "watchers": 2,
        "default_branch": "main",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 24
            }
        ],
        "readme_content": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# R package: `wei.series.md.c1.c2.c3`\n\nA likelihood model for series systems with Weibull component lifetimes.\nAccounts for right-censoring and candidate sets indicative of masked\nfailure causes.\n\n## Related Publication\n\nThis library was developed to support the research presented in the\nfollowing paper:\n\n  - \u201cReliability Estimation In Series Systems\u201d -\n    [GitHub](https://github.com/queelius/reliability-estimation-in-series-systems)\n\nFor detailed explanation and the scientific background behind the\nmethodologies implemented in this library, please refer to the paper.\n\n<!-- badges: start -->\n\n<!-- badges: end -->\n\n## Installation\n\nYou can install the development version of `wei.series.md.c1.c2.c3` from\n[GitHub](https://github.com/queelius/wei.series.md.c1.c2.c3) with:\n\n``` r\n# install.packages(\"devtools\")\n#devtools::install_github(\"queelius/wei.series.md.c1.c2.c3\")\n```\n\n``` r\nlibrary(algebraic.dist)\n#> Registered S3 method overwritten by 'algebraic.dist':\n#>   method     from \n#>   print.dist stats\nlibrary(algebraic.mle)\nlibrary(wei.series.md.c1.c2.c3)\n```\n\n## Examples\n\n``` r\n# fit the model\nfit <- mle_numerical(mle_lbfgsb_wei_series_md_c1_c2_c3(\n  df = guo_weibull_series_md$data,\n  theta0 = c(1,1,1,1,1,1),\n  control = list(\n    maxit = 1000L,\n    parscale = c(1, 1000, 1, 1000, 1, 1000))))\n\ncbind(confint(fit),\n  \"fit\" = params(fit),\n  \"guo mle\" = guo_weibull_series_md$mle)\n#>               2.5%       97.5%        fit  guo mle\n#> param1   0.5736164    1.941626   1.257621   1.2576\n#> param2 352.9027030 1635.838014 994.370358 994.3661\n#> param3   0.5633925    1.763536   1.163464   1.1635\n#> param4 310.1187793 1507.798853 908.958816 908.9458\n#> param5   0.6054160    1.656147   1.130782   1.1308\n#> param6 322.5652746 1357.623486 840.094380 840.1141\n\n# log-likelihood\nc(\"guo log-like\" = guo_weibull_series_md$loglike, \"fit log-like\" = loglik_val(fit))\n#> guo log-like fit log-like \n#>    -228.6851    -228.6851\n```\n\nWe see that they are approximately the same MLE fits.\n\n``` r\nshapes <- params(fit)[seq(1, length(params(fit)), 2)]\nscales <- params(fit)[seq(2, length(params(fit)), 2)]\ndata.frame(\n  \"Component Cause\" = wei_series_cause(1L:3L, shapes = shapes, scales = scales),\n  \"Component MTTF\" = wei_mttf(shape = shapes, scale = scales))\n#>   Component.Cause Component.MTTF\n#> 1       0.2862058       924.8697\n#> 2       0.3376112       862.1766\n#> 3       0.3761829       803.5490\n\ncat(\"System MTTF: \", wei_series_mttf(shapes = shapes, scales = scales))\n#> System MTTF:  339.3773\n```\n\n``` r\n(tq <- qwei_series(p = .825, shapes = shapes, scales = scales))\n#> [1] 575.704\nsurv_wei_series(t = tq, shapes = shapes, scales = scales)\n#> [1] 0.175\nrwei_series(10L, shapes =shapes, scales = scales)\n#>  [1]  95.53603 100.25772 282.05837 126.16159 425.90422  49.83648 130.02596\n#>  [8] 742.51530  64.97421 147.28431\npwei_series(seq(1, 5, 1), shapes = shapes, scales = scales)\n#> [1] 0.001024090 0.002293359 0.003675757 0.005136821 0.006658907\n```\n\n## Brief Overview\n\nThis package implements a likelihood model for Weibull series systems\nfrom masked data, including functions for the log-likelihood, score, and\nhessian of the log-likelihood. Analytical solutions are provided for the\nlog-likelihood and score functions, while the hessian is computed\nnumerically. The package is designed to handle two types of data: masked\ncomponent cause of failure data with exact failure time and\nright-censored system lifetime data.\n\nThe masked component data should approximately satisfy certain\nconditions. The conditions are as follows:\n\n#### Condition 1\n\nThe component cause of failure is in the candidate set.\n\n#### Condition 2\n\nWhen we condition on the component cause of failure being any particular\ncause in the canidate set and and the time of failure, the probability\nof the given candidate set does not vary as we vary the component cause\nof failure.\n\n#### Condition 3\n\nThe masking probabilities are independent of the series system lifetime\nparameter vector.\n\n### API\n\nAs a loglikelihood model, we provide the following functions:\n\n  - `loglik_wei_series_md_c1_c2_c3` for the log-likelihood\n  - `score_wei_series_md_c1_c2_c3` for the score function\n  - `hessian_wei_series_md_c1_c2_c3` for the hessian of the\n    log-likelihood\n\nFor convenience, we also provide some wrappers around the `optim`\nfunction to solve for the maximum likelihood estimates (MLE) of the\nshape and scale parameters using the Nelder-Mead and simulated annealing\nalgorithms:\n\n  - `mle_nelder_wei_series_md_c1_c2_c3` for the Nelder-Mead algorithm\n  - `mle_sann_wei_series_md_c1_c2_c3` for the simulated annealing\n    algorithm\n\nSince we base some of our results and analysis on Guo, Szidarovszky, and\nNiu (2013), we provide the data set from their paper, along with the\nmaximum likelihood estimates of the shape and scale parameters for the\nWeibull series system. We also provide a function to solve for the MLE\nusing the Nelder-Mead algorithm:\n\n  - `guo_weibull_series_md` for a model that generates data similar to\n    Guo, Szidarovszky, and Niu (2013)\n  - `guo_weibull_series_table_2` for the data from Table 2 in Guo,\n    Szidarovszky, and Niu (2013)\n\nWe also provide a host of supporting functions and data tables, e.g., we\nprovide Weibull series system distribution function that honors the\nestablished conventions in R:\n\n  - `dwei_series` for the probability density function\n  - `pwei_series` for the cumulative distribution function\n  - `qwei_series` for the quantile function\n  - `rwei_series` for random number generation\n\nWe also provide functions to compute the mean time to failure and the\ncomponent cause of failure for the Weibull series distribution, along\nwith the hazard and survival functions:\n\n  - `wei_series_mttf` for the mean time to failure\n  - `wei_series_cause` for the component cause of failure\n  - `hazard_wei_series` for the hazard function\n  - `surv_wei_series` for the survival function (this is normally done\n    by passing lower.tail = FALSE to `pwei_series` but we provide a\n    function)\n\nFinally, we also provide some functions for working with the components\nof the Weibull series system, e.g., we provide a function to compute the\nhazard function for the Weibull component lifetimes:\n\n  - `hazard_wei` for the hazard function of the Weibull component\n    lifetimes\n  - `wei_mttf` for the mean time to failure of the Weibull component\n    lifetimes\n",
        "github_pages": "https://queelius.github.io/wei.series.md.c1.c2.c3/"
    },
    {
        "id": 794223020,
        "node_id": "R_kgDOL1bhrA",
        "name": "AlgoTree",
        "full_name": "queelius/AlgoTree",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/AlgoTree",
        "description": "AlgoTree",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/AlgoTree",
        "forks_url": "https://api.github.com/repos/queelius/AlgoTree/forks",
        "keys_url": "https://api.github.com/repos/queelius/AlgoTree/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/AlgoTree/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/AlgoTree/teams",
        "hooks_url": "https://api.github.com/repos/queelius/AlgoTree/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/AlgoTree/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/AlgoTree/events",
        "assignees_url": "https://api.github.com/repos/queelius/AlgoTree/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/AlgoTree/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/AlgoTree/tags",
        "blobs_url": "https://api.github.com/repos/queelius/AlgoTree/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/AlgoTree/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/AlgoTree/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/AlgoTree/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/AlgoTree/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/AlgoTree/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/AlgoTree/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/AlgoTree/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/AlgoTree/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/AlgoTree/subscription",
        "commits_url": "https://api.github.com/repos/queelius/AlgoTree/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/AlgoTree/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/AlgoTree/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/AlgoTree/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/AlgoTree/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/AlgoTree/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/AlgoTree/merges",
        "archive_url": "https://api.github.com/repos/queelius/AlgoTree/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/AlgoTree/downloads",
        "issues_url": "https://api.github.com/repos/queelius/AlgoTree/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/AlgoTree/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/AlgoTree/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/AlgoTree/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/AlgoTree/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/AlgoTree/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/AlgoTree/deployments",
        "created_at": "2024-04-30T17:34:58Z",
        "updated_at": "2024-12-04T13:51:41Z",
        "pushed_at": "2024-10-31T02:08:22Z",
        "git_url": "git://github.com/queelius/AlgoTree.git",
        "ssh_url": "git@github.com:queelius/AlgoTree.git",
        "clone_url": "https://github.com/queelius/AlgoTree.git",
        "svn_url": "https://github.com/queelius/AlgoTree",
        "homepage": "https://queelius.github.io/AlgoTree/",
        "size": 6425,
        "stargazers_count": 16,
        "watchers_count": 16,
        "language": "Python",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": false,
        "has_pages": true,
        "has_discussions": false,
        "forks_count": 1,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "mit",
            "name": "MIT License",
            "spdx_id": "MIT",
            "url": "https://api.github.com/licenses/mit",
            "node_id": "MDc6TGljZW5zZTEz"
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 1,
        "open_issues": 0,
        "watchers": 16,
        "default_branch": "master",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 88
            }
        ],
        "readme_content": "AlgoTree\n========\n\n.. image:: https://img.shields.io/pypi/v/AlgoTree.svg\n   :target: https://pypi.org/project/AlgoTree/\n\n.. image:: https://img.shields.io/pypi/l/AlgoTree.svg\n   :target: https://pypi.org/project/AlgoTree/\n\n``AlgoTree`` is a Python package for working with tree structures, including\nFlatForest and TreeNode representations.\n\n\nIntroduction\n------------\n\nWelcome to the documentation for the ``AlgoTree`` package. This package provides a\nsuite of utilities for working with tree-like data structures in Python. It\nsupports various tree representations, including:\n\n- ``FlatForest`` and ``FlatForestNode`` for working with flat forest and tree structures\n- ``TreeNode`` for recursive tree structures\n- Conversion utilities to convert between different tree representations\n- Utility functions for common tree operations\n\nIt also comes with a command-line tool ``jt`` that exposes most of the functionality:\n\n- Can be used to create, manipulate, query, and visualize trees\n- It's like ``jq`` but for trees\n- Uses piping and redirection to make it easy to compose commands\n\nGetting Started\n---------------\n\nTo install the ``AlgoTree`` package, you can use pip:\n\n.. code-block:: shell\n\n   pip install AlgoTree\n\nOnce installed, you can start using the various tree structures and utilities\nprovided by the package. Here is a quick example to get you started:\n\n.. code-block:: python\n\n   from AlgoTree.flat_forest_node import FlatForestNode\n   from AlgoTree.pretty_tree import pretty_tree\n   root = FlatForestNode(name=\"root\", data=0)\n   node1 = FlatForestNode(name=\"node1\", parent=root, data=1)\n   node2 = FlatForestNode(name=\"node2\", parent=root, data=2)\n   node3 = FlatForestNode(name=\"node3\", parent=node2, data=3)\n   node4 = FlatForestNode(name=\"node4\", parent=node3, data=4)\n\n   pretty_tree(root)\n\nThis produces the output::\n\n   root\n   \u251c\u2500\u2500 node1\n   \u2514\u2500\u2500 node2\n       \u2514\u2500\u2500 node3\n           \u2514\u2500\u2500 node4\n\nThis code creates a simple tree with a root node and two child nodes. It then\npretty-prints the tree.\n\nThe ``AlgoTree`` package provides a wide range of tree structures and utilities\nto help you work with tree-like data structures in Python. You can explore the\ndocumentation to learn more about the available features and how to use them.\n\nFeatures\n--------\n\n- Flexible tree structures with ``FlatForest``, ``FlatForestNode``, and ``TreeNode``\n- Utility functions for common tree operations such as traversal, searching, and manipulation\n- Conversion utilities to easily convert between different tree representations\n- Integration with visualization tools to visualize tree structures\n\n\nNode-Centric API\n----------------\n\nWe implement two tree data structures:\n\n- ``FlatForest`` for working with flat tree structures with\n      \"pointers\" to parent nodes. It uses a proxy object ``FlatForestNode`` to\n      provide a node-centric API.\n- ``TreeNode`` for recursive tree structures, in which each node is a dictionary\n      with an optional list of child nodes.\n\nEach representation has its own strengths and weaknesses. The key design point\nfor ``FlatForest`` and ``TreeNode`` is that they are both also ``dict`` objects, i.e.,\nthey provide a *view* of dictionaries as tree-like structures, as long as the\ndictionaries are structured in a certain way. We document that structure\nelsewhere.\n\nEach tree data structure models the *concept* of a tree node so that the\nunderlying implementations can be decoupled from any algorithms\nor operations that we may want to perform on the tree.\n\nThe tree node concept is defined as follows:\n\n- **children** property\n\n      Represents a list of child nodes for the current node that can be\n      accessed and modified[1_].\n\n- **parent** property\n\n      Represents the parent node of the current node that can be accessed\n      and modified[2_]. \n      \n      Suppose we have the subtree ``G`` at node ``G``::\n\n            B (root)\n            \u251c\u2500\u2500 D\n            \u2514\u2500\u2500 E (parent)\n                \u2514\u2500\u2500 G (current node)\n\n      Then, ``G.parent`` should refer node ``E``. ``G.root.parent`` should be None\n      since ``root`` is the root node of subtree ``G`` and the root node has no parent.\n      This is true even if subtree ``G`` is a subtree view of a larger tree.\n\n      If we set ``G.parent = D``, then the tree structure changes to::\n\n            B (root)\n            \u251c\u2500\u2500 D\n            \u2502   \u2514\u2500\u2500 G (current node)\n            \u2514\u2500\u2500 E\n      \n      This also changes the view of the sub-tree, since we changed the\n      underlying tree structure. However, the same nodes are still accessible\n      from the sub-tree.\n\n      If we had set ``G.parent = X`` where ``X`` is not in the subtree ``G``, then\n      we would have an invalid subtree view even if is is a well-defined\n      operation on the underlying tree structure. It is undefined\n      behavior to set a parent that is not in the subtree, but leave it\n      up to each implementation to decide how to handle such cases.\n\n- **node(name: str) -> NodeType** method.\n\n      Returns a node in the current subtree that the\n      current node belongs to. The returned node should be the node with the\n      given name, if it exists. If the node does not exist, it should raise\n      a ``KeyError``.\n\n      The node-centric view of the returned node should be consistent with the\n      view of the current node, i.e., if the current node belongs to a specific sub-tree\n      rooted at some other node, the returned node should also belong to the\n      same sub-tree (i.e., with the same root), just pointing to the new node,\n      but it should be possible to use ``parent`` and ``children`` to go up and down\n      the sub-tree to reach the same nodes. Any node that is an ancestor of the\n      root of the sub-tree remains inaccessible.\n\n      Example: Suppose we have the sub-tree ``t`` rooted at ``A`` and the current node\n      is ``B``::\n\n            A (root)\n            \u251c\u2500\u2500 B (current node)\n            \u2502   \u251c\u2500\u2500 D\n            \u2502   \u2514\u2500\u2500 E\n            |       \u2514\u2500\u2500 G\n            \u2514\u2500\u2500 C\n                \u2514\u2500\u2500 F\n      \n      If we get node ``F``, ``t.node(F)``, then the sub-tree ``t`` remains the same,\n      but the current node is now ``F``::\n    \n            A (root)\n            \u251c\u2500\u2500 B\n            \u2502   \u251c\u2500\u2500 D\n            \u2502   \u2514\u2500\u2500 E\n            |       \u2514\u2500\u2500 G\n            \u2514\u2500\u2500 C\n                \u2514\u2500\u2500 F (current node)\n\n- **subtree(name: Optional[str] = None) -> NodeType** method.\n\n      This is an optional method that may not be implemented by all tree\n      structures. ``FlatForestNode`` implements this method, but ``TreeNode`` does\n      not.\n\n      Returns a view of another sub-tree rooted at ``node`` where ``node`` is\n      contained in the original sub-tree view. If ``node`` is ``None``, the method\n      will return the sub-tree rooted at the current node.\n\n      As a view, the subtree represents a way of looking at the tree structure\n      from a different perspective. If you modify the sub-tree, you are also\n      modifying the underlying tree structure. The sub-tree should be a\n      consistent view of the tree, i.e., it should be possible to use ``parent``\n      and ``children`` to navigate between the nodes in the sub-tree and the\n      nodes in the original tree.\n      \n      ``subtree`` is a *partial function* over the the nodes in the sub-tree,\n      which means it is only well-defined when ``node`` is a descendant of\n      the root of the sub-tree. We do not specify how to deal with the case\n      when this condition is not met, but one approach would be to raise an\n      exception.\n\n      Example: Suppose we have the sub-tree `t` rooted at `A` and the current node\n      is `C`::\n\n            A (root)\n            \u251c\u2500\u2500 B\n            \u2502   \u251c\u2500\u2500 D\n            \u2502   \u2514\u2500\u2500 E\n            |       \u2514\u2500\u2500 G\n            \u2514\u2500\u2500 C (current node)\n                \u2514\u2500\u2500 F\n\n      The subtree `t.subtree(B)` returns a new subtree::\n\n            B (root, current node)\n            \u251c\u2500\u2500 D\n            \u2514\u2500\u2500 E\n                \u2514\u2500\u2500 G\n\n- **root** property\n\n      An immutable property that represents the root node of the (sub)tree.\n      \n      Suppose we have the subtree ``G`` at node ``G``::\n\n            B (root)\n            \u251c\u2500\u2500 D\n            \u2514\u2500\u2500 E\n                \u2514\u2500\u2500 G (current node)\n\n      Then, `G.root` should refer node `B`.\n\n- **payload** property\n\n      Returns the payload of the current node. The payload\n      is the data associated with the node but not with the structure of the\n      tree, e.g., it does not include the ``parent`` or ``children`` of the node.\n\n- **name** property\n\n      Returns the name of the current node. The name is\n      an identifier for the node within the tree. It is not necessarily unique,\n      and nor is it necessarily even a meaningful identifier, e.g., a random\n      UUID.\n      \n      In ``TreeNode``, for instance, if the name is not set, a UUID is generated.\n\n.. [1] Modifying this property may change the **parent** property of other nodes.\n\n.. [2] Modifying this property may change the **children** property of other nodes.\n",
        "github_pages": "https://queelius.github.io/AlgoTree/"
    },
    {
        "id": 752346114,
        "node_id": "R_kgDOLNfkAg",
        "name": "elasticsearch-lm",
        "full_name": "queelius/elasticsearch-lm",
        "private": false,
        "owner": {
            "login": "queelius",
            "id": 1896674,
            "node_id": "MDQ6VXNlcjE4OTY2NzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1896674?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/queelius",
            "html_url": "https://github.com/queelius",
            "followers_url": "https://api.github.com/users/queelius/followers",
            "following_url": "https://api.github.com/users/queelius/following{/other_user}",
            "gists_url": "https://api.github.com/users/queelius/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/queelius/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/queelius/subscriptions",
            "organizations_url": "https://api.github.com/users/queelius/orgs",
            "repos_url": "https://api.github.com/users/queelius/repos",
            "events_url": "https://api.github.com/users/queelius/events{/privacy}",
            "received_events_url": "https://api.github.com/users/queelius/received_events",
            "type": "User",
            "user_view_type": "public",
            "site_admin": false
        },
        "html_url": "https://github.com/queelius/elasticsearch-lm",
        "description": "ElasticSearch Query Fine-Tuning Training Data for Large Language Models",
        "fork": false,
        "url": "https://api.github.com/repos/queelius/elasticsearch-lm",
        "forks_url": "https://api.github.com/repos/queelius/elasticsearch-lm/forks",
        "keys_url": "https://api.github.com/repos/queelius/elasticsearch-lm/keys{/key_id}",
        "collaborators_url": "https://api.github.com/repos/queelius/elasticsearch-lm/collaborators{/collaborator}",
        "teams_url": "https://api.github.com/repos/queelius/elasticsearch-lm/teams",
        "hooks_url": "https://api.github.com/repos/queelius/elasticsearch-lm/hooks",
        "issue_events_url": "https://api.github.com/repos/queelius/elasticsearch-lm/issues/events{/number}",
        "events_url": "https://api.github.com/repos/queelius/elasticsearch-lm/events",
        "assignees_url": "https://api.github.com/repos/queelius/elasticsearch-lm/assignees{/user}",
        "branches_url": "https://api.github.com/repos/queelius/elasticsearch-lm/branches{/branch}",
        "tags_url": "https://api.github.com/repos/queelius/elasticsearch-lm/tags",
        "blobs_url": "https://api.github.com/repos/queelius/elasticsearch-lm/git/blobs{/sha}",
        "git_tags_url": "https://api.github.com/repos/queelius/elasticsearch-lm/git/tags{/sha}",
        "git_refs_url": "https://api.github.com/repos/queelius/elasticsearch-lm/git/refs{/sha}",
        "trees_url": "https://api.github.com/repos/queelius/elasticsearch-lm/git/trees{/sha}",
        "statuses_url": "https://api.github.com/repos/queelius/elasticsearch-lm/statuses/{sha}",
        "languages_url": "https://api.github.com/repos/queelius/elasticsearch-lm/languages",
        "stargazers_url": "https://api.github.com/repos/queelius/elasticsearch-lm/stargazers",
        "contributors_url": "https://api.github.com/repos/queelius/elasticsearch-lm/contributors",
        "subscribers_url": "https://api.github.com/repos/queelius/elasticsearch-lm/subscribers",
        "subscription_url": "https://api.github.com/repos/queelius/elasticsearch-lm/subscription",
        "commits_url": "https://api.github.com/repos/queelius/elasticsearch-lm/commits{/sha}",
        "git_commits_url": "https://api.github.com/repos/queelius/elasticsearch-lm/git/commits{/sha}",
        "comments_url": "https://api.github.com/repos/queelius/elasticsearch-lm/comments{/number}",
        "issue_comment_url": "https://api.github.com/repos/queelius/elasticsearch-lm/issues/comments{/number}",
        "contents_url": "https://api.github.com/repos/queelius/elasticsearch-lm/contents/{+path}",
        "compare_url": "https://api.github.com/repos/queelius/elasticsearch-lm/compare/{base}...{head}",
        "merges_url": "https://api.github.com/repos/queelius/elasticsearch-lm/merges",
        "archive_url": "https://api.github.com/repos/queelius/elasticsearch-lm/{archive_format}{/ref}",
        "downloads_url": "https://api.github.com/repos/queelius/elasticsearch-lm/downloads",
        "issues_url": "https://api.github.com/repos/queelius/elasticsearch-lm/issues{/number}",
        "pulls_url": "https://api.github.com/repos/queelius/elasticsearch-lm/pulls{/number}",
        "milestones_url": "https://api.github.com/repos/queelius/elasticsearch-lm/milestones{/number}",
        "notifications_url": "https://api.github.com/repos/queelius/elasticsearch-lm/notifications{?since,all,participating}",
        "labels_url": "https://api.github.com/repos/queelius/elasticsearch-lm/labels{/name}",
        "releases_url": "https://api.github.com/repos/queelius/elasticsearch-lm/releases{/id}",
        "deployments_url": "https://api.github.com/repos/queelius/elasticsearch-lm/deployments",
        "created_at": "2024-02-03T17:11:56Z",
        "updated_at": "2024-12-07T10:43:05Z",
        "pushed_at": "2024-02-07T17:01:07Z",
        "git_url": "git://github.com/queelius/elasticsearch-lm.git",
        "ssh_url": "git@github.com:queelius/elasticsearch-lm.git",
        "clone_url": "https://github.com/queelius/elasticsearch-lm.git",
        "svn_url": "https://github.com/queelius/elasticsearch-lm",
        "homepage": null,
        "size": 60,
        "stargazers_count": 17,
        "watchers_count": 17,
        "language": "Python",
        "has_issues": true,
        "has_projects": true,
        "has_downloads": true,
        "has_wiki": false,
        "has_pages": false,
        "has_discussions": false,
        "forks_count": 2,
        "mirror_url": null,
        "archived": false,
        "disabled": false,
        "open_issues_count": 0,
        "license": {
            "key": "mit",
            "name": "MIT License",
            "spdx_id": "MIT",
            "url": "https://api.github.com/licenses/mit",
            "node_id": "MDc6TGljZW5zZTEz"
        },
        "allow_forking": true,
        "is_template": false,
        "web_commit_signoff_required": false,
        "topics": [],
        "visibility": "public",
        "forks": 2,
        "open_issues": 0,
        "watchers": 17,
        "default_branch": "main",
        "permissions": {
            "admin": true,
            "maintain": true,
            "push": true,
            "triage": true,
            "pull": true
        },
        "contributors": [
            {
                "name": "queelius",
                "commits": 12
            }
        ],
        "readme_content": "# Fine-Tuning Language Models for API Query Generation\n\n## Project Overview\n\nThis project aims to fine-tune a smaller Large Language Model (LLM) for the specific task of translating natural language queries (NLQs) into structured API queries, with an initial focus on Elasticsearch's Query DSL. The motivation behind this effort is to significantly enhance the accessibility and usability of API endpoints, making them more intuitive for users by allowing interactions in natural language.\n\nThe concept extends beyond Elasticsearch, proposing a universal approach to interfacing with various APIs. By leveraging compact, efficient language models, we envision a future where sophisticated API interactions are democratized, enabling more natural and user-friendly application interfaces.\n\n## Motivation\n\nWhile Large Language Models have demonstrated remarkable capabilities in understanding and generating natural language, their size and resource requirements often limit widespread deployment, especially in resource-constrained environments. This project explores the potential of smaller, optimized models to perform complex tasks\u2014like generating accurate API queries from NLQs\u2014while maintaining low latency, minimal memory footprint, and reduced power consumption. Such models can revolutionize API interactions across numerous platforms, making technology more accessible and intuitive for a broader user base.\n\n## Objective\n\nFine-tune a small LLM, [TinyLlama](https://github.com/jzhang38/TinyLlama), to accurately translate NLQs into Elasticsearch JSON queries based on given Elasticsearch mappings. The project aims to showcase the efficiency and competency of the model at the task, with the objective of being able to place it in diverse environments, from serverless architectures to edge devices.\n\n## Prior Work\n\nThis work is inspired by existing models that translate NLQs into SQL queries, like [duckdb-nsq](https://huggingface.co/motherduckdb/DuckDB-NSQL-7B-v0.1). We aim to build on this foundation by adapting the approach to the task of generating structured API queries, starting with Elasticsearch's Query DSL. The project also draws from research on fine-tuning language models for specific tasks, with a focus on optimizing model size and performance.\n\n## Synthetic Data Generation\n\nThe foundation of our fine-tuning process involves creating a rich dataset of Elasticsearch [mappings (schemas)](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html), along with corresponding NLQs (natural language queries), and their target Elasticsearch JSON queries. This synthetic data is designed to cover a wide range of query types and complexities, ensuring that the model is trained on diverse examples that reflect real-world use cases.\n\nThis section details our approach to synthetic data generation, ensuring a broad coverage of query types and complexities.\n\nWe actually generated our synthetic data by first sampling from GPT-4, and then using those results to prime an open-source\nmodel, [llama2](https://llama.meta.com/), to generate more synthetic data that was based on the high-quality examples\nprovided by GPT-4. This was done to ensure that the synthetic data was of high quality and covered a wide range of query types and complexities without costing too much in terms of computation resources. See the `synthetic_data_generation` directory for more details.\n\n### Process\n\nWe use the very large and capable GPT-4 model to generate the synthetic data. The process involves three key steps:\n\n1. **Generate Elasticsearch Mappings**: Create diverse mappings that represent different data domains, from e-commerce to public records.\n2. **Generate NLQs**: For each mapping, develop a variety of natural language queries that reflect potential user intents.\n3. **Generate Corresponding JSON Queries**: Construct accurate Elasticsearch queries for each NLQ, demonstrating the desired output for the model.\n\n### JSON Format of Training Data\n\nEach training example is a JSON object structured to contain all the necessary information for training the model to translate NLQs against mappings into the target Elasticsearch JSON queries.\n\nThis JSON format is designed for use in training machine learning models, specifically aimed at converting natural language queries into structured API queries when conditioned on Elasticsearch mappings. By documenting this JSON format, users and contributors can better understand how to create, extend, and utilize the synthetic dataset for training and testing purposes, ensuring that the data is correctly formatted and meaningful for the intended training tasks.\n\n#### Structure\n\nThe JSON object for each training example comprises the following key components:\n\n- **`domain`**: A string that identifies the specific domain or context of the example (e.g., \"Healthcare Appointments\", \"Employee Attendance\"). This helps in categorizing and filtering examples based on their application area.\n\n- **`mapping`**: An object representing the Elasticsearch index mapping. This defines the schema of the data that the NLQ and query pertain to, including field names and their data types.\n\n- **`NLQs`**: An array of objects, each containing:\n  - **`NLQ`**: A string representing a natural language query. This is the query that a user might input, seeking information from the Elasticsearch index.\n  - **`query`**: The Elasticsearch JSON query that corresponds to the `NLQ`. This object is structured according to the Elasticsearch Query DSL, representing the exact query that should be executed to satisfy the information need expressed in the `NLQ`.\n\n##### Example\n\n```json\n{\n  \"domain\": \"Sample Domain\",\n  \"mapping\": {\n    \"properties\": {\n      \"field1\": { \"type\": \"text\" },\n      \"field2\": { \"type\": \"date\" },\n      \"field3\": { \"type\": \"keyword\" }\n    }\n  },\n  \"NLQs\": [\n    {\n      \"NLQ\": \"Example natural language query\",\n      \"query\": {\n        \"query\": {\n          \"bool\": {\n            \"must\": [{ \"match\": { \"field1\": \"some value\" } }],\n            \"filter\": [{ \"range\": { \"field2\": { \"gte\": \"2023-01-01\" } } }]\n          }\n        }\n      }\n    }\n  ]\n}\n```\n\n## Inference Time: The System Instruction\n\nAt inference time, users and developers are expected to use a `system instruction` that it is similar to the training data. The model will then generate a query that is similar to the `query` field in the training data. For example, in the above example, the system instruction is given by:\n\n```json\n{\n  \"domain\": \"Sample Domain\",\n  \"mapping\": { \n    \"properties\": {\n      \"field1\": { \"type\": \"text\" },\n      \"field2\": { \"type\": \"date\" },\n      \"field3\": { \"type\": \"keyword\" }\n    }\n  },\n}\n```\n\nThen, when the user asks the NLQ \"Example natural language query\", the program will\nmake this the prompt to the LLM, and the model will generate a response that\nit has been fine-tuned to predict according to our synthetic training data.\n\n#### In-Context Learning\n\nThere is also an opportunity for in-context learning, where the developers of the system can, given their special domain knowledge of their users and data, provide additional examples of NLQs and their corresponding queries.\nHowever, since we are assuming computation resources are limited, adding to the context will generally slow down\nthe system. This is a tradeoff that the developers will have to make. Indeed, if resources are not that constrained, then\nbetter results can be achieved by using a larger language model and optionally providing examples for in-context learning.\n\n### Challenges and Solutions\n\n- **Variability and Complexity**: Addressed by including a wide range of query scenarios and incorporating both basic and advanced Elasticsearch functionalities.\n- **Realism**: Ensured by basing synthetic data on realistic use cases and varying the structure and complexity of mappings.\n\n## Fine-Tuning Process\n\nThis section outlines the steps taken to adapt the language model to our specific task, including model selection, training environment setup, and evaluation metrics.\n\n### Model Selection\n\nCriteria for choosing a suitable smaller LLM include performance, efficiency, and adaptability to the task of generating structured API queries. This suggests looking for a model that has been fine-tuned on instruction following tasks, and that has a small memory footprint. The primary model we are considering is [TinyLlama](https://github.com/jzhang38/TinyLlama), which is a 1.1 billion parameter model that has been fine-tuned on instruction following tasks.\n\n### Training and Evaluation\n\n#### Dataset Preparation\n\nWe split the synthetic data into training, validation, and test sets, following a standard ratio (e.g., 70% training, 15% validation, 15% test). This ensures that the model is trained on a diverse range of examples and evaluated on unseen data.\n\n#### Evaluation Metrics\n\nSince we synthetically generated the data, there is no real data on which to evaluate the model. Hoewver, to make this problem more tractable, we consider the data in the test set as the ground truth. So, for the test set, we will take an additional step of generating more synthetic data for specifying the contents of the database for each mapping (domain). For each of these, we will have GPT-4 generate a Python script that populates the database with relevant values, and so we should be able to make these databases as large as we want without much time and effort.\n\nWe will then run the queries generated in the test set that correspond to each NLQ, by the model on the populated database, and then compare the search results from the model with the ground truth. In this way, even if the predicted query is different, as long as the search results are similiar (precision, recall, etc), we can consider the model to have performed well.\n\nIn information retrieval, the following metrics are commonly used:\n\n- **Accuracy**: The proportion of search results that are relevant to the user's information need, as represented by the NLQ.\n- **Precision**: The proportion of relevant search results among all retrieved results.\n- **Recall**: The proportion of relevant search results that are retrieved among all relevant results.\n- **Execution Success Rate**: The percentage of queries that are successfully executed. (The query may be malformed or invalid, leading to execution failure.)\n    \n## Future Directions\n\nWhile the initial focus is on Elasticsearch, the methodology and findings from this project have broader implications. Future work will explore extending this approach to other APIs, further reducing model size without compromising performance, and investigating deployment strategies for real-time applications.\n\n## Contributing\n\nWe welcome contributions from the community, whether it's in the form of feedback, bug reports, or pull requests.\n"
    }
]
